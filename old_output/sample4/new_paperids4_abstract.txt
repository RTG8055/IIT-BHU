78B9FFFA	Various software packages are commonly used for the implementation and calculation of decision-analytic models for health economic evaluations. However, comparison of these programs with regard to ease of implementing a model is lacking.(i) to compare the assets and drawbacks of three commonly used software packages for Markov models with regard to ease of implementation; and (ii) to investigate how a technical model validation can be conducted by comparing the results of the three implementations.A Markov model on chronic obstructive pulmonary disease was implemented in TreeAge, Microsoft Excel and Arena with the same assumptions on model structure, transition probabilities and costs. A hypothetical smoking cessation programme for patients in stage 1 was evaluated against usual care. The packages were compared with respect to time and effort for implementation, run-time, features for the presentation of results, and flexibility. Agreement between the packages on average costs and life-years gained and on the incremental cost-effectiveness ratio was considered for technical validation in the form of expected values (between TreeAge and Excel only) and Monte Carlo simulations.Ease of implementation was best in TreeAge, whereas Arena offered the highest flexibility. Deterministic results were in agreement between TreeAge and Excel, as were simulated values between all three packages.Excel offers an intuitive spreadsheet interface, but the acquisition of and the training in TreeAge or Arena is worthwhile for more complex models. Double implementation is a practicable validation technique that should be conducted to ensure correct model implementation.
7F5443CD	In this paper, we study the correlation properties of the fading mobile radio channel. Based on these studies, we model the channel as a one-step Markov process whose transition probabilities are a function of the channel characteristics. Then we present the throughput performance of the Go-Back-N and selective-repeat automatic repeat request (ARQ) protocols with timer control, using the Markov model for both forward and feedback channels. This approximation is found to be very good, as confirmed by simulation results.
78744637	In this paper, we introduce a 3-D human-body tracker capable of handling fast and complex motions in real-time. The parameter space, augmented with first order derivatives, is automatically partitioned into Gaussian clusters each representing an elementary motion: hypothesis propagation inside each cluster is therefore accurate and efficient.  The transitions between clusters use the predictions of a Variable Length Markov Model which can explain high level behaviours over a long history. Using Monte-Carlo methods, evaluation of model candidates is critical for both speed and robustness.  We present a new evaluation scheme based on volumetric reconstruction and blobs-fitting, where appearance models and image evidences are represented by Gaussian mixtures.  We demonstrate the application of our tracker to long video sequences exhibiting rapid and diverse movements.
7D1020E8	An automatic-repeat-request (ARQ) Go-Back-N (GBN) protocol with unreliable feedback and time-out mechanism is studied, using renewal theory. Transmissions on both the forward and the reverse channels are assumed to experience Markovian errors. The exact throughput of the protocol is evaluated, and simulation results, that confirm the analysis, are presented. A detailed comparison of the proposed method and the commonly used transfer function method reveals that the proposed approach is simple and potentially more powerful.
80D7D606	The recently developed technique of arithmetic coding, in conjunction with a Markov model of the source, is a powerful method of data compression in situations where a linear treatment is inappropriate. Adaptive coding allows the model to be constructed dynamically by both encoder and decoder during the course of the transmission, and has been shown to incur a smaller coding overhead than explicit transmission of the model's statistics. But there is a basic conflict between the desire to use high-order Markov models and the need to have them formed quickly as the initial part of the message is sent. This paper describes how the conflict can be resolved with partial string matching, and reports experimental results which show that mixed-case English text can be coded in as little as 2.2 bits/ character with no prior knowledge of the source.
78AD17F6	Using a finite state Markov channel model, we develop an analytical method for evaluation of the packet error structure in multiple-input multiple-output (MIMO) systems based on singular value decomposition (SVD). We consider dual-branch MIMO systems, with either two transmit and arbitrary number of receive antennas, or arbitrary number of transmit and two receive antennas. The corresponding Markov model parameters are obtained using a novel closed-form expressions for probability density function and level crossing rate of the signal-to-noise ratio at the output of eigenchannels in a MIMO system, derived for a case of Rayleigh propagation, imperfect channel state information and any fixed power allocation. The exact bit error rate for the transmission of quadrature amplitude modulated (QAM) symbols through the eigenchannels is derived in polynomial closed form. Furthermore, by using the developed Markov model, the packet error statistics in the corresponding eigenchannels are determined, and the closed-form analytical expression for the system throughput is derived when ‘go-back-N’ automatic repeat request procedure is applied in time-varying eigenchannels. The analytical results are validated by using Monte Carlo simulations.
7D9B3729	Background. Serial period prevalence estimates for recurrent diseases such as major depression are available more frequently than fully detailed longitudinal data, but it is difficult to estimate incidence and episode duration from such data. Incidence and episode duration are critical decision modeling parameters for recurrent diseases. Objectives. To reduce bias that would otherwise occur in national incidence and duration-of-episode estimates for major depressive episodes deriving from studies using serial period prevalence data and to illustrate amethodological approach for the estimation of incidence from such studies. Methods. Monte Carlo simulation was applied to a Markov process describingincidence and recovery from major depressive episodes. Results. The annual incidence and episode duration were found to be 3.1% and 17.1 weeks, respectively. These estimates are expected to be less subject to bias than those generated without modeling. Conclusions. These results highlight the usefulness of Markov models for analysis of longitudinal data. The methods described here may be useful for decision modeling andmay be generalizable to other chronic diseases.
7E17B5B5	Most epidemiological studies of major depression report period prevalence estimates. These are of limited utility in characterizing the longitudinal epidemiology of this condition. Markov models provide a methodological framework for increasing the utility of epidemiological data. Markov models relating incidence and recovery to major depression prevalence have been described in a series of prior papers. In this paper, the models are extended to describe the longitudinal course of the disorder. Data from three national surveys conducted by the Canadian national statistical agency (Statistics Canada) were used in this analysis. These data were integrated using a Markov model. Incidence, recurrence and recovery were represented as weekly transition probabilities. Model parameters were calibrated to the survey estimates. The population was divided into three categories: low, moderate and high recurrence groups. The size of each category was approximated using lifetime data from a study using the WHO Mental Health Composite International Diagnostic Interview (WMH-CIDI). Consistent with previous work, transition probabilities reflecting recovery were high in the initial weeks of the episodes, and declined by a fixed proportion with each passing week. Markov models provide a framework for integrating psychiatric epidemiological data. Previous studies have illustrated the utility of Markov models for decomposing prevalence into its various determinants: incidence, recovery and mortality. This study extends the Markov approach by distinguishing several recurrence categories. 
7E61B32A	Depression is among the major contributors to worldwide disease burden and adequate modelling requires a framework designed to depict real world disease progression as well as its economic implications as closely as possible.In light of the specific characteristics associated with depression (multiple episodes at varying intervals, impact of disease history on course of illness, sociodemographic factors), our aim was to clarify to what extent "Discrete Event Simulation" (DES) models provide methodological benefits in depicting disease evolution.We conducted a comprehensive review of published Markov models in depression and identified potential limits to their methodology. A model based on DES principles was developed to investigate the benefits and drawbacks of this simulation method compared with Markov modelling techniques.The major drawback to Markov models is that they may not be suitable to tracking patients' disease history properly, unless the analyst defines multiple health states, which may lead to intractable situations. They are also too rigid to take into consideration multiple patient-specific sociodemographic characteristics in a single model. To do so would also require defining multiple health states which would render the analysis entirely too complex. We show that DES resolve these weaknesses and that its flexibility allow patients with differing attributes to move from one event to another in sequential order while simultaneously taking into account important risk factors such as age, gender, disease history and patients attitude towards treatment, together with any disease-related events (adverse events, suicide attempt etc.).DES modelling appears to be an accurate, flexible and comprehensive means of depicting disease progression compared with conventional simulation methodologies. Its use in analysing recurrent and chronic diseases appears particularly useful compared with Markov processes.
802AF8D6	We investigate the behavior of block errors which arise in data transmission on fading channels. Our approach takes into account the details of the specific coding/modulation scheme and tracks the fading process symbol by symbol. It is shown that a Markov approximation for the block error process (possibly degenerating into an identically distributed (i.i.d.) process for sufficiently fast fading) is a good model for a broad range of parameters. Also, it is observed that the relationship between the marginal error rate and the transition probability is largely insensitive to parameters such as block length, degree of forward error correction and modulation format, and depends essentially on an appropriately normalized version of the Doppler frequency. This relationship can therefore be computed in the simple case of a threshold model and then used more generally as an accurate approximation. This observation leads to a unified approach for the channel modeling, and to a simplified performance analysis of upper layer protocols.
7FD11145	Block-error processes in transmissions over slow-fading channels can be accurately modeled by a two-state Markov chain [the block Markov model (BMM)]. Another line of research has focused on the use of a channel-state Markov model (CSMM) to analyze block transmissions. Although both techniques provide results that agree well with observations, the relationship between both Markov models has not been recognized in the previous literature. In this letter, we show that the BMM for slow-fading channels can be directly derived from the CSMM. In addition, we introduce a greatly simplified channel-modeling methodology. In the new methodology, the BMM is the primary channel characterization tool, and the CSMM becomes essentially an estimation technique that provides parameters for the BMM. Results of packet transmissions in slow-fading channels show that our approach provides significant improvements in both accuracy and simplicity over previously proposed techniques.
7CBB23DF	Chronic obstructive pulmonary disease (COPD) is currently the fourth leading cause of death worldwide. It has serious health effects and causes substantial costs for society.The aim of the present paper was to develop a state-of-the-art decision-analytic model of COPD whereby the cost effectiveness of interventions in Germany can be estimated. To demonstrate the applicability of the model, a smoking cessation programme was evaluated against usual care. A seven-stage Markov model (disease stages I to IV according to the GOLD [Global Initiative for Chronic Obstructive Lung Disease] classification, states after lung-volume reduction surgery and lung transplantation, death) was developed to conduct a cost-utility analysis from the societal perspective over a time horizon of 10, 40 and 60 years. Patients entered the cohort model at the age of 45 with mild COPD. Exacerbations were classified into three levels: mild, moderate and severe. Estimation of stage-specific probabilities (for smokers and quitters), utilities and costs was based on German data where possible. Data on effectiveness of the intervention was retrieved from the literature. A discount rate of 3% was applied to costs and effects. Probabilistic sensitivity analysis was used to assess the robustness of the results.The smoking cessation programme was the dominant strategy compared with usual care, and the intervention resulted in an increase in health effects of 0.54 QALYs and a cost reduction of €1115 per patient (year 2007 prices) after 60 years. In the probabilistic analysis, the intervention dominated in about 95% of the simulations. Sensitivity analyses showed that uncertainty primarily originated from data on disease progression and treatment cost in the early stages of disease.e model developed allows the long-term cost effectiveness of interventions to be estimated, and has been adapted to Germany. The model suggests that the smoking cessation programme evaluated was more effective than usual care as well as being cost-saving. Most patients had mild or moderate COPD, stages for which parameter uncertainty was found to be high. This raises the need to improve data on the early stages of COPD.
7F603AAF	A method of dynamically constructing Markov chain models that describe the characteristics of binary messages is developed. Such models can be used to predict future message characters and can therefore be used as a basis for data compression. To this end, the Markov modelling technique is combined with Guazzo's arithmetic coding scheme to produce a powerful method of data compression. The method has the advantage of being adaptive: messages may be encoded or decoded with just a single pass through the data. Experimental results reported here indicate that.the Markov modelling approach generally achieves much better data compression than that observed with competing methods on typical computer data.
7F5E056C	Motivated by applications such as automated visual surveillance and video monitoring and annotation, there has been a lot of interest in constructing cognitive vision systems capable of interpreting the high level semantics of dynamic scenes. In this paper we present a novel approach for automatically inferring models of object interactions that can be used to interpret observed behaviour within a scene. A real-time low-level computer vision system, together with an attentional control mechanism, are used to identify incidents or events that occur in the scene. A data driven approach has been taken in order to automatically infer discrete and abstract representations (symbols) of primitive object interactions; effectively the system learns a set of qualitative spatial relations relevant to the dynamic behaviour of the domain. These symbols then form the alphabet of a VLMM which automatically infers the high level structure of typical interactive behaviour. The learnt behaviour model has generative capabilities and is also capable of recognizing typical or atypical activities within a scene. Experiments have been performed within the traffic monitoring domain; however the proposed method is applicable to the general automatic surveillance task since it does not assume a priori knowledge of a specific domain.
810600AC	Markov models are useful when a decision problem involves risk that is continuous over time, when the timing of events is important, and when important events may happen more than once. Representing such clinical settings with conventional decision trees is difficult and may require unrealistic simplifying assumptions. Markov models assume that a patient is always in one of a finite number of discrete health states, called Markov states. All events are represented as transitions from one state to another. A Markov model may be evaluated by matrix algebra, as a cohort simulation, or as a Monte Carlo simulation. A newer representation of Markov models, the Markov-cycle tree, uses a tree representation of clinical events and may be evaluated either as a cohort simulation or as a Monte Carlo simulation. The ability of the Markov model to represent repetitive events and the time dependence of both probabilities and utilities allows for more accurate representation of clinical settings that involve these issues. 
7E33249D	Smoking cessation is the only strategy that has shown a lasting reduction in the decline of lung function in patients with chronic obstructive pulmonary disease. This study aims to evaluate the cost-effectiveness of smoking cessation interventions in patients with chronic obstructive pulmonary disease, to assess the quality of the Markov models and to estimate the consequences of model structure and input data on cost–effectiveness. A systematic literature search was conducted in PubMed, Embase, BusinessSourceComplete and Econlit on June 11, 2014. Data were extracted, and costs were inflated. Model quality was evaluated by a quality appraisal, and results were interpreted. Ten studies met the inclusion criteria. The results varied widely from cost savings to additional costs of €17,004 per quality adjusted life year. The models scored best in the category structure, followed by data and consistency. The quality of the models seems to rise over time, and regarding the results there is no economic reason to refuse the reimbursement of any smoking cessation intervention 
81507EC1	In this paper, we present a tracking framework for capturing articulated human motions in real-time, without the need for attaching markers onto the subject's body. This is achieved by first obtaining a low dimensional representation of the training motion data, using a nonlinear dimensionality reduction technique called back-constrained GPLVM. A prior dynamics model is then learnt from this low dimensional representation by partitioning the motion sequences into elementary movements using an unsupervised EM clustering algorithm. The temporal dependencies between these elementary movements are efficiently captured by a Variable Length Markov Model. The learnt dynamics model is used to bias the propagation of candidate pose feature vectors in the low dimensional space. By combining this with an efficient volumetric reconstruction algorithm, our framework can quickly evaluate each candidate pose against image evidence captured from multiple views. We present results that show our system can accurately track complex structured activities such as ballet dancing in real-time.
804AD709	Most epidemiological studies of major depression report estimates of period prevalence. Such estimates are useful for public health applications, but are not very helpful for informing clinical practice. Period prevalence is determined predominantly by incidence and episode duration, but it is difficult to connect these epidemiological concepts to clinical issues such as risk and prognosis. Incidence is important for primary and secondary prevention, and prognostic information is useful for clinical decision-making. The objective of this study was to decompose period prevalence data for major depression into its constituent elements, thereby enhancing the value of these estimates for clinical practice. Data from a series of population-based Canadian studies were used in the analysis. Markov models depicting incidence, prevalence and recovery from major depressive episodes were developed. Monte Carlo simulation was used to constrain model parameters to the epidemiological data.The association of sex with major depression was found to be due to a higher incidence in women. In distinction, the higher prevalence in unmarried subjects was mostly due to a different prognosis. Age-related changes in prevalence were influenced by both factors. Education, which was not found to be associated with major depression in the survey data, had no impact either on risk or prognosis.The period prevalence of major depression is influenced both by incidence (risk) and episode duration (prognosis). Mathematical modeling of the underlying epidemiological relationships can make such data more readily interpretable in relation to clinical practice.
7EA1B380	A formula for the go-back-N ARQ (automatic repeat request) scheme applicable to Markov error patterns is derived. It is a generalization of the well-known efficiency formula p/(p+m(1-p)) (where m is the round trip delay in number of block durations and p is the block transmission success probability), and it has been successfully validated against simulation measurements. It is found that for a given error rate, error patterns having zero correlation between successive transmission generally fare better than those with negative correlation, and that error patterns with positive correlation fare better still. It is shown that the present analysis can be extended in a straightforward manner to cope with error patterns of a more complex nature. Simple procedures for numerical evaluation of efficiency under quite general error structures are presented.
7E8549A3	Markov models are often employed to represent stochastic processes, that is, random processes that evolve over time. In a healthcare context, Markov models are particularly suited to modelling chronic disease. In this article, we describe the use of Markov models for economic evaluation of healthcare interventions. The intuitive way in which Markov models can handle both costs and outcomes make them a powerful tool for economic evaluation modelling. The time component of Markov models can offer advantages of standard decision tree models, particularly with respect to discounting. This paper gives a comprehensive description of Markov modelling for economic evaluation, including a discussion of the assumptions on which the type of model is based, most notably the memoryless quality of Markov models often termed the 'Markovian assumption'. A hypothetical example of a drug intervention to slow the progression of a chronic disease is employed to demonstrate the modelling technique and the possible methods of analysing Markov models are explored. Analysts should be aware of the limitations of Markov models, particularly the Markovian assumption, although the adept modeller will often find ways around this problem.
7F8D3B50	In recent years there has been an increased interest in the modelling and recognition of human activities involving highly structured and semantically rich behaviour such as dance, aerobics, and sign language. A novel approach is presented for automatically acquiring stochastic models of the high-level structure of an activity without the assumption of any prior knowledge. The process involves temporal segmentation intoplausible atomic behaviour com-ponents and the use of variable length Markov models for the efficient rep-resentation of behaviours. Experimental results are presented which demon-strate the generation of realistic sample behaviours and evaluate the perfor-mance of models for long-term temporal prediction.
7F79AB85	This paper investigates the properties of a method for obtaining Markov models of unspecified order to be applied to narrow-band fading channels with additive white Gaussian noise. The models are obtained by applying the context tree pruning algorithm to experimental or simulated sequences. Fading environments are identified in which the extension from first-order to higher order models is justified. The paper presents, as examples, the evaluation of the covariance function and the packet error distribution.
7C7C2B02	To date, decision trees and Markov models have been the most common methods used in pharmacoeconomic evaluations. Both of these techniques lack the flexibility required to appropriately represent clinical reality. In this paper an alternative, more natural, way to model clinical reality — discrete event simulation — is presented and its application is illustrated with a real world example.A discrete event simulation represents the course of disease very naturally, with few restrictions. Neither mutually exclusive branches nor states are required, nor is a fixed cycle. All relevant aspects can be incorporated explicitly and efficiently. Flexibility in handling perspectives and carrying out sensitivity analyses, including structural variations, is incorporated and the entire model can be presented very transparently. The main limitations are imposed by lack of data to fit realistic models.Discrete event simulation, though rarely employed in pharmacoeconomics today, should be strongly considered when carrying out economic evaluations, particularly those aimed at informing policy makers and at estimating the budget impact of a pharmaceutical intervention.
0A7B0D45	Prediction is an important component in a variety of domains in Artificial Intelligence and Machine Learning, in order that Intelligent Systems may make more informed and reliable decisions. Certain domains require that prediction be performed on sequences of events that can typically be modeled as stochastic processes. This work presents Active LeZi, a sequential prediction algorithm that is founded on an Information Theoretic approach, and is based on the acclaimed LZ78 family of data compression algorithms. The efficacy of this algorithm in a typical Smart Environment – the Smart Home, is demonstrated by employing this algorithm to predict device usage in the home. The performance of this algorithm is tested on synthetic data sets that are representative of typical interactions between a Smart Home and the inhabitant.
5D7D351E	Intuitively, any ‘bag of words’ approach in IR should benefit from taking term dependencies into account. Unfortunately, for years the results of exploiting such dependencies have been mixed or inconclusive. To improve the situation, this paper shows how the natural language properties of the target documents can be used to transform and enrich the term dependencies to more useful statistics. This is done in three steps. The term co-occurrence statistics of queries and documents are each represented by a Markov chain. The paper proves that such a chain is ergodic, and therefore its asymptotic behavior is unique, stationary, and independent of the initial state. Next, the stationary distribution is taken to model queries and documents, rather than their initial distributions. Finally, ranking is achieved following the customary language modeling paradigm. The main contribution of this paper is to argue why the asymptotic behavior of the document model is a better representation then just the document’s initial distribution. A secondary contribution is to investigate the practical application of this representation in case the queries become increasingly verbose. In the experiments (based on Lemur’s search engine substrate) the default query model was replaced by the stable distribution of the query. Just modeling the query this way already resulted in significant improvements over a standard language model baseline. The results were on a par or better than more sophisticated algorithms that use fine-tuned parameters or extensive training. Moreover, the more verbose the query, the more effective the approach seems to become.
7A42DD4C	Recently, attention has been focused on spatial databases which combine conventional and spatial data. The need for spatial query languages has been identified in several different application domain as Geographic Information Systems (GISs) and Image Databases. Several extensions to the relational database query language SQL have been proposed to serve as a spatial query language. The large availability on the market place of the relational database technology is the major reason why an SQL-based spatial query language is welcome both from the GIS vendors and the GIS user community. Recent SQL extensions convinced us that it is the right time for working on the standardization of SQL-based spatial query languages. This paper sets a kernel of basic features for the creation of a standard and compares a large number of SQL spatial extensions according to such features.
7559C9A4	This paper proposes an algorithm, called sequence prediction via enhanced episode discovery (SPEED), to predict inhabitant activity in smart homes. SPEED is a variant of the sequence prediction algorithm. It works with the episodes of smart home events that have been extracted based on the on -off states of home appliances. An episode is a set of sequential user activities that periodically occur in smart homes. The extracted episodes are processed and arranged in a finite-order Markov model. A method based on prediction by partial matching (PPM) algorithm is applied to predict the next activity from the previous history. The result shows that SPEED achieves an 88.3% prediction accuracy, which is better than LeZi Update, Active LeZi, IPAM, and C4.5.
7FDEABB6	Continuous queries are used to monitor changes to time varying data and to provide results useful for online decision making. Typically a user desires to obtain the value of some function over distributed data items, for example, to determine when and whether (a) the traffic entering a highway from multiple feed roads will result in congestion in a thoroughfare or (b) the value of a stock portfolio exceeds a threshold. Using the standard Web infrastructure for these applications will increase the reach of the underlying information. But, since these queries involve data from multiple sources, with sources supporting standard HTTP (pull-based) interfaces, special query processing techniques are needed. Also, these applications often have the flexibility to tolerate some incoherency, i.e., some differences between the results reported to the user and that produced from the virtual database made up of the distributed data sources.In this paper, we develop and evaluate client-pull-based techniques for refreshing data so that the results of the queries over distributed data can be correctly reported, conforming to the limited incoherency acceptable to the users.We model as well as estimate the dynamics of the data items using a probabilistic approach based on Markov Chains. Depending on the dynamics of data we adapt the data refresh times to deliver query results with the desired coherency. The commonality of data needs of multiple queries is exploited to further reduce refresh overheads. Effectiveness of our approach is demonstrated using live sources of dynamic data: the number of refreshes it requires is (a) an order of magnitude less than what we would need if every potential update is pulled from the sources, and (b) comparable to the number of messages needed by an ideal algorithm, one that knows how to optimally refresh the data from distributed data sources. Our evaluations also bring out a very practical and attractive tradeoff property of pull based approaches, e.g., a small increase in tolerable incoherency leads to a large decrease in message overheads.
7D5544BA	An intelligent home is likely in the near future. A n important ingredient in an intelligent environment such as a home is prediction - of the next action, the next l ocation, and the next task that an inhabitant is likely to p erform. In this paper we describe our approach to solving the problem of predicting inhabitant behavior in a smart home. We model the inhabitant actions as states in a simple Markov model, then improve the model by supplying it with data from discovered high-level inhabitant tasks. For si mulated data we achieved good accuracy, whereas on real dat a we had marginal performance. We also investigate clust ering of actions and subsequently predict the next action an d the task with hidden Markov models created using the clusters.
00BA8AB5	MUSART is a research project developing and studying new techniques for music information retrieval.The MUSART architecture uses a variety of representations to support multiple search modes. Progress is reported on the use of Markov modeling,melodic contour, and phonetic streams for music retrieval.To enable large-scale databases and more advanced searches, musical abstraction is studied. The MME subsystem performs theme extraction, and two other analysis systems are described that discover structure in audio representations of music.Theme extraction and structure analysis promise to improve search quality and support better browsing and “audio thumbnailing.” Integration of these components within a single architecture will enable scientific comparison of different techniques and, ultimately, their use in combination for improved performance and functionality.
797DF42C	This paper proposes a new approach to combined spatial (Intra) prediction and adaptive transform coding in block-based video and image compression. Context-adaptive spatial prediction from available, previously decoded boundaries of the block, is followed by optimal transform coding of the prediction residual. The derivation of both the prediction and the adaptive transform for the prediction error, assumes a separable first-order Gauss-Markov model for the image signal. The resulting optimal transform is shown to be a close relative of the sine transform with phase and frequencies such that basis vectors tend to vanish at known boundaries and maximize energy at unknown boundaries. The overall scheme switches between the above sine-like transform and discrete cosine transform (per direction, horizontal or vertical) depending on the prediction and boundary information. It is implemented within the H.264/AVC intra mode, is shown in experiments to significantly outperform the standard intra mode, and achieve significant reduction of the blocking effect.
799E3C70	This paper presents a software simulator applicable to multipath fading channels in urban environments of mobile communication networks. The simulator is constructed by a two-state Markov model and several statistical models for simulating the characterizations of different environments. A core idea of the simulator is to construct a Rice distribution-based multipath fading module produced by a modified Gans Doppler power spectrum, and in combination with a Markov model to predict the time-dependent characteristics of packet in different radio circumstances. It can simply predict the packet performance of the future channel and evaluate the relations between the radio channel and the modulation schemes, error control protocols and channel coding. Simulation results demonstrate that it is a reliable and efficient method.
80567ABE	Prediction is an important component in a variety of domains in Artificial Intelligence and Machine Learning,in order that Intelligent Systems may make more informed and reliable decisions. Certain domains require that prediction be performed on sequences of events  that can typically be modeled as stochastic processes. This work presents Active LeZi, a sequential prediction algorithm that is  founded  on  an Information Theoretic approach, and is based on the acclaimed LZ78 family of data compression algorithms. The efficacy of this algorithm in a  typical Smart Environment–the Smart Home, is demonstrated by employing this algorithm to predict device usage in the home. The performance of  this algorithm is tested on synthetic data sets that are representative of typical interactions between a Smart Home and the inhabitant.  
762DB3E0	The measurement of individual single-channel events arising from the gating of ion channels provides a detailed data set from which the kinetic mechanism of a channel can be deduced. In many cases, the pattern of dwells in the open and closed states is very complex, and the kinetic mechanism and parameters are not easily determined. Assuming a Markov model for channel kinetics, the probability density function for open and closed time dwells should consist of a sum of decaying exponentials. One method of approaching the kinetic analysis of such a system is to determine the number of exponentials and the corresponding parameters which comprise the open and closed dwell time distributions. These can then be compared to the relaxations predicted from the kinetic model to determine, where possible, the kinetic constants. We report here the use of a linear technique, linear prediction/singular value decomposition, to determine the number of exponentials and the exponential parameters. Using simulated distributions and comparing with standard maximum-likelihood analysis, the singular value decomposition techniques provide advantages in some situations and are a useful adjunct to other single-channel analysis techniques.
75C9738A	The binding of regulatory proteins to their specific DNA targets determines the accurate expression of the neighboring genes. The in silico prediction of new binding sites in completely sequenced genomes is a key aspect in the deeper understanding of gene regulatory networks. Several algorithms have been described to discriminate against false-positives in the prediction of new binding targets; however none of them has been implemented so far to assist the detection of binding sites at the genomic scale.FITBAR (Fast Investigation Tool for Bacterial and Archaeal Regulons) is a web service designed to identify new protein binding sites on fully sequenced prokaryotic genomes. This tool consists in a workbench where the significance of the predictions can be compared using different statistical methods, a feature not found in existing resources. The Local Markov Model and the Compound Importance Sampling algorithms have been implemented to compute the P-value of newly discovered binding sites. In addition, FITBAR provides two optimized genomic scanning algorithms using either log-odds or entropy-weighted position-specific scoring matrices. Other significant features include the production of a detailed genomic context map for each detected binding site and the export of the search results in spreadsheet and portable document formats. FITBAR discovery of a high affinity Escherichia coli NagC binding site was validated experimentally in vitro as well as in vivo and publishedFITBAR was developed in order to allow fast, accurate and statistically robust predictions of prokaryotic regulons. This feature constitutes the main advantage of this web tool over other matrix search programs and does not impair its performance.
5B14A4B4	Proactive User Interfaces (PUIs) aim at facili- tating the interaction with a user interface, e.g., by highlighting fields or adapting the interface. For that purpose, they need to be able to pre- dict the next user action from the interaction his- tory. In this paper, we give an overview of se- quence prediction algorithms (SPAs) that are ap- plied in this domain, and build upon them to de- velop two new algorithms that base on combin- ing different order Markov models. We iden- tify the special requirements that PUIs pose on these algorithms, and evaluate the performance of the SPAs in this regard. For that purpose, we use three datasets with real usage-data and syn- thesize further data with specific characteristics. Our relatively simple yet efficient algorithm FxL performs extremely well in the domain of SPAs which make it a prime candidate for integration in a PUI. To facilitate further research in this field, we provide a Perl library that contains all presented algorithms and tools for the evaluation. 
80B4014C	The SAM-T04 method for predicting protein structures uses a single protocol across the entire range of targets, from comparative modeling to new folds. This protocol is similar to the SAM-T02 protocol used in CASP5, but has improvements in the iterative search for similar sequences in finding and aligning templates, in creating fragment libraries, in generating protein conformations, and in scoring the conformations. The automatic procedure made some improvements over simply selecting an alignment to the highest-scoring template, and human intervention made substantial improvements over the automatic procedure. The main improvements made by human intervention were from adding constraints to build (or retain) beta-sheets and from splitting multidomain proteins into separate domains. The uniform protocol was moderately successful across the entire range of target difficulty, but was somewhat less successful than other approaches in CASP6 on the comparative modeling targets.
7BCB90E0	Augmenting accurate prediction of channel attenuations can be of immense value in improving the quality of signals at high frequency for satellite communication networks. Such prediction of weather related attenuation factors for the impending weather conditions based on the weather data and the Markovian theory are the main object of this paper. The paper also describes an intelligent weather aware control system (IWACS) that is used to employ the predictions made from Markov model to maintain the quality of service (QoS) in channels that are impacted by rain, gaseous, cloud, fog, and scintillation attenuations. Based on that, a three dimensional relationship is proposed among estimated atmospheric attenuations, propagation angle, and predicted rainfall rate at a given location and operational frequency. This novel method of predicting weather characteristics supplies valuable data for mitigation planning, and subsequently for developing an algorithm to iteratively tune the IWACS by adaptively selecting appropriate channel frequency, modulation, coding, propagation angle, transmission power level, and data transmission rate to improve the satellite's system performance. Some simulation results are presented to show the effectiveness of the proposed scheme. 
7E5073A1	Efficient intra prediction is an important aspect of video coding with high compression efficiency. H.264/AVC applies directional prediction from neighboring pixels on an adjustable block size for local decorrelation. In this paper, we present an extended prediction scheme in the context of H.264/AVC that comprises two additional prediction methods exploiting self-similar properties of the encoded texture. A new macroblock type is implemented, allowing for flexible selection of the available prediction methods for sub-partitions of the macroblock. Depending on the content of the encoded video sequence, substantial gains in rate-distortion performance are achieved. The results may indicate directions towards an enhanced intra coding scheme with improved rate-distortion performance.
7EAB152E	Tropical Pacific sea surface temperatures (SSTs) and the accompanying El Niño–Southern Oscillation phenomenon are recognized as significant components of climate behavior. The atmospheric and oceanic processes involved display highly complicated variability over both space and time. Researchers have applied both physically derived modeling and statistical approaches to develop long-lead predictions of tropical Pacific SSTs. The comparative successes of these two approaches are a subject of substantial inquiry and some controversy. Presented in this article is a new procedure for long-lead forecasting of tropical Pacific SST fields that expresses qualitative aspects of scientific paradigms for SST dynamics in a statistical manner. Through this combining of substantial physical understanding and statistical modeling and learning, this procedure acquires considerable predictive skill. Specifically, a Markov model, applied to a low-order (empirical orthogonal function–based) dynamical system of tropical Pacific SST, with stochastic regime transition, is considered. The approach accounts explicitly for uncertainty in the formulation of the model, which leads to realistic error bounds on forecasts. The methodology that makes this possible is hierarchical Bayesian dynamical modeling.
80846A31	Conditional Random Fields (CRFs) are undirected probabilistic graphical models that were introduced for solving sequence labeling and segmenting problems. CRFs have several advantages compared to other well understood and widely used techniques such as Hidden Markov Models (HMMs) or Maximum Entropy Markov Models (MEMMs). Being a conditional model, it does not explicitly model the input data sequences but uses feature functions (features) to incorporate the arbitrary interactions and inter-dependencies that exist in the observation sequences. The number of all possible features is extremely large, up to millions, and is usually specified and designed in advance or according to a feature-generating scheme based on domain knowledge. This paper introduces a feature subset selection method for CRFs based on genetic algorithms, in which a population of candidate feature function subsets is evolved to achieve a maximal CRF performance. The method was experimentally validated on the well known bioinformatics problem of protein phosphorylation site prediction, phosphorylation being one of the most important protein modification mechanisms.
772EDB8B	A probabilistic graphical model is proposed in order to detect the coevolution between different sites in biological sequences. The model extends the continuous-time Markov process of sequence substitution for single nucleic or amino acids and imposes general constraints regarding simultaneous changes on the substitution rate matrix. Given a multiple sequence alignment for each molecule of interest and a phylogenetic tree, the model can predict potential interactions within or between nucleic acids and proteins. Initial validation of the model is carried out using tRNA and 16S rRNA sequence data. The model accurately identifies the secondary interactions of tRNA as well as several known tertiary interactions. In addition, results on 16S rRNA data indicate this general and simple coevolutionary model outperforms several other parametric and nonparametric methods in predicting secondary interactions. Furthermore, the majority of the putative predictions exhibit either direct contact or proximity of the nucleotide pairs in the 3-dimensional structure of the Thermus thermophilus ribosomal small subunit. The results on RNA data suggest a general model of coevolution might be applied to other types of interactions between protein, DNA, and RNA molecules.
7ABB00FC	Markov modelling offers the possibility of extracting long-term results from dynamic simulations with a significantly reduced execution time over that which would be necessary with an equivalent time-series simulation. The discretization of the problem variables which is necessary for Markov modelling introduces an inaccuracy into the simulation process which means that a balance must be struck between the accuracy required and the time reduction that is possible. The paper describes an approach to the quantification of the errors introduced by discretization of the simulation variables. Two error expressions were tested by running a representative building/HVAC system dynamic model in both time-series and Markov modes with varying degrees of discretization of the variables. A simplified error bound was found useful in identifying near-optimal discretization schemes: further refinement of this approach led to an expression that was found to give a good prediction of the error in Markov simulations of this type of system.	
5E05220A	This paper introduces the concept of Commented Markov Models (CMMs), an extension of the well known Markov Models, together with the relevant induction mechanisms. Given a discrete alphabet Σ and a source producing an input sequence (s1,s2,...,sn) with si ∈ Σ, the task of sequence prediction is to guess the successive sequence element sn+1. Here each element si may represent an object, a discrete event or any other discrete entity. Prediction with CMM is analogy-based. It is assumed that the final part of the input sequence describes the current state of the source. This final part is matched with earlier subsequences of the input, assuming that it will be continued the same way as was the ‘most similar’ subsequence. CMM learning involves the induction of objects, variables and object classes. While object and class creation are similar to the notions of chunking and merging in other grammatical inference approaches, the use of variables is a novel feature of CMM. It not only generalized the way subsequences can be matched, it also turns CMM from a pure sequence prediction algorithm into a computational model. I will show that CMM has sufficient expressiveness to represent any primitive recursive function. Thus it is not only capable of predicting e.g. the character ‘u’ to follow the sequence ‘seq’, but it can also extrapolate a sequence like ‘45+13=’ by calculating the sum ‘58’.
7E4DC75A	We propose a new and effective method of predicting tracking failures and apply it to the robust analysis of gait and human motion. We define a tracking failure as an event and describe its temporal characteristics using a hidden Markov model (HMM). We represent the human body using a three-dimensional, multicomponent structural model, where each component is designed to independently allow the extraction of certain gait variables. To enable a fault-tolerant tracking and feature extraction system, we introduce a single HMM for each element of the structural model, trained on previous examples of tracking failures. The algorithm derives vector observations for each Markov model using the time-varying noise covariance matrices of the structural model parameters. When transformed with a logarithmic function, the conditional output probability of each HMM is shown to have a causal relationship with imminent tracking failures. We demonstrate the effectiveness of the proposed approach on a variety of multiview video sequences of complex human motion.
7E030AE4	A foremost objective in wireless networks is to facilitate the communication of mobile users and the widespread tracking and prediction of their mobility regardless of their point of attachment to the network. In indoor environments the effective users' motion prediction system and wireless localization technology play an important role in all aspects of people's daily lives, including e.g. living assistant, navigation, emergency detection, surveillance/tracking of target-of-interest, evacuation purposes, and many other location-based services. Prediction techniques that are currently used do not consider the motivation behind the movement of mobile nodes and incur huge overheads to manage and manipulate the information required to make predictions. In this paper we propose an activity-based continuous-time Markov model to define and predict the human movement patterns. Then we demonstrate the utility of Nonparametric Belief Propagation (NBP) technique in particle filtering, for both estimating the node locations and representing location uncertainties, and for prediction of the areas that would be visited and those that would not in the future. NBP method admits a wide variety of statistical models, and can represent multi-modal uncertainty. This prediction system may be used as an additional input into intelligent building automation systems.
5C2535CD	In this paper, we present a new search algorithm for sequential labeling tasks based on the conditional Markov models (CMMs) frameworks. Unlike conventional beam search, our method traverses all possible incoming arcs and also considers the “local best” so-far of each previous node. Furthermore, we propose two heuristics to fit the efficiency requirement. To demonstrate the effect of our method, six variant and large-scale sequential labeling tasks were conducted in the experiment. In addition, we compare our method to Viterbi and Beam search approaches. The experimental results show that our method yields not only substantial improvement in runtime efficiency, but also slightly better accuracy. In short, our method achieves 94.49 F(β) rate in the well-known CoNLL-2000 chunking task.
7D89C765	Web based learning systems provides huge volume of educational content to learners. However, a single learner might not be interested in learning all the contents delivered. To encourage learners of varying skill sets and to develop learning interests web recommendation system is needed for web based learning. This paper focuses on providing recommendations to learners as well as web masters to improve overall effectiveness of web based teaching and learning. This work deals with analysis of web log data and development of recommendation framework using web usage mining techniques like upper approximation based rough set clustering using k nearest neighbors, dynamic support pruned all k-th order Markov model and all k-th order association rule mining by dynamic frequent (k+1) item set generation using Apriori. The goal of this integrated approach is to make accurate recommendations for learning management systems with reduced state space complexity
81018323	We use several approaches to demonstrate that neural networks can detect precursors to failure. That is, they can detect subtle changes in the process signals. In some cases these subtle changes are early warnings that a subsystem failure is imminent. The results on detection of precursors and faults with various types of time-delay neural networks are discussed. We also measure the noise inherent in our database and place bounds on neural network prediction in the presence of noise. We observe that the noise level can be as high as 40% for detection of failures and can be at 30% to still detect precursors to failure. We note that although self-organizing networks for classification of faults seems like a good idea, in fact they do not perform well in the presence of noise. Lastly, we show that neural networks can induce, or self-build, Markov models from process data and these models can be used to predict system state to a significant distance in the future (e.g., 100 wafers).
7E714964	In this paper, we present a stream-based mining algorithm for online anomaly prediction. Many real-world applications such as data stream analysis requires continuous cluster operation. Unfortunately, today's large-scale cluster systems are still vulnerable to various software and hardware problems. System administrators are often overwhelmed by the tasks of correcting various system anomalies such as processing bottlenecks (i.e., full stream buffers), resource hot spots, and service level objective (SLO) violations. Our anomaly prediction scheme raises early alerts for impending system anomalies and suggests possible anomaly causes. Specifically, we employ Bayesian classification methods to capture different anomaly symptoms and infer anomaly causes. Markov models are introduced to capture the changing patterns of different measurement metrics. More importantly, our scheme combines Markov models and Bayesian classification methods to predict when a system anomaly will appear in the foreseeable future and what are the possible anomaly causes. To the best of our knowledge, our work provides the first stream-based mining algorithm for predicting system anomalies. We have implemented our approach within the IBM System S distributed stream processing cluster, and conducted case study experiments using fully implemented distributed data analysis applications processing real application workloads. Our experiments show that our approach efficiently predicts and diagnoses several bottleneck anomalies with high accuracy while imposing low overhead to the cluster system.
7DBF6696	The Markov model has been applied to many prediction applications including the student models of intelligent tutoring systems. In this paper, we extend this well-known model to the weighted Markov model, and then apply it to student models in order to predict student behaviors. The prediction using our models is based not only on the frequency of collective behaviors of previous users, but also on the degrees of the relations between the predicted user and others. In doing so, a novel way is presented to quantify the similarities between previous students and the current active student. These similarity scores will be used as weights in the weighted Markov model.
80105513	With the introduction of dynamic image processing, such as in image analysis, the computational complexity has become data dependent and memory usage irregular. Therefore, the possibility of runtime estimation of resource usage would be highly attractive and would enable Quality-of-Service (QoS) control for dynamic image-processing applications with shared resources. A possible solution to this problem is to characterize the application execution using model descriptions of the resource usage. In this paper, we attempt to predict resource usage for groups of dynamic image-processing tasks based on Markov-chain modeling. As a typical application, we explore a medical imaging application to enhance a wire mesh tube (stent) under X-ray fluoroscopy imaging during angioplasty. Simulations show that Markov modeling can be successfully applied to describe the resource usage function even if the flow graph dynamically switches between groups of tasks. For the evaluated sequences, an average prediction accuracy of 97% is reached with sporadic excursions of the prediction error up to 20–30%.
7DC8E808	A research area that has become increasingly important in recent years is that of on-board mobile communication, where users on a vehicle are connected to a local network that attaches to the Internet via a mobile router and a wireless link. In this architecture, link disruptions (e.g., due to signal degradation) may have an immediate impact on a potentially large number of connections. We argue that the advance knowledge of public transport routes, and their repetitive nature, allows a certain degree of prediction of impending link disruptions, which can be used to offset their catastrophic impact. Focusing on the transmission control protocol (TCP) and its extension known as Freeze-TCP, we present a detailed analysis of the performance improvement of TCP connections in the presence of disruption prediction. In particular, we propose a Markov model of Freeze-TCP that captures both the TCP behavior and the prediction+"freezing" feature and, using simulations, show that it accurately predicts the performance of the protocol. Our results demonstrate the significant throughput improvement that can be gained by disruption prediction, even with random packet losses or imperfect timing of the predicted disruptions
80739C5A	Spectrum sensing is one of the key functionalities in cognitive radios which enables opportunistic spectrum access. In a cognitive radio system, secondary users need to detect the emergence of primary users as soon as possible to avoid harmful interference. In particular, sensing performance can be evaluated by detection delay and sensing overhead. Sequential detection techniques such as quickest detection can achieve minimum detection delay, while MAC layer sensing scheduling of periodic energy detection has demonstrated its high sensing efficiency. These motivate us to propose a joint PHY-MAC spectrum sensing algorithm in this letter, which employs sequential probability ratio test in the PHY layer and a probability-based sensing scheduling mechanism in the MAC layer. This algorithm can minimize detection delay with limited sensing overhead. Simulation results reveal that it has remarkable performance improvement compared with periodic energy detection.
793EC21A	We consider the prediction of new observations in a general Gauss–Markov model. We state the fundamental equations of the best linear unbiased prediction, BLUP, and consider some properties of the BLUP. Particularly, we focus on such linear statistics, which preserve enough information for obtaining the BLUP of new observations as a linear function of them. We call such statistics linearly prediction sufficient for new observations, and introduce some equivalent characterizations for this new concept.	
07027B17	Markov models have been a keystone in Artificial Intelligence for many decades. However, they remain unsatisfactory when the environment modelled is partially observable. There are pathological examples where no history of fixed length is sufficient for accurate prediction or decision making. On the other hand, working with a hidden state (like in Hidden Markov Models or Partially Observable Markov Decision Processes) has a high computational cost. In order to circumvent this problem, we suggest the use of a context-based model. Our approach replaces strict transition probabilities by influences on transitions. The method proposed provides a trade-off between a fully and partially observable model. We also discuss the capacity of our framework to model hierarchical knowledge and abstraction. Simple examples are given in order to show the advantages of the algorithm.
769C66A6	Understanding and modeling user online behavior, as well as predicting future requests remain an open challenge for researchers, analysts and marketers. In this paper, we propose an efficient prediction schema based on the extraction of sequential navigation patterns from server log files, combined with web site topology. Traversed paths are monitored, internally recorded and cleaned before being completed with cashed page views. After session and episode identification follows the construction of n-grams. Prediction is based upon a 5 + n-gram schema with all lower level n-grams participating, a procedure that resembles the construction of an All 5th-order Markov Model. The schema achieves full coverage while maintaining competitive prediction precision.
7852BB29	A novel multi-layer perceptrons (MLP)-based speech recognition method is proposed in this study. In this method, the dynamic time warping capability of hidden Markov models (HMM) is directly combined with the discriminant based learning of MLP for the sake of employing a sequence of MLPs (SMLP) as a word recognizer. Each MLP is regarded as a state recognizer to distinguish an acoustic event. Next, the word recognizer is formed by serially cascading all state recognizers. Advantages of both HMM and MLP methods are attained in this system through training the SMLP with an algorithm which combines a dynamic programming (DP) procedure with a generalized probabilistic descent (GPD) algorithm. Additionally, two sub-syllable SMLP-based schemes are studied through application of this method toward the recognition of isolated Mandarin digits. Simulation results confirm that the performance of the method is comparable to a well modeled continuous Gaussian mixture density HMM trained with the minimum error criterion. Not only does the SMLP require less trainable parameters than the HMM system, but the former is more convenient for analysing internal features. With the aid of internal feature selection, discarding the least useful parameters of SMLP without affecting its performance is relatively easy.
