76AFCB1F	This paper describes the application of the newly introduced Continuous Ant Colony Optimization Algorithm (CACOA) to optimal design of sewer networks. Two alternative approaches to implement the algorithm is presented and applied to a storm sewer network in which the nodal elevations of the network are considered as the decision variables of the optimization problem. In the first and unconstrained approach, a Gaussian probability density function is used to represent the pheromone concentration over the allowable range of each decision variable. The pheromone concentration function is used by each ant to randomly sample the nodal elevations of the trial networks. This method, however, will lead to solutions which may be infeasible regarding some or all of the constraints of the problem and in particular the minimum slope constraint. In the second and constrained approach, known value of the elevation at downstream node of a pipe is used to define new bounds on the elevation of the upstream node satisfying the explicit constraints on the pipe slopes. Two alternative formulations of the constrained algorithm are used to solve a test example and the results are presented and compared with those of unconstrained approach. The methods are shown to be very effective in locating the optimal solution and efficient in terms of the convergence characteristics of the resulting algorithms. The proposed algorithms are also found to be relatively insensitive to the initial colony and size of the colony used compared to the original algorithm.
7BFB8D91	Considering that the particle swarm optimization (PSO) algorithm has a tendency to get stuck at the local solutions, an improved PSO algorithm is proposed in this paper to solve constrained optimization problems. In this algorithm, the initial particle population is generated using good point set method such that the initial particles are uniformly distributed in the optimization domain. Then, during the optimization process, the particle population is divided into two sub-populations including feasible sub-population and infeasible sub-population. Finally, different crossover operations and mutation operations are applied for updating the particles in each of the two sub-populations. The effectiveness of the improved PSO algorithm is demonstrated on three benchmark functions.
7933BEEC	Artificial Bee Colony algorithm is an optimization algorithm based on the intelligent behavior of honey bee swarm. This paper presents Bee Swarm Optimization intended to introduce chaotic sequences into the algorithm. On the basis of Artificial Bee Colony Optimization Algorithm, a new algorithm by introducing constructing dynamic penalty function and chaotic sequences was presented. Based on Matlab software, the program CABCOA1.0 with hybrid discrete variables for the proposed algorithm was developed. The complex mechanical optimization was given. The results show that this algorithm has no special requirements on the characteristics of optimal designing problems, which has a fairly good universal adaptability and a reliable operation of program with a strong ability of overall convergence.
7781EAC6	Differential evolution (DE) is a simple and powerful evolutionary algorithm for global optimization. DE with constraint handling techniques, named constrained differential evolution (CDE), can be used to solve constrained optimization problems (COPs). In existing CDEs, the parents are randomly selected from the current population to produce trial vectors. However, individuals with fitness and diversity information should have more chances to be selected. This study proposes a new CDE framework that uses nondominated sorting mutation operator based on fitness and diversity information, named MS-CDE. In MS-CDE, firstly, the fitness of each individual in the population is calculated according to the current population situation. Secondly, individuals in the current population are ranked according to their fitness and diversity contribution. Lastly, parents in the mutation operators are selected in proportion to their rankings based on fitness and diversity. Thus, promising individuals with better fitness and diversity are more likely to be selected as parents. The MS-CDE framework can be applied to most CDE variants. In this study, the framework is applied to two popular representative CDE variants, (μ + λ)-CDE and ECHT-DE. Experiment results on 24 benchmark functions from CEC’2006 and 18 benchmark functions from CEC’2010 show that the proposed framework is an effective approach to enhance the performance of CDE algorithms.
7DF987AF	This paper presents a global optimization method based on the statistical genetic algorithm for solving nonlinear bilevel programming problems. The bilevel programming problem is firstly transformed into a single level problem by applying Karush-Kuhn-Tucker conditions, and then an efficient method based on the statistical genetic algorithm has been proposed for solving the single level problem with the complementarity constraints. By certain handling tech- nology, the simplified problem without the complementarity constraints can be gotten. If it is solvable then its optimal solution is a feasible solution of the original bilevel pro- gramming problem. At last, a global optimal solution of the original problem can be found among its feasible solutions. Numerical experiments on some benchmark problems show that the new algorithm can find global optimal solutions of the bilevel programming problems in a small number of fit- ness evaluations.
78783172	The slow convergence speed and the lack of effective constraint handling strategies are the major concerns when applying genetic algorithms (Gas) to constrained optimization problem. An improved genetic algorithm was proposed by dividing population into three parts: optimal subpopulation, elitists subpopulation and spare subpopulation. We applied genetic algorithm on three subpopulations with different evolutionary strategies. Isolation of optimal subpopulation was to improve convergence speed. Population diversity was kept by spare subpopulation setting and aperiodically decreasing of the size of optimal subpopulation. Gene segregation was carried out by crossover operation between optimal subpopulation and spare subpopulation. Combination of penalty function method and the strategy of elitists preservation by setting elitists subpopulation was used to constraint handling. Some numerical tests have been made and the results show that the algorithm is effective.
7863E9A7	To efficiently optimize the constrained engineering problems, in this paper, an improved constrained differential evolution (DE) method is proposed, where two improvements are presented. Firstly, to make the DE algorithm converge faster, a ranking-based mutation operator that is suitable to the constrained optimization problems is presented. Secondly, an improved dynamic diversity mechanism is proposed to maintain either infeasible or feasible solutions in the population. Combining the two improvements with the DE algorithm, the proposal is referred to as rank-iMDDE, for short. To evaluate the performance of rank-iMDDE, 24 benchmark functions presented in CEC’2006 are selected as the test suite. Moreover, five widely used constrained engineering benchmark problems and four constrained mechanical design problems from the literature are chosen to test the capability of rank-iMDDE for the engineering problems. Experimental results indicate that rank-iMDDE is able to improve the performance of DE in terms of the quality of the final solutions, the convergence rate, and the successful rate. Additionally, it can provide fairly-competitive results compared with other state-of-the-art evolutionary algorithms in both benchmark functions and engineering problems.
805BE90F	Boolean Satisfiability (SAT) has successfully been applied to the FPGA routing. It has many advantages over the conventional one-net-a-time routing algorithm such as routing all nets concurrently, higher flexibility and unroutability provable. However it also has the limits of scalability and is time-consuming. This paper presents some optimizations to the SAT-based routing approach by applying some architecture related features to the generated the Boolean constraints function. Specifically, Switch Box based connectivity optimization to reduce the variable number for each net, Logic Block pins rearrangement to improve the flexibility for each net and Exclusivity constraints optimization based on net-to-track distribution. Each of the optimizations is discussed in detail in this paper. Some heuristics and algorithms are also presented to implement the optimizations. We implement the SAT-based routing strategy as well as the optimizations on a general hierarchical FPGA architecture. The experimental results show that we can greatly reduce the variable and constraint number of the generated Boolean SAT functions. Hence, the generated SAT functions can be solved much more quickly. It also shows that high routing flexibility is also achieved due to the pins rearrangement.
7D9D105C	This paper proposes a hybrid algorithm for solving constrained semi-infinite optimization problems. It is based on a partially elitistic genetic algorithm which uses an interval procedure to compute penalty terms in constructing the fitness function. Due to the deterministic nature of the interval procedure, which globally converges with certainty, a robust overall algorithm is obtained. This hybrid algorithm is applied, reporting computational results, to the optimal PID controller design for H/sub 2/ minimax control of an uncertain plant.
7CFC5C89	We consider bang-bang control problems with state inequality constraints. It is shown that the control problem induces an optimization problem where the optimization vector consists of all switching times of the bang-bang control and junction times with boundary arcs. The induced optimization problem is a generalization of the one studied in [1], [19]. [20], [22] for bang-bang controls without state constraints. We develop second order sufficient conditions (SSC) for the state-constrained control problem which require that (1) the SSC for the induced optimization problem are satisfied and (2) additional conditions for the switching function hold at switching and junction times. An optimization algorithm is presented which simultaneously carries out the second-order test. The algorithm is illustrated on a numerical example in cancer chemotherapy.
80CE94A2	In this paper, we present an effective dynamical evolutionary algorithm (DEA) to handle constrained optimization problems. The novelty of DEA is that we design a new select mechanism based on the principle of energy minimization of statistical mechanics. The algorithm has been evaluated numerically using several benchmark problems. The numerical results show our approach is superior to any other published results known by the authors.
6847DC12	The goal of an evolutionary algorithm (EA) is to find the global optimum in a state space of potential solutions. But these systems can become trapped in local optima due to the EA having only generational information. Using the scouting algorithm (SA) it is suggested that a cross-generation memory mechanism can be added to modulate fitness relative to how well a region has previously been sampled. Thus, the goal is to allow the scouting-inspired EA (SEA) to leave well explore regions to find the global optimum more quickly. It will be shown that the SEA does achieve this goal for the problem domain of nonlinear programming (NLP).
756FEDB0	Uncertainties are commonly present in optimization systems, and when they are considered in the design stage, the problem usually is called a robust optimization problem. Robust optimization problems can be treated as noisy optimization problems, as worst case minimization problems, or by considering the mean and standard deviation values of the objective and constraint functions. The worst case scenario is preferred when the effects of the uncertainties on the nominal solution are critical to the application under consideration. Based on this worst case scenario, we developed the [I]RMOEA (Interval Robust Multi-Objective Evolutionary Algorithm), a hybrid method that combines interval analysis techniques to deal with the uncertainties in a deterministic way and a multi-objective evolutionary algorithm. We introduce [I]RMOEA and illustrate it on three robust test functions based on the ZDT problems. The results show that [I]RMOEA is an adequate way of tackling robust optimization problems with evolutionary techniques taking advantage of the interval analysis framework.
764E6F4F	In this paper, the results for the CEC 2010 Competition and Special Session on Constrained Real-Parameter Optimization using the multiobjective differential evolution algorithm with spherical pruning (sp-MODE) are presented. According to the obtained results, the sp-MODE shows to be able to find feasible solutions in highly constrained search spaces.
7C48D3D1	The emergence of metamodels as approximate objective function representations offers the ability to ‘design’ metamodels with favourable optimization characteristics without compromising the accurate representational capabilities of arbitrary function topologies and modalities. With non-uniform rational B-splines (NURBs) as a metamodel basis, favourable optimization properties can be obtained which allow the intelligent selection of starting points for multistart optimization algorithms and which constrain optimization searches to metamodel regions containing the global metamodel optimum. In this article NURBs-based metamodels are used to define an optimization algorithm (HyPerOp) which guarantees the discovery of the global metamodel optimum with known computational effort. Emphasis is placed on demonstrating how NURBs’ properties contribute to a favourable objective function approximation. Through a large non-linear optimization trial problem set, the claim that HyPerOp is guaranteed to find the global metamodel optimum is demonstrated and the performance of HyPerOp with respect to random multistart approaches is evaluated.
76DE3510	In this paper, the well-known Procrustes problem is reconsidered. The usual least squares objective function is replaced by more robust one, based on a smooth approximation of the l1 matrix norm. This smooth approximation to the l1 Procrustes problem is solved making use of the projected gradient method. The Procrustes problem with partially specified target is treated and solved as well. Several classical numerical examples from factor analysis (well-known with their least squares Procrustes solutions) are solved with respect to the smooth approximation of the l1 matrix norm goodness-of-fit measure.
7A24356F	In this paper, the problem of finding good wordlength combinations for fixed-point digital signal processing flowgraphs is addressed. By formulating and solving an approximate optimization problem, an estimated Pareto-optimal curve for attainable cost/quality combinations is rapidly calculated. This curve and the associated wordlength combinations are useful in several situations and can serve as starting points for real design searches. Examples that illustrate these concepts are given.
815CBE33	In this paper, we propose a generic, two-phase framework for solving constrained optimization problems using genetic algorithms. In the first phase of the algorithm, the objective function is completely disregarded and the constrained optimization problem is treated as a constraint satisfaction problem. The genetic search is directed toward minimizing the constraint violation of the solutions and eventually finding a feasible solution. A linear rank-based approach is used to assign fitness values to the individuals. The solution with the least constraint violation is archived as the elite solution in the population. In the second phase, the simultaneous optimization of the objective function and the satisfaction of the constraints are treated as a biobjective optimization problem. We elaborate on how the constrained optimization problem requires a balance of exploration and exploitation under different problem scenarios and come to the conclusion that a nondominated ranking between the individuals will help the algorithm explore further, while the elitist scheme will facilitate in exploitation. We analyze the proposed algorithm under different problem scenarios using Test Case Generator-2 and demonstrate the proposed algorithm's capability to perform well independent of various problem characteristics. In addition, the proposed algorithm performs competitively with the state-of-the-art constraint optimization algorithms on 11 test cases which were widely studied benchmark functions in literature.
7D12ED2B	A considerable number of constrained optimization evolutionary algorithms (COEAs) have been proposed due to increasing interest in solving constrained optimization problems (COPs) by evolutionary algorithms (EAs). In this paper, we first review existing COEAs. Then, a novel EA for constrained optimization is presented. In the process of population evolution, our algorithm is based on multiobjective optimization techniques, i.e., an individual in the parent population may be replaced if it is dominated by a nondominated individual in the offspring population. In addition, three models of a population-based algorithm-generator and an infeasible solution archiving and replacement mechanism are introduced. Furthermore, the simplex crossover is used as a recombination operator to enrich the exploration and exploitation abilities of the approach proposed. The new approach is tested on 13 well-known benchmark functions, and the empirical evidence suggests that it is robust, efficient, and generic when handling linear/nonlinear equality/inequality constraints. Compared with some other state-of-the-art algorithms, our algorithm remarkably outperforms them in terms of the best, mean, and worst objective function values and the standard deviations. It is noteworthy that our algorithm does not require the transformation of equality constraints into inequality constraints
7DF3B624	In this paper, an adaptive tradeoff model (ATM) is proposed for constrained evolutionary optimization. In this model, three main issues are considered: (1) the evaluation of infeasible solutions when the population contains only infeasible individuals; (2) balancing feasible and infeasible solutions when the population consists of a combination of feasible and infeasible individuals; and (3) the selection of feasible solutions when the population is composed of feasible individuals only. These issues are addressed in this paper by designing different tradeoff schemes during different stages of a search process to obtain an appropriate tradeoff between objective function and constraint violations. In addition, a simple evolutionary strategy (ES) is used as the search engine. By integrating ATM with ES, a generic constrained optimization evolutionary algorithm (ATMES) is derived. The new method is tested on 13 well-known benchmark test functions, and the empirical results suggest that it outperforms or performs similarly to other state-of-the-art techniques referred to in this paper in terms of the quality of the resulting solutions.
80950C3E	Constrained optimization problems are very important and frequently appear in the real world. The /spl alpha/ constrained method is a new transformation method for constrained optimization. In this method, a satisfaction level for the constraints is introduced, which indicates how well a search point satisfies the constraints. The /spl alpha/ level comparison, which compares search points based on their level of satisfaction of the constraints, is also introduced. The /spl alpha/ constrained method can convert an algorithm for unconstrained problems into an algorithm for constrained problems by replacing ordinary comparisons with the /spl alpha/ level comparisons. In this paper, we introduce some improvements including mutations to the nonlinear simplex method to search around the boundary of the feasible region and to control the convergence speed of the method, we apply the /spl alpha/ constrained method and we propose the improved /spl alpha/ constrained simplex method for constrained optimization problems. The effectiveness of the /spl alpha/ constrained simplex method is shown by comparing its performance with that of the stochastic ranking method on various constrained problems.
80CEAFD2	A self-adaptive fitness formulation is presented for solving constrained optimization problems. In this method, the dimensionality of the problem is reduced by representing the constraint violations by a single infeasibility measure. The infeasibility measure is used to form a two-stage penalty that is applied to the infeasible solutions. The performance of the method has been examined by its application to a set of eleven test cases from the specialized literature. The results have been compared with previously published results from the literature. It is shown that the method is able to find the optimum solutions. The proposed method requires no parameter tuning and can be used as a fitness evaluator with any evolutionary algorithm. The approach is also robust in its handling of both linear and nonlinear equality and inequality constraint functions. Furthermore, the method does not require an initial feasible solution.
803AD671	Penalty functions are often used in constrained optimization. However, it is very difficult to strike the right balance between objective and penalty functions. This paper introduces a novel approach to balance objective and penalty functions stochastically, i.e., stochastic ranking, and presents a new view on penalty function methods in terms of the dominance of penalty and objective functions. Some of the pitfalls of naive penalty methods are discussed in these terms. The new ranking method is tested using a (/spl mu/, /spl lambda/) evolution strategy on 13 benchmark problems. Our results show that suitable ranking alone (i.e., selection), without the introduction of complicated and specialized variation operators, is capable of improving the search performance significantly.
7D50A3D9	A novel two-phase neural network that is suitable for solving a large class of constrained or unconstrained optimization problem is presented. For both types of problems with solutions lying in the interior of the feasible regions, the phase-one structure of the network alone is sufficient. When the solutions of constrained problems are on the boundary of the feasible regions, the proposed two-phase network is capable of achieving the exact solutions, in contrast to existing optimization neural networks which can obtain only approximate solutions. Furthermore, the network automatically provides the corresponding Lagrange multiplier associated with each constraint. Thus, for linear programming, the network solves both the primal problems and their dual problems simultaneously.
7F458CEE	Variants of simplex-based methodologies are generally used to solve underlying linear programming (LP) problems. An implementation of the dual affine (DA) algorithm (a variant of N. Karmarkar's (1984) interior point method) is described in detail and some computational results are presented. This algorithm is particularly suitable for problems with a large number of constraints, and is applicable to linear and nonlinear optimization problems. In contrast with the simplex method, the number of iterations required by the DA algorithm to solve large-scale problems is relatively small. The DA algorithm has been implemented considering the sparsity of the constraint matrix. The normal equation that is required to be solved in every iteration is solved using a preconditioned conjugate gradient method. An application of the technique to a hydro-scheduling is presented; the largest problem is solved over nine times faster than an efficient simplex (MINOS) code. A new heuristic basis recovery procedure is implemented to provide primal and dual optimal basic solutions which are not generally available if interior point methods are used. The tested examples indicate that this new approach requires less than 10% of the original iterations of the simplex method to find the optimal basis.
7EACE9C0	A new framework for designing robust adaptive filters is introduced. It is based on the optimization of a certain cost function subject to a time-dependent constraint on the norm of the filter update. Particularly, we present a robust variable step-size NLMS algorithm which optimizes the square of the a posteriori error. We also show the link between the proposed algorithm and another one derived using a robust statistics approach. In addition, a theoretical model for predicting the transient and steady-state behavior and a proof of almost sure filter convergence are provided. The algorithm is then tested in different environments for system identification and acoustic echo cancelation applications.
8036643A	There exist many recurrent neural networks for solving optimization-related problems. In this paper, we present a method for deriving such networks from existing ones by changing connections between computing blocks. Although the dynamic systems may become much different, some distinguished properties may be retained. One example is discussed to solve variational inequalities and related optimization problems with mixed linear and nonlinear constraints. A new network is obtained from two classical models by this means, and its performance is comparable to its predecessors. Thus, an alternative choice for circuits implementation is offered to accomplish such computing tasks.
7D5A1501	This paper presents a novel evolutionary algorithm (EA) for constrained optimization problems, i.e., the hybrid constrained optimization EA (HCOEA). This algorithm effectively combines multiobjective optimization with global and local search models. In performing the global search, a niching genetic algorithm based on tournament selection is proposed. Also, HCOEA has adopted a parallel local search operator that implements a clustering partition of the population and multiparent crossover to generate the offspring population. Then, nondominated individuals in the offspring population are used to replace the dominated individuals in the parent population. Meanwhile, the best infeasible individual replacement scheme is devised for the purpose of rapidly guiding the population toward the feasible region of the search space. During the evolutionary process, the global search model effectively promotes high population diversity, and the local search model remarkably accelerates the convergence speed. HCOEA is tested on 13 well-known benchmark functions, and the experimental results suggest that it is more robust and efficient than other state-of-the-art algorithms from the literature in terms of the selected performance metrics, such as the best, median, mean, and worst objective function values and the standard deviations
75E3F2F2	This paper presents a novel Constrained Optimization based on Modified Differential Evolution algorithm (COMDE). In the new algorithm, a new directed mutation rule, based on the weighted difference vector between the best and the worst individuals at a particular generation, is introduced. The new directed mutation rule is combined with the modified basic mutation strategy DE/rand/1/bin, where only one of the two mutation rules is applied with the probability of 0.5. The proposed mutation rule is shown to enhance the local search ability of the basic Differential Evolution (DE) and to get a better trade-off between convergence rate and robustness. Two new scaling factors are introduced as uniform random variables to improve the diversity of the population and to bias the search direction. Additionally, a dynamic non-linear increased crossover probability is utilized to balance the global exploration and local exploitation. COMDE also includes a modified constraint handling technique based on feasibility and the sum of constraints violations. A new dynamic tolerance technique to handle equality constraints is also adopted. The effectiveness and benefits of the new directed mutation strategy and modified basic strategy used in COMDE has been experimentally investigated. The effect of the parameters of the crossover probability function and the parameters of the dynamic tolerance equation on the performance of COMDE have been analyzed and evaluated by different experiments. Numerical experiments on 13 well-known benchmark test functions and five engineering design problems have shown that the new approach is efficient, effective and robust. The comparison results between the COMDE and the other 28 state-of-the-art evolutionary algorithms indicate that the proposed COMDE algorithm is competitive with, and in some cases superior to, other existing algorithms in terms of the quality, efficiency, convergence rate, and robustness of the final solution.
7CBCC9CE	Motivated by the recent success of diverse approaches based on differential evolution (DE) to solve constrained numerical optimization problems, in this paper, the performance of this novel evolutionary algorithm is evaluated. Three experiments are designed to study the behavior of different DE variants on a set of benchmark problems by using different performance measures proposed in the specialized literature. The first experiment analyzes the behavior of four DE variants in 24 test functions considering dimensionality and the type of constraints of the problem. The second experiment presents a more in-depth analysis on two DE variants by varying two parameters (the scale factor F and the population size NP), which control the convergence of the algorithm. From the results obtained, a simple but competitive combination of two DE variants is proposed and compared against state-of-the-art DE-based algorithms for constrained optimization in the third experiment. The study in this paper shows (1) important information about the behavior of DE in constrained search spaces and (2) the role of this knowledge in the correct combination of variants, based on their capabilities, to generate simple but competitive approaches.
13FA6519	In this paper, a new optimisation strategy for the solution of the classical Unit Commitment problem is proposed. This problem is known to be an often large scale, mixed integer programming problem. Due to high combinatorial complexity, the exact solution is often intractable. Thus, a metaheuristic based method has to be used to compute a very often suitable solution. The main idea of the approach is to use ant colony algorithm, to explicitly deal with the feasibility of the solution, and to feed a genetic algorithm whose goal is to intensively explore the search space. Finally, results show that the proposed method leads to the tractable computation of satisfying solutions for the Unit Commitment problem. 
78E2DDEC	This paper analyzed the unreasonable of widespread use of competitive selection rules to solving Constrained Optimization Genetic Algorithm. With the concept of Pareto dominance and the sequence of individual factorial design a new sort of population model. It balances the feasible region and constraints optimal solution search direction, which makes the Constrained Optimization Genetic Algorithm along both sides of feasible region to search for constrained optimal solution. There is a relationship between feasible region in demes and evolutional generation and also the order factor. It considers both the algorithmic search quality and efficiency optimization. The numerical experiment and engineering example have shown, the improved Constrained Optimization Genetic Algorithm has the more simple algorithm structure, the higher solution quality and much more stable.
80C1A3F1	Constrained optimization problems(COPs) are a kind of mathematic programming problem frequently encountered in the disciplines of science and engineering application. After analyzing weaknesses of existing constrained optimization evolutionary algorithms (COEAs), a novel improved algorithm called Complex-GA, which converts COPs into Multi-objective optimization problems(MOPs) and effectively combines Multi-objective optimization concept with global and local search, was proposed to handle COPs. Complex-GA increases the speed of optima search noticeably by combining the advantages of the two methods and overcomes the disadvantages of them.
7FB9CE4E	We first propose a hybrid localization/inspection/machinability problem. Next, we formulate the hybrid problem using differential geometric theory and the minimax method. Then, we develop a methodology for treating localization, online inspection and machinability of workpieces simultaneously. Using the geometric properties of the hybrid problem, the hybrid problem is decoupled into a (symmetric) localization/inspection problem and a machinability problem. Then both problems are formulated as constrained optimization problems and are solved by a sequence of linear programming problems. Finally, we present simulation results to demonstrate the efficiency of our method for the hybrid problem.
7D2766AC	A recurrent neural network is proposed to deal with the convex optimization problem. By employing a specific nonlinear unit, the proposed neural network is proved to be convergent to the optimal solution in finite time, which increases the computation efficiency dramatically. Compared with most of existing stability conditions, i.e., asymptotical stability and exponential stability, the obtained finite-time stability result is more attractive, and therefore could be considered as a useful supplement to the current literature. In addition, a switching structure is suggested to further speed up the neural network convergence. Moreover, by using the penalty function method, the proposed neural network can be extended straightforwardly to solving the constrained optimization problem. Finally, the satisfactory performance of the proposed approach is illustrated by two simulation examples.
7583761A	This paper presents an effective hybrid coevolutionary particle swarm optimization algorithm for solving constrained engineering design problems, which is based on simulated annealing (SA) , employing the notion of co-evolution to adapt penalty factors. By employing the SAbased selection for the best position of particles and swarms when updating the velocity in co-evolutionary particle swarm optimization algorithm. Simulation results based on well-known constrained engineering design problems demonstrate the effectiveness, efficiency and robustness on initial populations of the proposed, and can reach a high precision.
7D27E632	Sparsity-constrained optimization has wide applicability in machine learning, statistics, and signal processing problems such as feature selection and Compressed Sensing. A vast body of work has studied the sparsity-constrained optimization from theoretical, algorithmic, and application aspects in the context of sparse estimation in linear models where the fidelity of the estimate is measured by the squared error. In contrast, relatively less effort has been made in the study of sparsity-constrained optimization in cases where nonlinear models are involved or the cost function is not quadratic. In this paper we propose a greedy algorithm, Gradient Support Pursuit (GraSP), to approximate sparse minima of cost functions of arbitrary form. Should a cost function have a Stable Restricted Hessian (SRH) or a Stable Restricted Linearization (SRL), both of which are introduced in this paper, our algorithm is guaranteed to produce a sparse vector within a bounded distance from the true sparse optimum. Our approach generalizes known results for quadratic cost functions that arise in sparse linear regression and Compressed Sensing. We also evaluate the performance of GraSP through numerical simulations on synthetic and real data, where the algorithm is employed for sparse logistic regression with and without l2-regularization.
7C462E67	The numerical analysis of a dynamic constrained optimization problem is presented. It consists of a global minimization problem that is coupled with a system of ordinary differential equations. The activation and the deactivation of inequality constraints induce discontinuity points in the time evolution. A numerical method based on an operator splitting scheme and a fixed point algorithm is advocated. The ordinary differential equations are approximated by the Crank-Nicolson scheme, while a primal-dual interior-point method with warm-starts is used to solve the minimization problem. The computation of the discontinuity points is based on geometric arguments, extrapolation polynomials and sensitivity analysis. Second order convergence of the method is proved when an inequality constraint is activated. Numerical results for atmospheric particles confirm the theoretical investigations.
76A6758D	Well pattern design plays a critical role during oil-field development. Inappropriate design would result in huge loss considering that the cost of a well may be millions of dollars. In this paper, our objective is aiming at solving the problem of optimization of regular well pattern for large-scale reservoir development. A new construction form and computing solution is proposed for well pattern. Due to varieties of regular well patterns, it is difficult to give a universal description for the corresponding structures. Hence, based on the definition of well pattern by Onwunalu, 6 variables are developed to describe the well pattern units. These variables are able to realize the rotating, scaling, shifting and shearing regardless of row well pattern, five-spot well pattern, seven-spot pattern or nine-spot pattern. Furthermore, optimal well pattern depends on not only the unit form but also the production control which is reflected in a new variable-total injection-production rate. Therefore, the total number of variables is up to 7 but not too many. And because they are continuous, NEWUOA algorithm can be used for the optimization of regular well pattern. Meanwhile, the constrained problems, such as the boundary restraints of variables and cumulative injection–production rates, can be better considered. Finally, detailed well pattern optimization examples are presented indicating that the well pattern optimization method is quite effective.
7CFA7D24	Providing guaranteed end-to-end quality of service (QoS) is a key issue for deploying multimedia applications on broadband integrated services networks. To support such a QoS-based service, a problem concerning how to select a feasible end-to-end path in order to satisfy multiple QoS constraints simultaneously must be studied. Two exact algorithms, branch-and-bound and extended Bellman-Ford algorithms, are proposed for this NP-complete problem. In spite of the time complexity of the branch-and-bound algorithm being O(d/sup n/) at the worst case, simulation results show that the branch-and-bound method not only outperforms the extended Bellman-Ford method, but also is an efficient method when it is applied to random networks and practical networks like ANSNET. As for mesh networks, it is observed that our branch-and-bound method is efficient only for networks where the number of hops of the desired MCOP (multiple constrained optimal path) is less than 15.
7B2FB487	Artificial bee colony (ABC) algorithm represents one of the most-studied swarm intelligence algorithms. Since the original ABC has been found to be very effective, today there are a lot of improved variants of ABC algorithm used to solve a wide range of hard optimization problems. This paper describes a novel artificial bee colony algorithm for constrained optimization problems. In the proposed algorithm, five modifications are introduced. Firstly, to improve the exploitation abilities of ABC, two different modified ABC search operators are used in employed and onlooker phases, and crossover operator is used in scout phase instead of random search. Secondly, modifications related to dynamic tolerance for handling equality constraints and improved boundary constraint-handling method are employed. The experimental results, obtained by testing on a set of 24 well-known benchmark functions and four widely used engineering design problems, show that the proposed approach can outperform ABC-based approaches for constrained optimization problems in terms of the quality of the results, robustness and convergence speed. Additionally, it provides better results in most cases compared with other state-of-the-art algorithms.
7BE93B72	Inverse problems are of the utmost importance in many fields of science and engineering. In the variational approach, inverse problems are formulated as partial differential equation-constrained optimization problems, where the optimal estimate of the uncertain parameters is the minimizer of a certain cost functional subject to the constraints posed by the model equations. The numerical solution of such optimization problems requires the computation of derivatives of the model output with respect to model parameters. The first-order derivatives of a cost functional (defined on the model output) with respect to a large number of model parameters can be calculated efficiently through first-order adjoint (FOA) sensitivity analysis. Second-order adjoint (SOA) models give second derivative information in the form of matrix–vector products between the Hessian of the cost functional and user-defined vectors. Traditionally, the construction of second-order derivatives for large-scale models has been considered too costly. Consequently, data assimilation applications employ optimization algorithms that use only first-order derivative information, such as nonlinear conjugate gradients and quasi-Newton methods.In this paper, we discuss the mathematical foundations of SOA sensitivity analysis and show that it provides an efficient approach to obtain Hessian-vector products. We study the benefits of using second-order information in the numerical optimization process for data assimilation applications. The numerical studies are performed in a twin experiment setting with a two-dimensional shallow water model. Different scenarios are considered with different discretization approaches, observation sets, and noise levels. Optimization algorithms that employ second-order derivatives are tested against widely used methods that require only first-order derivatives. Conclusions are drawn regarding the potential benefits and the limitations of using high-order information in large-scale data assimilation problems.
7787F07D	The philosophy of multisplitting methods is the replacement of a large-scale linear or nonlinear problem by a set of smaller subproblems, each of which can be solved locally and independently in parallel by taking advantage of well-tested sequential algorithms. Because of this formulation most compute-intensive operations can be calculated independently and the algorithms are highly parallel. In continuation of our earlier work we utilize a new parameter-free formulation of linearly constrained convex minimization problems to obtain a parallel algorithm of multisplitting type. Numerical results both serial and parallel are reported which demonstrate its efficiency and which also show that it compares favorably to our earlier parameter-dependent approach.
7935478F	This survey is concerned with variants of nonlinear optimization methods designed for implementation on parallel computers. First, we consider a variety of methods for unconstrained minimization. We consider a particular type of parallelism (simultaneous function and gradient evaluations), and we concentrate on the main sources of inspiration: conjugate directions, homogeneous functions, variable-metric updates, and multi-dimensional searches. The computational process for solving small and medium-size constrained optimization problems is usually based on unconstrained optimization. This provides a straightforward opportunity for the introduction of parallelism. In the present survey, however, we focus on promising approaches for solving large, well-structured constrained problems: dualization of problems with separable objective and constraint functions, and decomposition of hierarchical problems with linking variables (typical for Bender's decomposition in the linear case). Finally, we outline the key issues in future computational studies of parallel nonlinear optimization algorithms.
59DBE1B5	We investigate genetic algorithms where more than two parents are involved in the recombination operation. We introduce two multi-parent recombination mechanisms: gene scanning and diagonal crossover that generalize uniform, respecively n-point crossovers. In this paper we concentrate on the gene scanning mechanism and we perform extensive tests to observe the effect of different numbers of parents on the performance of the GA. We consider different problem types, such as numerical optimization, constrained optimization (TSP) and constraint satisfaction (graph coloring). The experiments show that 2-parent recombination is inferior on the classical DeJong functions. For the other problems the results are not conclusive, in some cases 2 parents are optimal, while in some others more parents are better.
7CC85D5E	This paper presents an application of genetic algorithms (GAs) to nonlinear constrained optimization. GAs are general purpose optimization algorithms which apply the rules of natural genetics to explore a given search space. When GAs are applied to nonlinear constrained problems, constraint handling becomes an important issue. The proposed search algorithm is realized by GAs which utilize a penalty function in the objective function to account for violation. This extension is based on systematic multi-stage assignments of weights in the penalty method as opposed to single-stage assignments in sequential unconstrained minimization. The experimental results are satisfactory and agree well with those of the gradient type methods.
7AAEFF33	This paper presents an optimization algorithm for engineering design problems having a mix of continuous, discrete and integer variables; a mix of linear, non-linear, differentiable, non-differential, equality, inequality and even discontinuous design constraints; and conflicting multiple design objectives. The intelligent movement of objects (vertices and compounds) is simulated in the algorithm based on a Nelder–Mead simplex with added features to handle variable types, bound and design constraints, local optima, search initiation from an infeasible region and numerical instability, which are the common requirements for large-scale, complex optimization problems in various engineering and business disciplines. The algorithm is called an INTElligent Moving Object algorithm and tested for a wide range of benchmark problems. Validation results for several examples, which are manageable within the scope of this paper, are presented herein. Satisfactory results have been obtained for all the test problems, hence, highlighting the benefits of the proposed method.
802C3D01	A novel approach to deal with numerical and engineering constrained optimization problems, which incorporates a hybrid evolutionary algorithm and an adaptive constraint-handling technique, is presented in this paper. The hybrid evolutionary algorithm simultaneously uses simplex crossover and two mutation operators to generate the offspring population. Additionally, the adaptive constraint-handling technique consists of three main situations. In detail, at each situation, one constraint-handling mechanism is designed based on current population state. Experiments on 13 benchmark test functions and four well-known constrained design problems verify the effectiveness and efficiency of the proposed method. The experimental results show that integrating the hybrid evolutionary algorithm with the adaptive constraint-handling technique is beneficial, and the proposed method achieves competitive performance with respect to some other state-of-the-art approaches in constrained evolutionary optimization.