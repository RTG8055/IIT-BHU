788ED83F	Hierarchical graphs are widely used as models of the structure of software systems. A central problem in the visualization of hierarchical graphs is the computation of layouts, i.e. of positions of the nodes in two- or three-dimensional space. We derive requirements for graph layouts from various software analysis questions, and classify the required layouts along three dimensions: layouts with meaningful distances between single nodes vs. layouts with meaningful distances between groups of nodes, layouts reflecting adjacency vs. layouts reflecting hierarchy, and layouts that faithfully reflect the size of subgraphs vs. layouts where certain subgraphs are magnified. We present a fairly simple and theoretically validated energy model for computing such layouts.
7880312C	Now that multicore chips are common, providing an approach to parallel programming that is usable by regular programmers has become even more important. This cloud has one silver lining: providing useful speedup on a program is useful in and of itself, even if the resulting performance is lower than the best possible parallel performance on the same program. To help achieve this goal, Yada is an explicitly parallel programming language with sequential semantics. Explicitly parallel, because we believe that programmers need to identify how and where to exploit potential parallelism, but sequential semantics so that programmers can understand and debug their parallel programs in the way that they already know, i.e. as if they were sequential.The key new idea in Yada is the provision of a set of types that support parallel operations while still preserving sequential semantics. Beyond the natural read-sharing found in most previous sequential-like languages, Yada supports three other kinds of sharing. Writeonce locations support a single write and multiple reads, and two kinds of sharing for locations updated with an associative operator generalise the reduction and parallel-prefix operations found in many data-parallel languages. We expect to support other kinds of sharing in the future.We have evaluated our Yada prototype on eight algorithms and four applications, and found that programs require only a few changes to get useful speedups ranging from 2.2 to 6.3 on an 8-core machine. Yada performance is mostly comparable to parallel implementations of the same programs using OpenMP or explicit threads.
70022CC5	We adopt a layered approach to autonomic systems to simplify the specification, implementation and evaluation of self-* behaviours. Autonomy is rendered in two dimensions and interfaces suitable for tool based development are incorporated. To exemplify our approach we present an emergent solution for airspace management. This is representative of many problems in which local neighbour interactions can be utilised to give stable and robust global behaviour
7B0B5ECA	Parallel programming on loosely coupled distributed systems involves many system dependent tasks such as sensing node availability, creating remote processes, programming inter-process communication and synchronization, etc. Very often these system-dependent tasks are handled at the programmer level. This has complicated the process of parallel programming on distributed systems. The portability of these programs is also severely affected. The programmer may also start his remote processes on heavily loaded nodes, thereby degrading the overall performance of the system. To overcome these difficulties, we introduce a language construct called parset at the programming level. Parset captures various kinds of coarse grain parallelism occurring in distributed systems. It also provides scalability to distributed programs. We show that this construct greatly simplifies writing programs on distributed systems providing transparency to various system dependent tasks.
781E3669	This paper proposes an unsupervised algorithm for learning a finite mixture model from multivariate data. The adjective "unsupervised" is justified by two properties of the algorithm: 1) it is capable of selecting the number of components and 2) unlike the standard expectation-maximization (EM) algorithm, it does not require careful initialization. The proposed method also avoids another drawback of EM for mixture fitting: the possibility of convergence toward a singular estimate at the boundary of the parameter space. The novelty of our approach is that we do not use a model selection criterion to choose one among a set of preestimated candidate models; instead, we seamlessly integrate estimation and model selection in a single algorithm. Our technique can be applied to any type of parametric mixture model for which it is possible to write an EM algorithm; in this paper, we illustrate it with experiments involving Gaussian mixtures. These experiments testify for the good performance of our approach.
5F86BBDC	Minimally Synchronous Parallel ML (MSPML) is a functional parallel programming language. It is based on a small number of primitives on a parallel data structure. MSPML programs are written like usual sequential ML program and use this small set of functions. MSPML is deterministic and deadlock free. The execution time of the programs can be estimated.Divide-and-conquer is a natural way of expressing parallel algorithms. MSPML is a flat language: it is not possible to split the parallel machine in order to implement divide-and-conquer parallel algorithms. This paper presents an extension of MSPML to deal with this kind of algorithms: a parallel composition primitive.
7FB99442	A new architecture for mobile radio networks, called the linked cluster architecture, is described, and methods for implementing this architecture using distributed control techniques are presented. We illustrate how fully distributed control methods can be combined with hierarchical control to create a network that is robust with respect to both node loss and connectivity changes. Two distributed algorithms are presented that deal with the formation and linkage of clusters and the activation of the network links. To study the performance of our network structuring algorithms, a simulation model was developed. The use of Simula to construct, software simulation tools is illustrated. Simulation results are shown for the example of a high frequency (HF) intratask force (ITF) communication network.
7F82D4FE	We explore the idea of evidence accumulation (EAC) for combining the results of multiple clusterings. First, a clustering ensemble - a set of object partitions, is produced. Given a data set (n objects or patterns in d dimensions), different ways of producing data partitions are: 1) applying different clustering algorithms and 2) applying the same clustering algorithm with different values of parameters or initializations. Further, combinations of different data representations (feature spaces) and clustering algorithms can also provide a multitude of significantly different data partitionings. We propose a simple framework for extracting a consistent clustering, given the various partitions in a clustering ensemble. According to the EAC concept, each partition is viewed as an independent evidence of data organization, individual data partitions being combined, based on a voting mechanism, to generate a new n × n similarity matrix between the n patterns. The final data partition of the n patterns is obtained by applying a hierarchical agglomerative clustering algorithm on this matrix. We have developed a theoretical framework for the analysis of the proposed clustering combination strategy and its evaluation, based on the concept of mutual information between data partitions. Stability of the results is evaluated using bootstrapping techniques. A detailed discussion of an evidence accumulation-based clustering algorithm, using a split and merge strategy based on the k-means clustering algorithm, is presented. Experimental results of the proposed method on several synthetic and real data sets are compared with other combination strategies, and with individual clustering results produced by well-known clustering algorithms.
7DDC65F8	Over the past few years, there has been a renewed interest in the consensus clustering problem. Several new methods have been proposed for finding a consensus partition for a set of n data objects that optimally summarizes an ensemble. In this paper, we propose new consensus clustering algorithms with linear computational complexity in n. We consider clusterings generated with a random number of clusters, which we describe by categorical random variables. We introduce the idea of cumulative voting as a solution for the problem of cluster label alignment, where unlike the common one-to-one voting scheme, a probabilistic mapping is computed. We seek a first summary of the ensemble that minimizes the average squared distance between the mapped partitions and the optimal representation of the ensemble, where the selection criterion of the reference clustering is defined based on maximizing the information content as measured by the entropy. We describe cumulative vote weighting schemes and corresponding algorithms to compute an empirical probability distribution summarizing the ensemble. Given the arbitrary number of clusters of the input partitions, we formulate the problem of extracting the optimal consensus as that of finding a compressed summary of the estimated distribution that preserves the maximum relevant information. An efficient solution is obtained using an agglomerative algorithm that minimizes the average generalized Jensen-Shannon divergence within the cluster. The empirical study demonstrates significant gains in accuracy and superior performance compared to several recent consensus clustering algorithms.
5E7FA96D	The monitor construct has been implemented in several concurrent and/or parallel programming languages for shared-memory system environments, Extensions of the monitor to support process synchronization in distributed systems have also been proposed. But, most existing work only provides the architecture design of the distributed monitor. There is no discussion about the algorithmic and implementation issues. Also, none of them consider how to implement conditional variables. In this paper, we present the design and implementation of a distributed monitor construct, named DisMoniC, for programming process synchronization in distributed systems. DisMoniC is generic in the sense that it can be used with any distributed mutual exclusion (DME) algorithm to implement exclusive access to the monitor operations. Time-efficient algorithms are proposed to implement conditional process synchronization in the distributed monitor. We also present performance evaluation of the proposed construct.
5EEA5FD7	There are several parallel programming models available for numerical computations at different levels of expressibility and ease of use. For the development of new domain specific programming models, a splitting into a distributed data container and parallel data iterators is proposed. Data distribution is implemented in application specific libraries. Data iterators are directly analysed and compiled automatically into parallel code. Target architectures of the source-to-source translation include shared (pthreads, Cell SPE), distributed memory (MPI) and hybrid programming styles. A model applications for grid based hierarchical numerical methods and an auto-parallelizing compiler are introduced.
7C31495C	Novel memory programming methods and corresponding memory structures are presented in this paper. Unlike conventional memory programming, this programming technique does not require deterministic switching of memory elements. This technique explicitly exploits the probabilistic switching characteristics of memory elements such as spin-transfer torque magnetic tunnel junction (STT-MTJ) to reduce programming power and delay. This technique also allows multilevel cell (MLC) spin-transfer torque magnetoresistive random access memory (STT-MRAM) to be fabricated with existing STT-MTJ fabrication processes, thus making high capacity STT-MRAM chips readily achievable. The optimal STT-MTJ switching probabilities are given in this paper for reaching minimum programming delay, power, and iteration. Moreover, this paper proves, by applying probabilistic programming to existing STT-MTJs, both programming delay and power can be reduced to levels beyond the reach of conventional deterministic programming. Furthermore arbitrarily small programming bit error rate (BER) can be accomplished in theory using probabilistic programming without much penalty on average programming delay and power. On the contrary, deterministic programming always presents finite programming BER, which is expensive to reduce in terms of programming power and delay. The MLC capability of STT-MTJ clusters has also been confirmed using fabricated STT-MTJ devices. The major circuitries for implementing probabilistically programmed MLC STT-MRAM are also presented in this paper.
7E74D135	We introduce a middleware infrastructure that provides software services for developing and deploying high-performance parallel programming models and distributed applications on clusters and networked heterogeneous systems. This middleware infrastructure utilizes distributed agents residing on the participating machines and communicating with one another to perform the required functions. An intensive study of the parallel programming models in Java has helped identify the common requirements for a runtime support environment, which we used to define the middleware functionality. A Java-based prototype, based on this architecture, has been developed along with a Java object-passing interface (JOPI) class library. Since this system is written completely in Java, it is portable and allows executing programs in parallel across multiple heterogeneous platforms. With the middleware infrastructure, users need not deal with the mechanisms of deploying and loading user classes on the heterogeneous system. Moreover, details of scheduling, controlling, monitoring, and executing user jobs are hidden, while the management of system resources is made transparent to the user. Such uniform services are essential for facilitating the development and deployment of scalable high-performance Java applications on clusters and heterogeneous systems. An initial deployment of a parallel Java programming model over a heterogeneous, distributed system shows good performance results. In addition, a framework for the agents' startup mechanism and organization is introduced to provide scalable deployment and communication among the agents.
7FECDA80	This study explores the appropriateness of the locality of air monitoring stations which are meant to indicate air quality in the area. Daily variations in NO2 and PM10 concentrations at 14 monitoring stations in Hong Kong are examined. The daily variations in NO2 at a number of background monitoring stations exhibit patterns similar to variations in traffic volume while variations in PM10 concentration exhibit less discernible pattern. Principal component analysis (PCA) and cluster analysis (CA) are applied to analyse NO2 and PM10 measurements between January 2001 and December 2005. The results show that NO2 concentrations at background stations within the urban area are highly influenced by vehicle emissions. The effect vehicle emission has on NO2 at stations within new towns is smaller. CA results also show that variations in PM10 concentrations are distinguished by the area the station is located in. PCA results show that there are two principal components (PC's) associated with variations in roadside concentration of PM10. The strong influence of roadside emissions towards concentrations of NO2 and PM10 at a number of urban background stations may be due to their close proximity to busy roadways and the high density of surrounding tall buildings, which creates an enclosure that hinders dispersion of roadside emissions and results in air pollution behaviour that reflects variation in traffic.
7FA60214	Clustering is a discovery process in data mining. It groups a set of data in a way that maximizes the similarity within clusters and minimizes the similarity between two different clusters. Many advanced algorithms have difficulty dealing with highly variable clusters that do not follow a preconceived model. By basing its selections on both interconnectivity and closeness, the Chameleon algorithm yields accurate results for these highly variable clusters. Existing algorithms use a static model of the clusters and do not use information about the nature of individual clusters as they are merged. Furthermore, one set of schemes (the CURE algorithm and related schemes) ignores the information about the aggregate interconnectivity of items in two clusters. Another set of schemes (the Rock algorithm, group averaging method, and related schemes) ignores information about the closeness of two clusters as defined by the similarity of the closest items across two clusters. By considering either interconnectivity or closeness only, these algorithms can select and merge the wrong pair of clusters. Chameleon's key feature is that it accounts for both interconnectivity and closeness in identifying the most similar pair of clusters. Chameleon finds the clusters in the data set by using a two-phase algorithm. During the first phase, Chameleon uses a graph partitioning algorithm to cluster the data items into several relatively small subclusters. During the second phase, it uses an algorithm to find the genuine clusters by repeatedly combining these subclusters.	
7804FE7F	Coverage preservation, unique ID assignment and extension of network lifetime are important features for wireless sensor networks. Grouping sensor nodes into clusters is an effective way to improve the network performance. By analyzing communication energy consumption of the clusters and the impact of node failures on coverage with different densities, we propose a DEECIC (Distributed Energy-Efficient Clustering with Improved Coverage) algorithm. DEECIC aims at clustering with the least number of cluster heads to cover the whole network and assigning a unique ID to each node based on local information. In addition, DEECIC periodically updates cluster heads according to the joint information of nodes’ residual energy and distribution. The algorithm requires neither time synchronization nor knowledge of a node’s geographic location. Simulation results show that the proposed algorithm can prolong the network lifetime and improve network coverage effectively.
7C2C3EA0	22 Physico-chemical variables have been analyzed in water samples collected every three months for two and a half years from three sampling stations located along a section of 25 km of a river affected by man-made and seasonal influences. Exploratory analysis of experimental data have been carried out by box plots, ANOVA, display methods (principal component analysis) and unsupervised pattern recognition (cluster analysis) in an attempt to discriminate sources of variation of water quality. PCA has allowed the identification of a reduced number of “latent” factors with a hydrochemical meaning: mineral contents, man-made pollution and water temperature. Spatial (pollution from anthropogenic origin) and temporal (seasonal and climatic) sources of variation affecting quality and hydrochemistry of river water have been differentiated and assigned to polluting sources. An ANOVA of the rotated principal components has demonstrated that (i) mineral contents are seasonal and climate dependent, thus pointing to a natural origin for this polluting form and (ii) pollution by organic matter and nutrients originates from anthropogenic sources, mainly as municipal wastewater. The application of PCA and cluster analysis has achieved a meaningful classification of river water samples based on seasonal and spatial criteria.
7C271CAE	Clustering partitions a collection of objects into groups called clusters, such that similar objects fall into the same group. Similarity between objects is defined by a distance function satisfying the triangle inequality; this distance function along with the collection of objects describes a distance space. In a distance space, the only operation possible on data objects is the computation of distance between them. All scalable algorithms in the literature assume a special type of distance space, namely a k-dimensional vector space, which allows vector operations on objects. We present two scalable algorithms designed for clustering very large datasets in distance spaces. Our first algorithm BUBBLE is, to our knowledge, the first scalable clustering algorithm for data in a distance space. Our second algorithm BUBBLE-FM improves upon BUBBLE by reducing the number of calls to the distance function, which may be computationally very expensive. Both algorithms make only a single scan over the database while producing high clustering quality. In a detailed experimental evaluation, we study both algorithms in terms of scalability and quality of clustering. We also show results of applying the algorithms to a real life dataset.
6C904FD2	In this study, we evaluated the performance of Shanghai's air quality monitoring network (AQMN) using principal components analysis, an assignment method, and cluster analysis. Our goal was to improve the utilization of monitoring stations and evaluate Shanghai's air quality more comprehensively and accurately. Specifically, we (i) identified similar pollution sources or behaviors in the monitoring areas; (ii) identified redundant monitoring stations and re-evaluated the AQMN's performance without them; and (iii) proposed adjustments to the AQMN. We used data on particulates less than 2.5 μm (PM2.5) and 10 μm (PM10) in diameter, sulfur dioxide (SO2), nitrogen dioxide (NO2), ozone (O3), and carbon monoxide (CO) at stations in and around Shanghai from 1 January to 22 August 2014. For each pollutant, we grouped the monitoring stations into clusters based on their different pollution behaviors, revealing redundancy and inefficiency in the current AQMN that resulted from the concentrated station distribution and similarity of the monitoring environments. The analysis results showed that there exist redundant stations in the current AQMN of Shanghai. Furthermore, we proposed adjustments to Shanghai's AQMN: transfer four redundant stations and build a new station in the directions of the Taicang Experimental Primary School, Kunshan Zhenchuan Middle School, Suzhou Industrial Park, Wujiang Industrial Zone, and Jiaxing Monitoring Station. Our analysis suggests that, in addition to industrial, transportation, construction, and population influences inside Shanghai, external pollutants significantly affect Shanghai's air quality. Therefore, it is necessary to jointly prevent and control regional air pollution both in Shanghai and in neighboring cities.
42D8D46C	Efficient management of energy resources is a challenging research area in Wireless Sensor Networks (WSNs). Recent studies have revealed that clustering is an efficient topology control approach for organizing a network into a connected hierarchy which balances the traffic load of the sensor nodes and improves the overall scalability and the lifetime of WSNs. Inspired by the advantages of clustering techniques, we have three main contributions in this paper. First, we propose an energy efficient cluster formation algorithm called Active Node Cluster Formation (ANCF). The core aim to propose ANCF algorithm is to distribute heavy data traffic and high energy consumption load evenly in the network by offering unequal size of clusters in the network. The developed scheme appoints each cluster head (CH) near to the sink and sensing event while the remaining set of the cluster heads (CHs) are appointed in the middle of each cluster to achieve the highest level of energy efficiency in dense deployment. Second, we propose a lightweight sensing mechanism called Active Node Sensing Algorithm (ANSA). The key aim to propose the ANSA algorithm is to avoid high sensing overlapping data redundancy by appointing a set of active nodes in each cluster with satisfy coverage near to the event. Third, we propose an Active Node Routing Algorithm (ANRA) to address complex inter and intra cluster routing issues in highly dense deployment based on the node dominating values. Extensive experimental studies conducted through network simulator NCTUNs 6.0 reveal that our proposed scheme outperforms existing routing techniques in terms of energy efficiency, end-to-end delay and data redundancy, congestion management and setup robustness.
791CA357	We combine image-processing techniques with a powerful new statistical technique to detect linear pattern production faults in woven textiles. Our approach detects a linear pattern in preprocessed images via model-based clustering. It employs an approximate Bayes factor which provides a criterion for assessing the evidence for the presence of a defect. The model used in experimentation is a (possibly highly elliptical) Gaussian cloud superimposed on Poisson clutter. Results are shown for some representative examples, and contrasted with a Hough transform. Software for the statistical modeling is available.
7F02386E	We explore the idea of evidence accumulation for combining the results of multiple clusterings. Initially, n d-dimensional data is decomposed into a large number of compact clusters; the K-means algorithm performs this decomposition, with several clusterings obtained by N random initializations of the K-means. Taking the co-occurrences of pairs of patterns in the same cluster as votes for their association, the data partitions are mapped into a co-association matrix of patterns. This n/spl times/n matrix represents a new similarity measure between patterns. The final clusters are obtained by applying a MST-based clustering algorithm on this matrix. Results on both synthetic and real data show the ability of the method to identify arbitrary shaped clusters in multidimensional data.
7A1A88AA	The study presents the application of selected chemometric techniques: cluster analysis, principal component analysis, factor analysis and discriminant analysis, to classify a river water quality and evaluation of the pollution data. Seventeen stations, monitored for 16 physical and chemical parameters in 4 seasons during the period 1999–2003, located at the Bagmati river basin in Kathmandu Valley, Nepal were selected for the purpose of this study. The results allowed, determining natural clusters of monitoring stations with similar pollution characteristics and identifying main discriminant variables that are important for regional water quality variation and possible pollution sources affecting the river water quality. The analysis enabled to group 17 monitoring sites into 3 regions with 5 major discriminating variables: EC, DO, CL, NO2N and BOD. Results revealed that some locations were under the high influence of municipal contamination and some others under the influence of minerals. This study demonstrated that chemometric method is effective for river water classification, and for rapid assessment of water qualities, using the representative sites; it could serve to optimize cost and time without losing any significance of the outcome.
766E9DA6	Survey properties of soil and rock mass have always been associated with uncertainty. Hence, the behavior of the soil or rock cannot be investigated specifically by choosing a value specified for these properties. One of the most common systems for studying properties of rock mass is the rock mass classification system (RMR) which was developed by Bieniawski. In this system the input parameters are divided into several classes, and each class has particular rating. In this system, because of uncertainties of the input parameters, determining the definite boundary between the classes and assigning a specified value to a particular class is difficult, so when the input parameters are close to the boundary between the classes, the class rating with certainity is not decided. The aim of this paper is to propose a hybrid nonlinear Chaotic and Neuro-Fuzzy system modeling for the basic RMR system uncertainty based on continuous functions. This model also proves the theory of Bieniawski that is based on nonlinear systems by using chaos theory and mathematical relations. The main advantage of proposed model is to directly predict output of RMR system classification system without considering the input parameters so that it leads to better results and a higher level of prediction rock quality.
805E1A24	The novel concept of pseudoerrors for a self-organizing neuro-fuzzy system (SO-NFS) is proposed for tracking control problem. To demonstrate the proposed approach, an example of motion control of an auto-warehousing crane system is illustrated, which can move back and forth in x,y, and z directions to access and store cargoes. The proposed SO-NFS shows excellent performance in control of the crane system for different loading conditions and varying distances in all directions.
7871F90D	A method for determining the mutual nearest neighbours (MNN) and mutual neighbourhood value (mnv) of a sample point, using the conventional nearest neighbours, is suggested. A nonparametric, hierarchical, agglomerative clustering algorithm is developed using the above concepts. The algorithm is simple, deterministic, noniterative, requires low storage and is able to discern spherical and nonspherical clusters. The method is applicable to a wide class of data of arbitrary shape, large size and high dimensionality. The algorithm can discern mutually homogenous clusters. Strong or weak patterns can be discerned by properly choosing the neighbourhood width.
7D078885	This paper introduces the problem of combining multiple partitionings of a set of objects into a single consolidated clustering without accessing the features or algorithms that determined these partitionings. We first identify several application scenarios for the resultant 'knowledge reuse' framework that we call cluster ensembles. The cluster ensemble problem is then formalized as a combinatorial optimization problem in terms of shared mutual information. In addition to a direct maximization approach, we propose three effective and efficient techniques for obtaining high-quality combiners (consensus functions). The first combiner induces a similarity measure from the partitionings and then reclusters the objects. The second combiner is based on hypergraph partitioning. The third one collapses groups of clusters into meta-clusters which then compete for each object to determine the combined clustering. Due to the low computational costs of our techniques, it is quite feasible to use a supra-consensus function that evaluates all three approaches against the objective function and picks the best solution for a given situation. We evaluate the effectiveness of cluster ensembles in three qualitatively different application scenarios: (i) where the original clusters were formed based on non-identical sets of features, (ii) where the original clustering algorithms worked on non-identical sets of objects, and (iii) where a common data-set is used and the main purpose of combining multiple clusterings is to improve the quality and robustness of the solution. Promising results are obtained in all three situations for synthetic as well as real data-sets.
76459DD9	Conservation of energy and fault tolerance are two major issues in the deployment of a wireless sensor network (WSN). Design of clustering and routing algorithms for a large scale WSN should incorporate both these issues for the long run operation of the network. In this paper, we propose distributed clustering and routing algorithms jointly referred as DFCR. The algorithm is shown to be energy efficient and fault tolerant. The DFCR uses a distributed run time recovery of the sensor nodes due to sudden failure of the cluster heads (CHs). It takes care of the sensor nodes which have no CH within their communication range. We perform extensive experiments on the proposed algorithm using various network scenarios. The experimental results are compared with the existing algorithms to demonstrate the strength of the algorithm in terms of various performance metrics.
7C443D8B	The recent advances in genomic technologies and the availability of large-scale microarray datasets call for the development of advanced data analysis techniques, such as data mining and statistical analysis to cite a few. Among the mining techniques proposed so far, cluster analysis has become a standard method for the analysis of microarray expression data. It can be used both for initial screening of patients and for extraction of disease molecular signatures. Moreover, clustering can be profitably exploited to characterize genes of unknown function and uncover patterns that can be interpreted as indications of the status of cellular processes. Finally, clustering biological data would be useful not only for exploring the data but also for discovering implicit links between the objects. To this end, several clustering approaches have been proposed in order to obtain a good trade-off between accuracy and efficiency of the clustering process. In particular, great attention has been devoted to hierarchical clustering algorithms for their accuracy in unsupervised identification and stratification of groups of similar genes or patients, while, partition based approaches are exploited when fast computations are required. Indeed, it is well known that no existing clustering algorithm completely satisfies both accuracy and efficiency requirements, thus a good clustering algorithm has to be evaluated with respect to some external criteria that are independent from the metric being used to compute clusters. In this paper, we propose a clustering algorithm called M-CLUBS (for Microarray data CLustering Using Binary Splitting) exhibiting higher accuracy than the hierarchical ones proposed so far while allowing a faster computation with respect to partition based approaches. Indeed, M-CLUBS is faster and more accurate than other algorithms, including k-means and its recently proposed refinements, as we will show in the experimental section. The algorithm consists of a divisive phase and an agglomerative phase; during these two phases, the samples are repartitioned using a least quadratic distance criterion possessing unique analytical properties that we exploit to achieve a very fast computation. M-CLUBS derives good clusters without requiring input from users, and it is robust and impervious to noise, while providing better speed and accuracy than methods, such as BIRCH, that are endowed with the same critical properties. Due to the structural feature of microarray data (they are represented as arrays of numeric values), M-CLUBS is suitable for analyzing them since it is designed to perform well for Euclidean distances. In order to stronger the obtained results we interpreted the obtained clusters by a domain expert and the evaluation by quality measures specifically tailored for biological validity assessment.
7EB83834	Applications running on exascale machines will be complex in many ways. They will involve dynamic and adaptive refinements, and will be composed of multiple, independently developed modules, often involving a multiphysics simulation. The programming models of this era must have several characteristics. First, they need to do away with the notion of processors, and automate resource management via adaptive runtime systems. Data structure-specific frameworks and domain-specific environments will be needed to further simplify programming. More importantly, parallel mini-languages need to be developed, such that each language captures only a restricted subset of possible parallel interactions, but allows for a simple expression of them. Coupled with interoperability and parallel composition, which must be supported in many ways, including message-driven runtime systems, this will create a productive ecosystem of parallel programming models for the exascale era.
0D1E4331	The aim of this study was to evaluate the performance of two statistical methods, principal component analysis (PCA) and cluster analysis (CA), for the management of air quality monitoring network (AQMN) of Oporto Metropolitan Area (Oporto-MA). The specific objectives were: (i) to identify city areas with similar air pollution behaviours; and (ii) to locate emission sources. The statistical methods were applied to the mass concentrations of carbon monoxide (CO), nitrogen dioxide (NO2) and ozone (O3), collected in the AQMN of Oporto-MA from January 2003 to December 2005.It was demonstrated that for each pollutant the monitoring sites are grouped into different classes based on their air pollution behaviour. The sites were divided: (i) into three different groups for CO and for NO2 and (ii) into two groups for O3. It was also found that several monitoring sites covered city areas characterized by the same specific air pollution behaviour, suggesting then an ineffective management of the air quality-monitoring system. The redundant equipment should be transferred to other monitoring sites allowing enlargement of the monitored area. The conclusions obtained with the statistical methods were supported by the location of main emission sources through the analysis of the wind direction. Four main emission sources of CO and NO2 were located. Additionally, it was concluded that the sea wind had an important contribution towards the increase in the O3 concentration. For all pollutants, two sites were always coupled in one group due to the different air pollution behaviour presented in the analysed period.
791E94C8	Clustering is the process of organizing dataset into isolated groups such that data points in the same are more similar and data points of different groups are more dissimilar. The k-modes algorithm well known for its simplicity is a popular partitioning algorithm for clustering categorical data. In this paper, we discuss the limitations of distance function used in this algorithm with an illustrative example and then we propose a similarity coefficient based on Information Entropy. We analyze the time complexity of the k-modes algorithm with proposed similarity coefficient. The main advantage of this coefficient is that it improves the clustering accuracy while retaining scalability of the k-modes algorithm. We perform the scalability tests on synthetic datasets.
76802CE9	This case study reports different multivariate statistical techniques applied for evaluation of temporal/spatial variations and interpretation of a large complex water-quality data set obtained during monitoring of Gomti River in Northern part of India. Water quality of the Gomti River, a major tributary of the Ganga River was monitored at eight different sites selected in relatively low, moderate and high pollution regions, regularly over a period of 5 years (1994-1998) for 24 parameters. The complex data matrix (17,790 observations) was treated with different multivariate techniques such as cluster analysis, factor analysis/principal component analysis (FA/PCA) and discriminant analysis (DA). Cluster analysis (CA) showed good results rendering three different groups of similarity between the sampling sites reflecting the different water-quality parameters of the river system. FA/PCA identified six factors, which are responsible for the data structure explaining 71% of the total variance of the data set and allowed to group the selected parameters according to common features as well as to evaluate the incidence of each group on the overall variation in water quality. However, significant data reduction was not achieved, as it needed 14 parameters to explain 71% of both the temporal and spatial changes in water quality. Discriminant analysis showed the best results for data reduction and pattern recognition during both temporal and spatial analysis. Discriminant analysis showed five parameters (pH, temperature, conductivity, total alkalinity and magnesium) affording more than 88% right assignations in temporal analysis, while nine parameters (pH, temperature, alkalinity, Ca-hardness, DO, BOD, chloride, sulfate and TKN) to afford 91% right assignations in spatial analysis of three different regions in the basin. Thus, DA allowed reduction in dimensionality of the large data set, delineating a few indicator parameters responsible for large variations in water quality. This study presents necessity and usefulness of multivariate statistical techniques for evaluation and interpretation of large complex data sets with a view to get better information about the water quality and design of monitoring network for effective management of water resources.
7A897473	This paper introduces a novel distance measure for clustering high dimensional data based on the hitting time of two Minimal Spanning Trees (MST) grown sequentially from a pair of points by Prim’s algorithm. When the proposed measure is used in conjunction with spectral clustering, we obtain a powerful clustering algorithm that is able to separate neighboring non-convex shaped clusters and to account for local as well as global geometric features of the data set. Remarkably, the new distance measure is a true metric even if the Prim algorithm uses a non-metric dissimilarity measure to compute the edges of the MST. This metric property brings added flexibility to the proposed method. In particular, the method is applied to clustering non Euclidean quantities, such as probability distributions or spectra, using the Kullback–Leibler divergence as a base measure. We reduce computational complexity by applying consensus clustering to a small ensemble of dual rooted MSTs. We show that the resultant consensus spectral clustering with dual rooted MST is competitive with other clustering methods, both in terms of clustering performance and computational complexity. We illustrate the proposed clustering algorithm on public domain benchmark data for which the ground truth is known, on one hand, and on real-world astrophysical data on the other hand.
5AD9E47D	We report a comparative study using three different chemometric techniques to evaluate both spatial and temporal changes in Suquı́a River water quality, with a special emphasis on the improvement obtained using discriminant analysis for such evaluation. We have monitored 22 parameters at different stations from the upper, middle, and beginning of the lower river basin during at least two years including 232 different samples. We obtained a complex data matrix, which was treated using the pattern recognition techniques of cluster analysis (CA), factor analysis/principal components (FA/PCA), and discriminant analysis (DA). CA renders good results as a first exploratory method to evaluate both spatial and temporal differences, however it fails to show details of these differences. FA/PCA needs 13 parameters to point out 71% of both temporal and spatial changes; consequently data reduction from FA/PCA in this case is not as considerable as expected. However, FA/PCA allows to group the selected parameters according to common features as well as to evaluate the incidence of each group on the overall change in water quality, specially during the analysis of temporal changes. DA technique shows the best results for data reduction and pattern recognition during both temporal and spatial analysis. DA renders an important data reduction using 6 parameters to afford 87% right assignations during temporal analysis. Besides, it uses only 5 parameters to yield 75% right assignations during the spatial analysis of four different basin areas. DA allowed us to greatly reduce the dimensionality of the starting data matrix, pointing out to a few parameters that indicate the biggest changes in water quality as well as variation patterns associated with seasonal variations, urban run-off, and pollution sources, presenting a novel approach for water quality assessments.
7E027E2A	In Bilbao (Spain), an air quality network measures sulphur dioxide levels at 4 locations. The objective of this paper is to develop a practical methodology to identify redundant sensors and evaluate a network's capability to correctly follow and represent SO2 fields in Bilbao, in the frame of a continuous network optimization process.The methodology is developed and tested at this particular location, but it is general enough to be useable at other places as well, since it is not tied neither to the particular geographical characteristics of the place nor to the phenomenology of the air quality over the area.To assess the spatial variability of SO2 measured at 4 locations in the area, three different techniques have been used: Self-Organizing Maps (SOMs), cluster analysis (CA) and Principal Component Analysis (PCA). The results show that the three techniques yield the same results, but the information obtained via PCA can be helpful not only for that purpose but also to throw light on the major mechanisms involved. This might be used in future network optimization stages. The main advantage of cluster analysis and SOMs is that they provide readily interpretable results. All the calculations have been carried out using the freely available software R.
80401A34	Distributed clustering is a new research field of data mining now. In this paper, one of distributed clustering named DCBKC (Distributed Clustering Based on K-means and Coarse-grained parallel genetic algorithm) based on K-means and Coarse-grained Parallel Genetic Algorithm is advanced. The algorithm can solve local clustering problem of distributed clustering effectively, reflect all of local data characters, enhance local data’s perspectivity and decrease network overload at a way by adopting proper migration strategy simultaneously. Both theory analysis and experimental results confirm that DCBKC is feasible.
7FA23803	Cross-national research on health system performance can yield important findings for public policy purposes. We seek to further this research by examining the problem of selection bias, an important methodological issue that investigators initially should consider. Because of the logistical difficulties and enormous expense involved in collecting voluminous data from many countries, researchers often must rely on information contained in data sets of international organizations, such as the World Health Organization (WHO) and the Organization for Economic Cooperation and Development. Under the circumstances, the comparisons that researchers can make will depend to a great extent on the availability and richness of data for certain measures. This situation raises the potential for selection or experimenter bias. We use multivariate statistics to group countries with similar characteristics, an approach that we believe will mitigate the problem. We perform a cluster analysis of 186 countries using principal components derived from 7 demographic variables and 27 mortality and burden of disease variables. Our analysis produced six clusters that we believe represent suitable groupings for comparative purposes.
80636922	Currently in the Internet many collaborative tagging sites exist, but there is the need for a service to integrate the data from the multiple sites to form a large and unified set of collaborative data from which users can have more accurate and richer information than from a single site. In our paper, we have proposed a collective collaborative tagging (CCT) service architecture in which both service providers and individual users can merge folksonomy data (in the form of keyword tags) stored in different sources to build a larger, unified repository. We have also examined a range of algorithms that can be applied to different problems in folksonomy analysis and information discovery. These algorithms address several common problems for online systems: searching, getting recommendations, finding communities of similar users, and finding interesting new information by trends. Our contributions are to a) systematically examine the available public algorithms' application to tag-based folksonomies, and b) to propose a service architecture that can provide these algorithms as online capabilities.
8062E538	We provide an overall framework for learning in search based systems that are used to find optimum solutions to problems. This framework assumes that prior knowledge is available in the form of one or more heuristic functions (or features) of the problem domain. An appropriate clustering strategy is used to partition the state space into a number of classes based on the available features. The number of classes formed will depend on the resource constraints of the system. In the training phase, example problems are run using a standard admissible search algorithm. In this phase, heuristic information corresponding to each class is learned. This new information can be used in the problem solving phase by appropriate search algorithms so that subsequent problem instances can be solved more efficiently. In this framework, we also show that heuristic information of forms other than the conventional single valued underestimate value can be used, since we maintain the heuristic of each class explicitly. We show some novel search algorithms that can work with some such forms. Experimental results have been provided for some domains.
5D87E519	Implicitly parallel programming languages place the burden of exploiting and managing parallelism upon the compiler and runtime system, rather than on the programmer. This paper describes the design of NIP, a runtime system for supporting implicit parallelism in languages which combine both functional and object-oriented programming. NIP is designed for scaleable distributed memory systems including networks of workstations and custom parallel machines. The key components of NIP are: a parallel task execution unit which includes an efficient method for lazily creating parallel tasks from loop iterations; a distributed shared memory system optimised for parallel object-oriented programs; and a load balancing system for distributing work over the nodes of the parallel system. The paper describes the requirements placed on the runtime system by an implicitly parallel language and then details the design of the components that comprise NIP, showing how the components meet these requirements. Performance results for NIP running programs on a network of workstations are presented and analysed.
75CEF15A	Minimizing energy dissipation and maximizing network lifetime are among the central concerns when designing applications and protocols for sensor networks. Clustering has been proven to be energy-efficient in sensor networks since data routing and relaying are only operated by cluster heads. Besides, cluster heads can process, filter and aggregate data sent by cluster members, thus reducing network load and alleviating the bandwidth. In this paper, we propose a novel distributed clustering algorithm where cluster heads are elected following a three-way message exchange between each sensor and its neighbors. Sensor’s eligibility to be elected cluster head is based on its residual energy and its degree. Our protocol has a message exchange complexity of and a worst-case convergence time complexity of . Simulations show that our algorithm outperforms EESH, one of the most recently published distributed clustering algorithms, in terms of network lifetime and ratio of elected cluster heads.
807A339B	Topology control in a sensor network balances load on sensor nodes and increases network scalability and lifetime. Clustering sensor nodes is an effective topology control approach. We propose a novel distributed clustering approach for long-lived ad hoc sensor networks. Our proposed approach does not make any assumptions about the presence of infrastructure or about node capabilities, other than the availability of multiple power levels in sensor nodes. We present a protocol, HEED (Hybrid Energy-Efficient Distributed clustering), that periodically selects cluster heads according to a hybrid of the node residual energy and a secondary parameter, such as node proximity to its neighbors or node degree. HEED terminates in O(1) iterations, incurs low message overhead, and achieves fairly uniform cluster head distribution across the network. We prove that, with appropriate bounds on node density and intracluster and intercluster transmission ranges, HEED can asymptotically almost surely guarantee connectivity of clustered networks. Simulation results demonstrate that our proposed approach is effective in prolonging the network lifetime and supporting scalable data aggregation.
7F9D2BC6	Up to now, it still remains a big challenge for us to build a high performance geo-computing system with high processing speed and also be easy of use by domain researchers. The unprecedented scale data and various complex algorithms pose many computational and management challenges. To properly settle these main issues above, a new system framework for high performance geo-computing is presented in this paper. A High Performance Geo-data Object Storage System (HPGOSS) base on parallel file System is used for eliminating I/O performance bottleneck and deal with the data managing problem result from the close relevancy between geo-information and remote sensing image data. Parallel programming models for fast parallelization of geo-computing algorithms are proposed. In addition, the job scheduling strategy and workflow engine are also discussed. Finally, such system could provide a parallel geo-computing environment with high performance, easy to use, optimal resource utilization, and high scalability.
7900DDE3	Multivariate statistical techniques, such as cluster analysis (CA), factor analysis (FA), principal component analysis (PCA) and discriminant analysis (DA) were applied to the data set on water quality of the Gomti river (India), generated during three years (1999–2001) monitoring at eight different sites for 34 parameters (9792 observations). This study presents usefulness of multivariate statistical techniques for evaluation and interpretation of large complex water quality data sets and apportionment of pollution sources/factors with a view to get better information about the water quality and design of monitoring network for effective management of water resources. Three significant groups, upper catchments (UC), middle catchments (MC) and lower catchments (LC) of sampling sites were obtained through CA on the basis of similarity between them. FA/PCA applied to the data sets pertaining to three catchments regions of the river resulted in seven, seven and six latent factors, respectively responsible for the data structure, explaining 74.3, 73.6 and 81.4% of the total variance of the respective data sets. These included the trace metals group (leaching from soil and industrial waste disposal sites), organic pollution group (municipal and industrial effluents), nutrients group (agricultural runoff), alkalinity, hardness, EC and solids (soil leaching and runoff process). DA showed the best results for data reduction and pattern recognition during both temporal and spatial analysis. It rendered five parameters (temperature, total alkalinity, Cl, Na and K) affording more than 94% right assignations in temporal analysis, while 10 parameters (river discharge, pH, BOD, Cl, F, PO4, NH4–N, NO3–N, TKN and Zn) to afford 97% right assignations in spatial analysis of three different regions in the basin. Thus, DA allowed reduction in dimensionality of the large data set, delineating a few indicator parameters responsible for large variations in water quality. Further, receptor modeling through multi-linear regression of the absolute principal component scores (APCS-MLR) provided apportionment of various sources/factors in respective regions contributing to the river pollution. It revealed that soil weathering, leaching and runoff; municipal and industrial wastewater; waste disposal sites leaching were among the major sources/factors responsible for river quality deterioration.
766897A3	Clustering is an efficient topology control method which balances the traffic load of the sensor nodes and improves the overall scalability and the life time of the wireless sensor networks (WSNs). However, in a cluster based WSN, the cluster heads (CHs) consume more energy due to extra work load of receiving the sensed data, data aggregation and transmission of aggregated data to the base station. Moreover, improper formation of clusters can make some CHs overloaded with high number of sensor nodes. This overload may lead to quick death of the CHs and thus partitions the network and thereby degrade the overall performance of the WSN. It is worthwhile to note that the computational complexity of finding optimum cluster for a large scale WSN is very high by a brute force approach. In this paper, we propose a novel differential evolution (DE) based clustering algorithm for WSNs to prolong lifetime of the network by preventing faster death of the highly loaded CHs. We incorporate a local improvement phase to the traditional DE for faster convergence and better performance of our proposed algorithm. We perform extensive simulation of the proposed algorithm. The experimental results demonstrate the efficiency of the proposed algorithm.
7E068751	Multivariate statistical techniques, such as cluster analysis (CA), principal component analysis (PCA), factor analysis (FA) and discriminant analysis (DA), were applied for the evaluation of temporal/spatial variations and the interpretation of a large complex water quality data set of the Fuji river basin, generated during 8 years (1995–2002) monitoring of 12 parameters at 13 different sites (14 976 observations). Hierarchical cluster analysis grouped 13 sampling sites into three clusters, i.e., relatively less polluted (LP), medium polluted (MP) and highly polluted (HP) sites, based on the similarity of water quality characteristics. Factor analysis/principal component analysis, applied to the data sets of the three different groups obtained from cluster analysis, resulted in five, five and three latent factors explaining 73.18, 77.61 and 65.39% of the total variance in water quality data sets of LP, MP and HP areas, respectively. The varifactors obtained from factor analysis indicate that the parameters responsible for water quality variations are mainly related to discharge and temperature (natural), organic pollution (point source: domestic wastewater) in relatively less polluted areas; organic pollution (point source: domestic wastewater) and nutrients (non-point sources: agriculture and orchard plantations) in medium polluted areas; and organic pollution and nutrients (point sources: domestic wastewater, wastewater treatment plants and industries) in highly polluted areas in the basin. Discriminant analysis gave the best results for both spatial and temporal analysis. It provided an important data reduction as it uses only six parameters (discharge, temperature, dissolved oxygen, biochemical oxygen demand, electrical conductivity and nitrate nitrogen), affording more than 85% correct assignations in temporal analysis, and seven parameters (discharge, temperature, biochemical oxygen demand, pH, electrical conductivity, nitrate nitrogen and ammonical nitrogen), affording more than 81% correct assignations in spatial analysis, of three different sampling sites of the basin. Therefore, DA allowed a reduction in the dimensionality of the large data set, delineating a few indicator parameters responsible for large variations in water quality. Thus, this study illustrates the usefulness of multivariate statistical techniques for analysis and interpretation of complex data sets, and in water quality assessment, identification of pollution sources/factors and understanding temporal/spatial variations in water quality for effective river water quality management.
7BF77DA5	In this paper, we consider an entropy criterion to estimate the number of clusters arising from a mixture model. This criterion is derived from a relation linking the likelihood and the classification likelihood of a mixture. Its performance is investigated through Monte Carlo experiments, and it shows favorable results compared to other classical criteria.
7E05645F	This paper introduces a new parallel programming model motivated by: 1) the concept that computation should move to, and execute near, the global data which it accesses, 2) a set of extended memory semantics to provide fine-grained global synchronization, 3) architectural support for fast lightweight thread creation/destruction/migration, and 4) the need for a high performance language to provide the programmer with transparency to the generated code while protecting them from making low-level errors. Using pseudocode examples, we compare this new model to several other high performance languages: Chapel, Fortress, and UPC, in terms of 1) expressibility of parallel structures, 2) facility in synchronizing communication to avoid race conditions, and 3) ability to diagnose/resolve possible performance issues that result from the mapping of these structures to hardware and system software. The new model, combined with appropriate architectural support, provides equal potential for expressibility and safety while giving the programmer more direct insight into the code that ultimately executes.
7D1222C0	Clustering is a very important tool in data mining and is widely used in on-line services for medical, financial and social environments. The main goal in clustering is to create sets of similar objects in a data set. The data set to be used for clustering can be owned by a single entity, or in some cases, information from different databases is pooled to enrich the data so that the merged database can improve the clustering effort. However, in either case, the content of the database may be privacy sensitive and/or commercially valuable such that the owners may not want to share their data with any other entity, including the service provider. Such privacy concerns lead to trust issues between entities, which clearly damages the functioning of the service and even blocks cooperation between entities with similar data sets. To enable joint efforts with private data, we propose a protocol for distributed clustering that limits information leakage to the untrusted service provider that performs the clustering. To achieve this goal, we rely on cryptographic techniques, in particular homomorphic encryption, and further improve the state of the art of processing encrypted data in terms of efficiency by taking the distributed structure of the system into account and improving the efficiency in terms of computation and communication by data packing. While our construction can be easily adjusted to a centralized or a distributed computing model, we rely on a set of particular users that help the service provider with computations. Experimental results clearly indicate that the work we present is an efficient way of deploying a privacy-preserving clustering algorithm in a distributed manner.
7FE8D880	Swarm intelligence forms the core of a new class of algorithms inspired by the social behavior of insects that live in swarms. Its attractive features include adaptation, robustness and a distributed, decentralized nature, rendering swarm-based algorithms well-suited for routing in wireless or satellite networks, where it is difficult it implement centralized network control. We propose one such routing algorithm, dubbed adaptive swarm-based distributed routing (adaptive-SDR), which is scalable, robust and suitable to handle large amounts of network traffic, while minimizing delay and packet loss.
7BBB7054	Here we tested the application of a nodal analysis for the elaboration of biotic indices for particular stressing conditions. The work was carried out in an intermittent Mediterranean stream where superficial flow was absent during summer. The river was perturbed by an effluent with high pH, sulphates, nitrates and conductivity. “Summer” and “winter” samples were treated separately. We first identified groups of sites differing in taxonomical composition by cluster analysis. Then we tested whether groups of sites also differed in their abiotic characteristics. In the following step, groups of cooccurring taxa were also identified by cluster analysis. The indicator value of a taxa group was measured by fidelity measurements for site groups. Indicator taxa were incorporated in a water quality table. The biotic index in the water quality table clearly discriminated impacted from reference sites in the two following years and was correlated with the first axis of a correspondence analysis biplot which also discriminated impacted from clean sites. We suggest that nodal analysis can be a reliable technique for the identification of bioindicators and the elaboration of biotic indices.
774C2C5B	In implementations of neuromorphic computing systems (NCS), memristor and its crossbar topology have been widely used to realize fully connected neural networks. However, many neural networks utilized in real applications often have a sparse connectivity, which is hard to be efficiently mapped to a crossbar structure. Moreover, the scale of the neural networks is normally much larger than that can be offered by the latest integration technology of memristor crossbars. In this work, we propose AutoNCS -- an EDA framework that can automate the NCS designs that combine memristor crossbars and discrete synapse modules. The connections of the neural networks are clustered to improve the utilization of the memristor elements in crossbar structures by taking into account the physical design cost of the NCS. Our results show that AutoNCS can substantially enhance the utilization efficiency of memristor crossbars while reducing the wirelength, area and delay of the physical designs of the NCS.