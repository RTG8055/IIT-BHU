7ED41F05	Voice activity detection (VAD) algorithms have become an integral part of many of the standardized wireless cellular and personal communications systems (PCS). We present a comparative study of the performance of three proposed VAD algorithms under various acoustical background noise conditions. We also propose new ideas to enhance the performance of a VAD algorithm in wireless PCS speech applications.
7B5F66BD	A robust algorithm for voice activity detection (VAD) is presented. It defines a likelihood ratio test (LRT) involving multiple and independent observations of the bispectra. The proposed VAD provides significant improvements in speech/pause discrimination when compared to standardised and recently reported VADs.
75280E8A	The author describes a voice activity detector (VAD) that can operate reliably in SNRs down to 0 dB and detect most speech at -5 dB. The detector applies a least-squares periodicity estimator to the input signal, and triggers when a significant amount of periodicity is found. It does not aim to find the exact talkspurt boundaries and, consequently, is most suited to speech-logging applications where it is easy to include a small margin to allow for any missed speech. The author discusses the problem of false triggering on nonspeech periodic signals and shows bow robustness to these signals can be achieved with suitable preprocessing and postprocessing.
7B3D178B	Simple active noise-canceling systems (such as noise canceling headphones) use a feedback mechanism whereby the signal recorded by a microphone placed near the loudspeaker is phase-inverted and sent back through the loudspeaker via a feedback filter. The feedback filter is designed to achieve a high gain at low frequencies (for best noise reduction) while maintaining closed-loop stability under various conditions. To design the feedback filter, fairly ad-hoc techniques were traditionally used under the broad denomination of "loop-shaping" until the advent in the 1980s of optimal Hinfin algorithms. The design technique outlined in this letter uses a cepstral domain approach, where gain and phase constraints take a convenient linear form, and linear programming to design the unique optimal feedback filter
7D10FBFF	Currently, there are technology barriers inhibiting speech processing systems that work in extremely noisy conditions from meeting the demands of modern applications. This letter presents a new voice activity detector (VAD) for improving speech detection robustness in noisy environments and the performance of speech recognition systems. The algorithm defines an optimum likelihood ratio test (LRT) involving multiple and independent observations. The so-defined decision rule reports significant improvements in speech/nonspeech discrimination accuracy over existing VAD methods that are defined on a single observation and need empirically tuned hangover mechanisms. The algorithm has an inherent delay that, for several applications, including robust speech recognition, does not represent a serious implementation obstacle. An analysis of the overlap between the distributions of the decision variable shows the improved robustness of the proposed approach by means of a clear reduction of the classification error as the number of observations is increased. The proposed strategy is also compared to different VAD methods, including the G.729, AMR, and AFE standards, as well as recently reported algorithms showing a sustained advantage in speech/nonspeech detection accuracy and speech recognition performance.
80BCCB77	In this letter, we propose a novel approach to voice activity detection (VAD) based on the modified maximum a posteriori (MAP) criterion conditioned on the voice activity decision made in the previous frame. To exploit the inter-frame correlation of voice activity, the probability of the voice presence conditioned on both the observed spectrum and the voice activity decision in the previous frame is employed instead of the conventional strategy that depends only on the current observation. The proposed conditional MAP criterion incorporating temporal correlations leads to two separate thresholds for the likelihood ratio test (LRT) depending on the previous VAD result. Experimental results show that the VAD based on the proposed conditional MAP criterion outperforms the VAD based on the conventional MAP criterion under various noise environments.
7DFD48D8	In this paper, a new method for voiced/nonvoiced detection based on epoch extraction is proposed. Zero-frequency filtered speech signal is used to extract the instants of significant excitation (or epochs). The robustness of the method to extract epochs in the voiced regions, even with small amount of additive white noise, is used to distinguish voiced epochs from random instants detected in nonvoiced regions. The main feature of the proposed method is that it uses the strength of glottal activity as against using the periodicity of the signal. Performance of the proposed algorithm is studied on TIMIT and CMU ARCTIC databases, for two different noise types, white and vehicle noise from the NOISEX database, at different signal-to-noise ratios (SNRs). The proposed method performs similar or better than the popular normalized crosscorrelation based voiced/nonvoiced detection used in the open source utility wavesurfer, especially at lower SNRs.
7F31EB2F	Discrete Fourier transforms are derived which allow the use of nonequally spaced time-domain samples. It is shown that the use of equal spacings in the logarithmic time and frequency domains provides a very efficient transform algorithm. The applicability of this algorithm for the analysis of systems with moderate dynamic behavior over several frequency decades is demonstrated by examples. An error analysis is given.
785CCF61	The instantaneous frequency of a signal may be uniquely defined from the analytical signal. However, for a Gaussian signal, this frequency has an infinite variance and is useless. Instead, amplitude-weighted instantaneous frequencies are often used. Here it is shown that if powers of the envelope Ak(t), k = 1, 2, 3,.. are used as weight factors, the first power minimizes the variance for a narrow-band signal.
805FB923	This correspondence presents a statistical analysis of frequency estimation using state-variable balancing for a single sinusoid in the presence of additive noise at high signal-to-noise ratios. The calculated variance is compared to the performance of the frequency estimation using linear prediction and the result is validated by simulations.
7EE0AE0C	A stand-alone noise suppression algorithm is presented for reducing the spectral effects of acoustically added noise in speech. Effective performance of digital speech processors operating in practical environments may require suppression of noise from the digital wave-form. Spectral subtraction offers a computationally efficient, processor-independent approach to effective digital speech analysis. The method, requiring about the same computation as high-speed convolution, suppresses stationary noise from speech by subtracting the spectral noise bias calculated during nonspeech activity. Secondary procedures are then applied to attenuate the residual noise left after subtraction. Since the algorithm resynthesizes a speech waveform, it can be used as a pre-processor to narrow-band voice communications systems, speech recognition systems, or speaker authentication systems.
7F66E47F	This paper presents a robust algorithm for a voice activity detector (VAD) based on generalized autoregressive conditional heteroscedasticity (GARCH) filter, variance gamma distribution (VGD), and adaptive threshold function. GARCH models are new statistical methods that are used especially in economic time series. There is a consensus that speech signals exhibit variances that change through time. GARCH models are a popular choice to model these changing variances. A speech signal is assumed to have a VGD because the VGD has heavier tails than the Gaussian distribution (GD). The distribution of noise signal is assumed to be Gaussian. In proposed method, heteroscedasticity will be modeled by GARCH, and then the parameters of the distributions will be estimated recursively. Finally, hard detection is the result of comparing a multiple observation likelihood ratio test (MOLRT) with an adaptive threshold function. The simulation results show that the proposed VAD is able to operate down to -5 dB and in nonstationary environments
7F5323F7	This paper presents a new method for voice activity detection (VAD) based on the autoregressive-generalized autoregressive conditional heteroscedasticity (AR-GARCH) model. The speech signal is modeled as an AR-GARCH process in the time domain, and the likelihood ratio is computed and compared to a threshold. The time-varying variance of the speech signal needed for computing the likelihood function under speech presence hypothesis, is estimated using the AR-GARCH model. The model parameters are estimated using a novel technique based on the recursive maximum likelihood (RML) estimation. The variance of the additive noise, a critical issue in designing a VAD, is estimated using the improved minima controlled recursive averaging (IMCRA) method, which is properly modified to be applicable to noise variance estimation in the time domain. The performances of the VAD and the parameter estimation method are examined under several conditions. Experimental results indicate the robustness of the AR-GARCH based VAD both to noise variations and low signal-to-noise ratio (SNR) conditions.
804AF37B	Traditionally, voice activity detection algorithms are based on any combination of general speech properties such as temporal energy variations, periodicity, and spectrum. This paper describes a novel statistical method for voice activity detection using a signal-to-noise ratio measure. The method employs a low-variance spectrum estimate and determines an optimal threshold based on the estimated noise statistics. A possible implementation is presented and evaluated over a large test set and compared to current modern standardized algorithms. The evaluations indicate promising results with the proposed scheme being comparable or favorable over the whole test set.
7D1784A0	Voice-based interaction generates a lot of interest for natural human-robot interaction. Auditory information from microphones is an essential clue for a robot's attention to a person. Fault detection of microphones is required in order to improve the reliability of the voice-based human-robot interaction. This paper proposes a new approach for real-time fault detection in a microphone array in conversation without a calibration signal and a known sound source position by the intercorrelation of features in voice activity detection. The approach is successfully applied to a six-microphone system, and experimental results show an average fault detection of 97.6%.
7B40D0BB	In this paper, we present a scheme to detect significantly overlapping transients buried in white Gaussian noise. A nonuniform M-band wavepacket decomposition algorithm using M-band, translation-invariant wavelet transform (NMTI) is developed, and its application to transient signal detection is discussed. The robustness of the NMTI-based detector is illustrated.
8123CF86	In this paper, by using the properties of the higher order statistics (HOS) of speech and noise signals, we develop an improved voice activity detection (VAD) scheme. The proposed scheme employs the logarithm of the kurtosis of the LPC residual of a speech signal and is shown to be more effective and efficient in detecting active speech in medium to low signal-to-noise ratio (SNR) conditions without being unduly affected by the variations in the signal energy. To overcome the inability of the HOS in detecting unvoiced speech, another metric (the low band to full band energy ratio) is introduced. Depending on the estimated mean SNR, the proposed scheme works adaptively in two modes: a simple mode using only the SNR, and an enhanced mode using the HOS, the low band to full band energy ratio and the SNR. This scheme is capable of avoiding unnecessary computations, while maintaining the same performance as that working only in the enhanced mode. Simulations results are presented to demonstrate the effectiveness of the proposed voice activity detection scheme.
7EEDE9E5	In this paper, we present a time domain aperiodicity, periodicity, and pitch (APP) detector that estimates 1) the proportion of periodic and aperiodic energy in a speech signal and 2) the pitch period of the periodic component. The APP system is particularly useful in situations where the speech signal contains simultaneous periodic and aperiodic energy, as in the case of breathy vowels and some voiced obstruents. The performance of the APP system was evaluated on synthetic speech-like signals corrupted with noise at various levels of signal-to-noise ratio (SNR) and on three different natural speech databases that consist of simultaneously recorded electroglottograph (EGG) and acoustic data. When compared on a frame basis (at a frame rate of 2.5 ms) the results show excellent agreement between the periodic/aperiodic decisions made by the APP system and the estimates obtained from the EGG data (94.43% for periodicity and 96.32% for aperiodicity). The results also support previous studies that show that voiced obstruents are frequently manifested with either little or no aperiodic energy, or with strong periodic and aperiodic components. The EGG data were used as a reference for evaluating the pitch detection algorithm. The ground truth was not manually checked to rectify or exclude incorrect estimates. The overall gross error rate in pitch prediction across the three speech databases was 5.67%. In the case of synthetic speech-like data, the estimated SNR was found to be in close proportion to the actual SNR, and the pitch was always accurately found regardless of the presence of any shimmer or jitter.
8096C0E7	A new fusion method for voice activity detection in additive nonstationary noise is suggested. A performance study of the methods: fusion, the geometrically adaptive energy level, periodicity measure, and zero crossings rates, is presented. The new method is shown to operate reliably down to -5 dB SNR.
76747C20	Voice activity detection (VAD) plays an important role on the performance of speech processing systems in adverse environments. Recently, statistical model-based VADs have demonstrated impressive performance. The study presents a novel decision test (named likelihood ratio sign test, LRST) for VAD by using sign test and Neyman-Pearson criterion to improve the performance of statistical model-based VAD. The proposed LRST is derived based on the likelihood ratios (LRs) calculated from multiple independent observations by incorporating the long-term speech information into the decision rule. An implementation of the LRST VAD is introduced by defining the LRST over a sliding window and calculating the LRs based on complex Gaussian distribution for an input signal. For experiments, the multiple-observation LRT (MO-LRT) VAD based on multiple observations is used as a reference owing to its outstanding performance compared with conventional VADs. The experimental results show that the proposed approach outperforms the MO-LRT VAD in various noise environments.
76D3AB89	The performance of traditional voice activity detectors significantly deteriorates in the presence of highly nonstationary noise and transient interferences. One solution is to incorporate a video signal which is invariant to the acoustic environment. Although several voice activity detectors based on the video signal were recently presented, merely few detectors which are based on both the audio and the video signals exist in the literature to date. In this paper, we present an audio-visual voice activity detector and show that the incorporation of both audio and video signals is highly beneficial for voice activity detection. The algorithm is based on a supervised learning procedure, and a labeled training data set is considered. The algorithm comprises a feature extraction procedure, where the features are designed to separate speech from nonspeech frames. Diffusion maps is applied separately and similarly to the features of each modality and builds a low dimensional representation. Using the new representation, we propose a measure for voice activity which is based on a supervised learning procedure and the variability between adjacent frames in time. The measures of the two modalities are merged to provide voice activity detection based on both the audio and the video signals. Experimental results demonstrate the improved performance of the proposed algorithm compared to state-of-the-art detectors.
75377BCA	Glottal activity is an important aspect of speech production that results in voiced speech, and localizing such regions for computing various parameters of the excitation source is useful in many speech processing applications. The aim of this paper is to investigate the ability of Empirical Mode Decomposition (EMD) and its noise assisted variants, in characterizing glottal activity from the speech signal. A pair of consecutive Intrinsic Mode Functions (IMFs), obtained from the decomposition is found to reflect the periodic nature of different voiced regions of the speech signal. This IMF pair is utilized to construct a signal, named the Glottal Intrinsic Mode Function (GIMF), which represents most of the voiced speech regions. To measure the capability of the GIMF in representing the glottal activity, it is applied to the tasks of Glottal Activity Detection (GAD), pitch frequency (F0) tracking and detecting pitch markers. The results ascertain the capability of EMD in localizing Glottal activity within a small subset of IMFs, and suggest the possibility of accurately extracting source-information from voiced speech with simple signal processing procedures.
754B0F91	This paper describes a method to detect repeating segments in an audio signal by using dynamic time warping algorithm. The proposed framework extracts features from frames of the audio by Mel frequency cepstral coefficients. The features extracted from the audio clip of the chorus were matched against the features of the whole clip by dynamic time warping. The number of matches found was determined by self similarity matrix. The experimental results indicate that the minimum distance matches between query and reference clip is successfully achieved. The proposed scheme was tested in a database of audio signals and the experimental results are encouraging. The proposed scheme was implemented and tested using a database of audio signals with accuracy up to 98%.
7F5ADE63	Speech coding is one of the major degradation involved in building the speech systems in mobile environment. In this paper, we are exploring the effect of low bit rate speech coding on the accuracy of detection of epochs. Epoch is referred as the instant of significant excitation of the vocal-tract system during production of speech. Many speech applications depend on the the accurate estimation of the epoch locations. Epoch extraction from speech signal is challenging due to time-varying characteristics of the excitation source and vocal-tract system. For determining the epochs, two recently developed accurate methods (i) zero frequency filter (ZFF) (ii) Dynamic programming projected phase slope (DYPSA) are used. Most of the epoch extraction methods except ZFF method, attempt to remove the characteristics of the vocal-tract system, in order to emphasize the excitation characteristics in the residual. ZFF method extracts the epoch locations directly from the speech signals using impulse like nature of excitation. Speech coders used in this study are GSM full rate (ETSI 06.10), CELP (FS-1016), and MELP (TI 2.4 kbps). Performance of epoch extraction methods is evaluated using CMU-Arctic data using the epoch locations from electro-glottograph as reference.
815E3783	Human whistle could be a way to perform activation of different kind of devices, for example turn on and off a light in a smart room. Therefore, in this paper a human whistle detection and frequency estimation system is presented. Further, an investigation of human whistling and a robust non-linear feature extraction is presented. A system for robust performance due to sensor change and various noise situations is proposed using these features. Experiments in various noise situations are conducted.
7EA7521D	An improved voice activity detection (VAD) based on the radial basis function neural network (RBF NN) and continuous wavelet transform (CWT) for speech recognition system is presented in the paper. The input speech signal is analyzed in the form of fixed size window by using Mel-frequency cepstral coefficients (MFCC). Within the windowed signal, the proposed RBF-CWT VAD algorithm detects the speech/ non-speech signal using the RBF NN. Once the interchange of speech to non-speech or vice versa occurred, the energy changes of the CWT coefficients are calculated to localize the final coordination of the starting/ending speech points. Instead of classifying the speech signal using the MFCC at the frame-level which easily capture lots of undesired noise encountered by the conventional VAD with the binary classifier, the proposed RBF NN with the aid of CWT analyzes the transformation of the MFCC at the window-level that offers a better compensation to the noisy signal. The simulation results shows an improvement on the precision of the speech detection and the overall ASR rate particularly under the noisy circumstances compared to the conventional VAD with the zero-crossing rate, short-term signal energy and binary classifier.
7AB9A301	In speech communication systems, the microphone signals are degraded by reverberation and ambient noise. The reverberant speech can be separated into two components, namely, an early speech component that includes the direct path and some early reflections, and a late reverberant component that includes all the late reflections. In this paper, a novel algorithm to simultaneously suppress early reflections, late reverberation and ambient noise is presented. A multi-microphone minimum mean square error estimator is used to obtain a spatially filtered version of the early speech component. The estimator constructed as a minimum variance distortionless response (MVDR) beamformer (BF) followed by a postfilter (PF). Three unique design features characterize the proposed method. First, the MVDR BF is implemented in a special structure, named the nonorthogonal generalized sidelobe canceller (NO-GSC). Compared with the more conventional orthogonal GSC structure, the new structure allows for a simpler implementation of the GSC blocks for various MVDR constraints. Second, In contrast to earlier works, RETFs are used in the MVDR criterion rather than either the entire RTFs or only the direct-path of the desired speech signal. An estimator of the RETFs is proposed as well. Third, the late reverberation and noise are processed by both the beamforming stage and the PF stage. Since the relative power of the noise and the late reverberation varies with the frame index, a computationally efficient method for the required matrix inversion is proposed to circumvent the cumbersome mathematical operation. The algorithm was evaluated and compared with two alternative multichannel algorithms and one single-channel algorithm using simulated data and data recorded in a room with a reverberation time of 0.5 s for various source-microphone array distances (1-4 m) and several signal-to-noise levels. The processed signals were tested using two commonly used objective measures, namely perceptual evaluation of speech quality and log-spectral distance. As an additional objective measure, the improvement in word accuracy percentage of an acoustic speech recognition system is also demonstrated.
7DAA7F69	This paper introduces two new frequency domain overdetermined blind source separation (BSS) algorithms: Inter-frequency Correlation with Microphone Diversity (ICMD), and ICA with Triggered Principal component analysis (ITP). In the first, we consider different sets of microphones, where in each set the number of microphones and sources are equal. In the second, we extract principal components from an overdetermined mixture to form a determined mixture for separation. Both techniques utilize inter-frequency correlation to align permutations via energy profiles. Both monitor the condition number of an inter-frequency cross-correlation matrix of the normalized de-mixed signals' envelopes to determine if separation has failed for the current ICA input configuration; if so, the input configuration is revised and efficiently realigned to produce a better mixture for separation. The complexities and performances of these algorithms are examined in both simulations and a real-room measurement, with three and five sources. They are also compared to other recent frequency domain BSS algorithms for benchmarking purposes. Results show that generally, ICMD and ITP show similar performance with each other and with one of the benchmarking algorithms. However, ICMD is more computationally efficient.
0AE7B73F	Automatic Speaker recognition (ASR) is a pattern recognition problem that involves the process of automatically recognizing the speakers from their voices. Password protected or secured speaker recognition system gives an extra security to the system where a person is not only identified by his voice but also needs to utter a particular password correctly in order to access the system. In this paper we present a new modeling scheme for a password protected speaker recognition system by cascading a modified RBF Neural Network using Kalman filtering approach (ANN) and a Dynamic Time Warping (DTW) model. We propose to use TESPAR (Time Encoded Signal Processing And Recognition) features for Speaker recognition and MFCC Coefficients for password recognition. The key problem is to define the TESPAR alphabet used for the TESPAR coding process. In this paper we propose an approach to generate this alphabet using the Kohenen Neural Networks in a Vector Quantization process. For the recognition process a modified RBF Neural Network using Extended Kalman filtering approach (ANN) is used. MFCC Coefficients using DTW based approach is used to verify the password related information. The combined model has been tested on 20 speakers with an overall accuracy of 98.82%.
7C0324A9	The beauty of human speech lies in the complexity of the different sounds that can be produced by a few tubes and muscles. This intricacy, however, makes speech processing a challenging task. One defining characteristic of speech is its pitch. Detecting this Pitch or equivalently, fundamental frequency detection of a speech signal is important in many speech applications. Pitch detectors are used in vocoders, speaker identification and verification systems and also as aids to the handicapped. Because of its importance many solutions to detect pitch has been proposed both in time and frequency domains. One such solution is pitch detection is by using Autocorrelation method and Average Magnitude Difference Function (AMDF), method which are analyses done in the time domain and the other is detecting the harmonic nature in the frequency domain. This paper gives the implementation results of the pitch period estimated in the time and frequency domains for vowel and fricative speech sounds, both for male and female speakers.
7722C102	The task of query-by-example spoken term detection (QbE-STD) is to find a spoken query within spoken audio data. Current state-of-the-art techniqu es assume zero prior knowledge about the language of the audio data, and thus explore dynamic time warping (DTW) based techniques for the QbE-STD task. In this paper, we use a variant of DTW based algorithm referred to as non-segmental DTW (NS-DTW), with a computational upper bound of and analyze the performance of QbE-STD with Gaussian posteriorgrams obtained from spectral and temporal features of the speech signal. The results show that frequency domain linear prediction cepstral coef fi cients, which capture the temporal dynamics of the speech signal, can be used as an alternative to traditional spectral parameters such as linear prediction cepstral coefficients, perceptual linear prediction cepstral coef fi cients and Mel-frequency cepstral coefficients. We also introduce another variant of NS-DTW called fast NS-DTW (FNS-DTW) which uses reduced feature vectors for search. With a reduction factor of , we show that the computational upper bound for 
81671F57	This paper examines a query-by-example approach to spoken term detection in audio files. The approach is designed for low-resource situations in which limited or no in-domain training material is available and accurate word-based speech recognition capability is unavailable. Instead of using word or phone strings as search terms, the user presents the system with audio snippets of desired search terms to act as the queries. Query and test materials are represented using phonetic posteriorgrams obtained from a phonetic recognition system. Query matches in the test data are located using a modified dynamic time warping search between query templates and test utterances. Experiments using this approach are presented using data from the Fisher corpus
7FDB6778	In this work, we propose a novel scheme to re-estimate the linear predictive parameters in sparse speech coding. The idea is to estimate the optimal truncated impulse response that creates the given sparse coded residual without distortion. An all-pole approximation of this impulse response is then found using a least square approximation. The all-pole approximation is a stable linear predictor that allows a more efficient reconstruction of the segment of speech. The effectiveness of the algorithm is proved in the experimental analysis.
8319BFE4	Traditional and fuzzy cluster analyses are applicable to variables whose values are uncorrelated. Hence, in order to cluster time series data which are usually serially correlated, one needs to extract features from the time series, the values of which are uncorrelated. The periodogram which is an estimator of the spectral density function of a time series is a feature that can be used in the cluster analysis of time series because its ordinates are uncorrelated. Additionally, the normalized periodogram and the logarithm of the normalized periodogram are also features that can be used. In this paper, we consider a fuzzy clustering approach for time series based on the estimated cepstrum. The cepstrum is the spectrum of the logarithm of the spectral density function. We show in our simulation studies for the typical generating processes that have been considered, fuzzy clustering based on the cepstral coefficients performs very well compared to when it is based on other features.
7776875F	This paper addresses the problem of automatically detecting infant crying sounds. Infant crying sounds show the distinct and regular time-frequency patterns that include a clear harmonic structure and a unique melody. Therefore, extracting appropriate features to properly represent these characteristics is important in achieving a good performance. In this paper, we propose weighted segment-based two-dimensional linear-frequency cepstral coefficients to characterize the time-frequency patterns within a long-range segment of the target signal. A Gaussian mixture model is adopted to statistically represent the crying and non-crying sounds, and test sounds are classified by using a likelihood ratio test. Evaluation of the proposed feature extraction method on a database of several hundred crying and non-crying sound clips yields an average equal error rate of 4.42% in various noisy environments, showing over 20% relative improvements compared to conventional feature extraction methods.
7E3F7F89	Dialog-act tagging is one of the hot topics in processing human-human conversation. In this paper, we introduce a novel model to predict and tag the dialog-act, in which Markov decision process (MDP) is utilized to predict the dialog-act sequence instead of using traditional dialog-act based n-gram, and Support Vector Machine (SVM) is employed to classify the dialog-act for each utterance. The predicting result of MDP and the classifying result of SVM are integrated as the final tagging. The experimental results have shown that our approach outperforms the traditional method.
7CF8DE0F	The conventional model of the linear prediction analysis suffers from difficulties in estimating vocal tract characteristics of high-pitched speakers. This paper shows that for voiced speech the vocal tract characteristics can be estimated accurately by homomorphic deconvolution in the autocorrelation domain. The speech autocorrelation function used by linear prediction is actually an 'aliased' version of that of the vocal tract system impulse response. This aliasing occurs due to the periodic nature of voiced speech. By using cepstrum analysis, the effect of this periodicity is eliminated from the autocorrelation function which is also periodic with the same periodicity as speech itself. The formant frequencies estimated using the deconvolved autocorrelation sequences of the system impulse response are found to be accurate by more than an order of magnitude when compared with the conventional linear prediction. The accuracy of formant estimation is verified on synthetic vowels for a wide range of pitch periods. The validity of the proposed method is also examined by inspecting the estimated spectral envelopes of real speech spoken by a female child.
805E033C	We discuss techniques for voice activity detection (VAD) for voice over Internet Protocol (VoIP). VAD aids in saving the bandwidth requirement of a voice session, thereby increasing the bandwidth efficiently. We compare the quality of speech, level of compression and computational complexity for three time-domain and three frequency-domain VAD algorithms. Implementation of time-domain algorithms is computationally simple. However, better speech quality is obtained with the frequency-domain algorithms. A comparison of the merits and demerits along with the subjective quality of speech after removal of silence periods is presented for all the algorithms. A quantitative measurement of speech quality for different algorithms is also presented.
7CA89D80	An  algorithm  is  presented  for  the  estimation  of  the  fundamental  frequency of  speech  or musical   sounds.   It   is   based   on   the   well-known   autocorrelation   method   with   a   number   of modifications  that  combine  to  prevent  errors. The  algorithm  has  several  desirable  features.  Error rates are about three times lower than the best competing methods, as evaluated over a database of speech  recorded  together  with  a  laryngograph  signal.  There  is  no  upper  limit  on  the  frequency search  range,  so  the  algorithm  is  suited  for  high-pitched  voices  and  music.  The  algorithm  is relatively  simple  and  may  be  implemented  efficiently  and  with  low  latency,  and  it  involves  few parameters that must be tuned. It is based on a signal model ~ periodic signal ! that may be extended in several ways to handle various forms of aperiodicity that occur in particular applications. Finally, interesting parallels may be drawn with models of auditory processing. 
7E1B495B	Currently, there are technology barriers inhibiting speech processing systems working under extreme noisy conditions. The emerging applications of speech technology, especially in the fields of wireless communications, digital hearing aids or speech recognition, are examples of such systems and often require a noise reduction technique operating in combination with a precise voice activity detector (VAD). This paper presents a new VAD algorithm for improving speech detection robustness in noisy environments and the performance of speech recognition systems. The algorithm measures the long-term spectral divergence (LTSD) between speech and noise and formulates the speech/non-speech decision rule by comparing the long-term spectral envelope to the average noise spectrum, thus yielding a high discriminating decision rule and minimizing the average number of decision errors. The decision threshold is adapted to the measured noise energy while a controlled hang-over is activated only when the observed signal-to-noise ratio is low. It is shown by conducting an analysis of the speech/non-speech LTSD distributions that using long-term information about speech signals is beneficial for VAD. The proposed algorithm is compared to the most commonly used VADs in the field, in terms of speech/non-speech discrimination and in terms of recognition performance when the VAD is used for an automatic speech recognition system. Experimental results demonstrate a sustained advantage over standard VADs such as G.729 and adaptive multi-rate (AMR) which were used as a reference, and over the VADs of the advanced front-end for distributed speech recognition.
76DFEEE9	An effective voice activity detection (VAD) algorithm is proposed for improving speech recognition performance in noisy environments. The proposed speech/pause discrimination method is based on a hard-decision clustering approach built on a set of subband log-energies and noise prototypes that define a cluster. Detecting the presence of speech (a new cluster) is achieved using a basic sequential algorithm scheme (BSAS) according to a given “distance” (in this case, geometrical distance) and a suitable threshold. The accuracy of the Cluster VAD (ClVAD) algorithm lies in the use of a decision function defined over a multiple-observation (MO) window of averaged subband log-energies and a suitable noise subspace model defined in terms of prototypes. In addition, the reduced computational cost of the clustering approach makes it adequate for real-time applications, i.e. speech recognition. An exhaustive analysis is conducted on the Spanish SpeechDat-Car databases in order to assess the performance of the proposed method and to compare it to existing standard VAD methods. The results show improvements in detection accuracy over standard VADs such as ITU-T G.729, ETSI GSM AMR and ETSI AFE and a representative set of recently reported VAD algorithms for noise robust speech processing.
7B245CA0	Nowadays, the accuracy of speech processing systems is strongly affected by acoustic noise. This is a serious obstacle regarding the demands of modern applications. Therefore, these systems often need a noise reduction algorithm working in combination with a precise voice activity detector (VAD). The computation needed to achieve denoising and speech detection must not exceed the limitations imposed by real time speech processing systems. This paper presents a novel VAD for improving speech detection robustness in noisy environments and the performance of speech recognition systems in real time applications. The algorithm is based on a Multivariate Complex Gaussian (MCG) observation model and defines an optimal likelihood ratio test (LRT) involving multiple and correlated observations (MCO) based on a jointly Gaussian probability distribution (jGpdf) and a symmetric covariance matrix. The complete derivation of the jGpdf-LRT for the general case of a symmetric covariance matrix is shown in terms of the Cholesky decomposition which allows to efficiently compute the VAD decision rule. An extensive analysis of the proposed methodology for a low dimensional observation model demonstrates: (i) the improved robustness of the proposed approach by means of a clear reduction of the classification error as the number of observations is increased, and (ii) the trade-off between the number of observations and the detection performance. The proposed strategy is also compared to different VAD methods including the G.729, AMR and AFE standards, as well as other recently reported algorithms showing a sustained advantage in speech/non-speech detection accuracy and speech recognition performance using the AURORA databases.
78881FBC	This paper proposes a noise robust voice activity detection (VAD) technique called PARADE (PAR based Activity DEtection) that employs the periodic component to aperiodic component ratio (PAR). Conventional noise robust features for VAD are still sensitive to non-stationary noise, which yields variations in the signal-to-noise ratio, and sometimes requires a priori noise power estimations, although the characteristics of environmental noise change dynamically in the real world. To overcome this problem, we adopt the PAR, which is insensitive to both stationary and non-stationary noise, as an acoustic feature for VAD. By considering both periodic and aperiodic components simultaneously in the PAR, we can mitigate the effect of the non-stationarity of noise. PARADE first estimates the fundamental frequencies of the dominant periodic components of the observed signals, decomposes the power of the observed signals into the powers of its periodic and aperiodic components by taking account of the power of the aperiodic components at the frequencies where the periodic components exist, and calculates the PAR based on the decomposed powers. Then it detects the presence of target speech signals by estimating the voice activity likelihood defined in relation to the PAR. Comparisons of the VAD performance for noisy speech data confirmed that PARADE outperforms the conventional VAD algorithms even in the presence of non-stationary noise. In addition, PARADE is applied to a front-end processing technique for automatic speech recognition (ASR) that employs a robust feature extraction method called SPADE (Subband based Periodicity and Aperiodicity DEcomposition) as an application of PARADE. Comparisons of the ASR performance for noisy speech show that the SPADE front-end combined with PARADE achieves significantly higher word accuracies than those achieved by MFCC (Mel-frequency Cepstral Coefficient) based feature extraction, which is widely used for conventional ASR systems, the SPADE front-end without PARADE, and other standard noise robust front-end processing techniques (ETSI ES 202 050 and ETSI ES 202 212). This result confirmed that PARADE can improve the performance of front-end processing for ASR.
79E74BEE	A new rescoring method for spoken term detection (STD) is proposed. Phoneme-based close-matching techniques have been used because of their ability to detect out-of-vocabulary (OOV) queries. To improve the accuracy of phoneme-based techniques, rescoring techniques have been used to accurately re-rank the results from phoneme-based close-matching; however, conventional rescoring techniques based on an utterance verification model still produce many false detection results. To further improve the accuracy, in this study, several features representing the “naturalness” (or “abnormality”) of duration of phonemes/syllables in detected candidates of a keyword are proposed. These features are incorporated into a conventional rescoring technique using logistic regression. Experimental results with a 604-hour Japanese speech corpus indicated that combining the rhythmic features achieved a further relative error reduction of 8.9% compared to a conventional rescoring technique.