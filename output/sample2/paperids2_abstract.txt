7ED83CC3	A fuzzy clustering algorithm is used for the image tree structure vector quantization (TSVQ). First, a digital image is divided into subblocks of fixed size, which consists of 4/spl times/4 blocks of pixels. By performing a 2-D discrete cosine transform (DCT), we select six DCT coefficients to form the feature vector, and use the fuzzy c-means algorithm in constructing the TSVQ codebook. By doing so, the algorithm can preserve the edge of image, make good image quality, and reduce the processing time while constructing the tree structured codebook, and reduce coding and decoding time.
8054BEFC	A convolution-based algorithm for computing the discrete cosine transform (DCT) (with power of two length) that is based on some theorems of number theory is proposed: It computes a length-N DCT (with N a power of two) using only N multiplications.
7B613B01	Video codecs operating at integral multiples of 64 kbps are well-known in visual communications technology as p * 64 systems (p equals 1 to 24). Originally developed as a class of ITU standards, these codecs have served as core technology for videoconferencing, and they have also influenced the MPEG standards for addressable video. Video compression in the above systems is provided by motion compensation followed by discrete cosine transform -- quantization of the residual signal. Notwithstanding the promise of higher bit rates in emerging generations of networks and storage devices, there is a continuing need for facile audiovisual communications over voice band and wireless modems. Consequently, video compression at bit rates lower than 64 kbps is a widely-sought capability. In particular, video codecs operating at rates in the neighborhood of 64, 32, 16, and 8 kbps seem to have great practical value, being matched respectively to the transmission capacities of basic rate ISDN (64 kbps), and voiceband modems that represent high (32 kbps), medium (16 kbps) and low- end (8 kbps) grades in current modem technology. The purpose of this talk is to describe the state of video technology at these transmission rates, without getting too literal about the specific speeds mentioned above. In other words, we expect codecs designed for non- submultiples of 64 kbps, such as 56 kbps or 19.2 kbps, as well as for sub-multiples of 64 kbps, depending on varying constraints on modem rate and the transmission rate needed for the voice-coding part of the audiovisual communications link. The MPEG-4 video standards process is a natural platform on which to examine current capabilities in sub-ISDN rate video coding, and we shall draw appropriately from this process in describing video codec performance. Inherent in this summary is a reinforcement of motion compensation and DCT as viable building blocks of video compression systems, although there is a need for improving signal quality even in the very best of these systems. In a related part of our talk, we discuss the role of preprocessing and postprocessing subsystems which serve to enhance the performance of an otherwise standard codec. Examples of these (sometimes proprietary) subsystems are automatic face-tracking prior to the coding of a head-and-shoulders scene, and adaptive postfiltering after conventional decoding, to reduce generic classes of artifacts in low bit rate video. The talk concludes with a summary of technology targets and research directions. We discuss targets in terms of four fundamental parameters of coder performance: quality, bit rate, delay and complexity; and we emphasize the need for measuring and maximizing the composite quality of the audiovisual signal. In discussing research directions, we examine progress and opportunities in two fundamental approaches for bit rate reduction: removal of statistical redundancy and reduction of perceptual irrelevancy; we speculate on the value of techniques such as analysis-by-synthesis that have proved to be quite valuable in speech coding, and we examine the prospect of integrating speech and image processing for developing next-generation technology for audiovisual communications
7591F8D7	This paper presents an efficient fast algorithm to reduce redundant discrete cosine transform (DCT) and quantization computations for H.264/AVC encoding optimization. A mathematic model is established based on analyzing residual coefficients distribution and considering the properties of DCT coefficientsenergy distribution. The experimental results demonstrate that the proposed approach can achieve the best performance in reducing the DCT and quantization(Q) computations and obtain almost the same video quality as the original encoder in H.264/AVC
7D506DE7	The MPEG committee has recently completed development of a new audio coding standard MPEG-4 Advanced Audio Coding-Enhanced Low Delay (AAC-ELD). AAC-ELD is targeted towards high-quality, full-duplex communication applications such as audio and video conferencing. AAC-ELD uses low delay spectral band replication (LD-SBR) technology together with a low delay AAC core encoder to achieve high coding efficiency and low algorithmic delays. In this paper, we present fast algorithms for computing LD-SBR filterbanks in AAC-ELD. The proposed algorithms map complex exponential modulation portion of the filterbanks to discrete cosine transforms of types IV and II. Our proposed mapping also allows to merge some multiplications with the windowing stage that precedes or succeeds the modulation step. This further reduces computational complexity. Our presentation includes detailed explanation and flow-graphs of the algorithms, complexity analysis, and comparisons with alternative implementations.
7F506E8E	Compressing an image is significantly different than compressing raw binary data. Evidently, general purpose compression algorithms can be used to compress images, but the result is less than optimal. Discrete Cosine Transform (DCT) has been widely used in signal processing of image. Joint Photographic Experts Group (JPEG) is a commonly used standard technique of compression for photographic images and in turn utilizes DCT. Apart from DCT, their also exist a decomposition algorithm well known as Singular Value Decomposition (SVD). The proposed schemes investigate the performance evaluation of variable quantization DCT and variable rank of image matrix SVD based image compression. The numerical analysis of such algorithms is carried out by measuring Peak Signal to Noise Ratio (PSNR), Compression Ratio (CR).
218C8616	 	Data compression has become an increasingly popular option as advances in information technology have placed further demands on data storage capabilities. With compression ratios as high as 100:1 the benefits are clear; however, the inherent intolerance of many compression formats to error events should be given careful consideration. If we consider that efficiently compressed data will ideally contain no redundancy, then the introduction of a channel error must result in a change of understanding from that of the original source. While the prefix property of codes such as Huffman enables resynchronisation, this is not sufficient to arrest propagating errors in an adaptive environment. Arithmetic, Lempel-Ziv, discrete cosine transform (DCT) and fractal methods are similarly prone to error propagating behaviors. It is, therefore, essential that compression implementations provide sufficient combatant error control in order to maintain data integrity. Ideally, this control should be derived from a full understanding of the prevailing error mechanisms and their interaction with both the system configuration and the compression schemes in use. 
7B8FFF7E	 2D fast cosine and sine transforms with regular structure are developed for 2n X 2n data points. These algorithms are extended versions of the 1D fast regular algorithms introduced in our recent paper. The rationale for these 2D algorithms for sine/cosine transforms in a 2D decomposition of data sequences into 2D subblocks with reduced dimension, rather than 1D, separable treatments for the columns and rows of the data sets. As a result the number of multiplications is 25 percent less than in row- column approach. Numerous algorithms of these type were proposed previously for discrete Fourier transform (DFT) and discrete cosine transform of type 2 (DCT-II). In DCT-II case the algorithms do not have a regular structure as is the case in DFT algorithms and motivation of this work is to derive 2D algorithms for discrete sine and cosine transforms with regular constant geometry structures. Extension to 2n X 2m data points is straightforward.
7D26715E	The authors present the design and performance evaluation of a robust, DCT-based (discrete-cosine-transform-based) variable-bit-rate (VBR) compression algorithm for use on B-ISDN/ATM networks. The algorithm class under consideration is based on a recent proposal by F. Kishino et al. (1989), intended to provide robust delivery of video under relatively high ATM cell loss conditions. The robust VBR codec is based on separation of subjectively important low-frequency DCT coefficients (for high-priority transport) from the less important high-frequency coefficients (which are sent at a lower priority level). Temporal propagation of error after loss of low-priority ATM cells is avoided by limiting interframe prediction to low-frequency information transmitted in high-priority cells. Several key questions that arise in the design of such an ATM codec are considered, including: (a) the trade-off between total bit-rate and robustness; (b) the influence of the high/low priority boundary parameter on the high-priority and low-priority bit-rates; and (c) performance at the decoder in the presence of ATM channel loss
813D8ACA	Discrete Tchebichef transform (DTT), derived from a discrete class of the popular Chebyshev polynomials, is a novel orthogonal transform that has high energy compaction and de-correlation properties. Therefore, in this paper, DTT is examined and treated for transform coding applications. A framework is laid to derive an approximation-free integer representation of DTT to meet the current application requirements. A fast algorithm is further proposed for multiplier-free computation of DTT. The image compression performance of the 4-point DTT is found to be superior to that of the 4-point discrete cosine transform (DCT) and integer cosine transform (ICT), the integer approximation of DCT. It is shown that the fast DTT is easily derived, has low complexity, does not involve approximations and can be carried out within the same dynamic range. Hence, DTT can be used for image and data compression applications. Since the image compression performance and computational simplicity of DTT are found to be significantly better than that of ICT, the use of DTT in place of ICT for transform coding in the H.264/AVC looks promising.
80D06662	Research of robust and invisible double digital watermark is one of the hot fields currently, and it has received considerable attention. To change the situation that many methods about watermarking are based on embedding one single watermark, a new double digital watermark algorithm on the basis of discrete cosine transformation and image blocks is presented. The algorithm embeds both robust watermark and fragile watermark to one video sequence by using DCT and multiple embedded methods. The later embedded fragile watermark is served for the early robust watermark. The experiment results verify the algorithm achieves better robustness and imperceptibility.
7686BE02	On the basis of the Mobius function, a two-stage algorithm for the discrete cosine transform (DCT) and the inverse DCT (IDCT) is proposed. In this approach, the DCT matrix is factorized into the preprocessing and postprocessing matrices. The preprocessing matrix has elements of values 1 and -1, and the postprocessing matrix is a circular convolution/correlation matrix.
7BCFEA89	In fractal image compression the encoding step is computationally expensive, because every range block must be compared to all domain blocks in the codebook to find the best-matched one during the coding procedure. In this paper, a fast classification algorithm using DCT coefficients is proposed. Simulation results show that the runtime of the proposed algorithm is reduced greatly compared to the existing methods. At the same time, the new algorithm also achieved high PSNR values
6F004731	Applications of bounded error parameter estimation in the field of image compression are described. A bounded error parameter estimator is shown to improve the performance of an adaptive predictive compression scheme. The quantization of discrete cosine transform coefficients is viewed from a parameter bounding perspective and bounds for the coefficient quantization error are derived. They can be used to keep the reconstructed image sample quantization error within bounds.
7D7F7051	We implement a two-dimensional 8/spl times/8 fast discrete cosine transform and its inverse by the Feig's algorithm which is recognized the fastest method so far and this algorithm potentially has very wide applications. All the equations are derived in detail. The verification and evaluation are proved by computer simulation. The result of real application in MPEG1 is also presented.
79046CE5	In this paper, a replacement algorithm for Linear Prediction Coefficients (LPC) along with Hamming Correction Code based Compressor (HCDC) algorithms are investigated for speech compression. We started with an CELP system with order 12 and with Discrete Cosine Transform (DCT) based residual excitation. Forty coefficients with transmission rate of 5.14 kbps were first used. For each frame of the testing signals we applied a multistage HCDC, we tested the compression performance for parities from 2 to 7, we were able to achieve compression only at parity 4. This rate reduction was made with no compromise in the original CELP signal quality since compression is lossless. The compression approach is based on constructing dynamic reflection coefficients codebook, this codebook is constructed and used simultaneously using a certain store/retrieve threshold. The initial linear prediction codec we used is excited by a discrete cosine transform (DCT) residual, the results were tested using the MOS and SSNR, we had acceptable ranges for the MOS (average 3.6), and small variations of the SSNR.
7B8ECF46	In this paper,a novel grayscale watermarking algorithm based on Two-Level Discrete Cosine Transform (DCT) and Singular Value Decomposition (SVD) is proposed. The watermark signal is bit gray image.First,The original image is divided into blocks according to the size of the watermark;each block corresponds to each pixel value of watermark.Second,the DCT is applied in each block twice and form new blocks.Then,perform SVD on each new block to get matrices U,S and V for each block.The pixel value of watermark is embedded into the largest singular value of S matrix of each new block.And the watermark can be detected with the original image.The experimental results show that the algorithm can satisfy the transparence and robustness of the watermarking system very well. Experimental evaluation demonstrates that the proposed scheme is able to withstand a variety of attacks.
5CFE86E1	The DFT is an important tool in digital signal processing. An effective index mapping is introduce by which the odd-length sinusoid-class orthogonal transforms, such as the generalised discrete Fourier transforms (GDFTs), generalised discrete Hartley transforms (GDHTs), discrete cosine transforms (DCTs) and discrete sine transforms (DSTs), can be converted to DFTs, real-valued DFTs (RDFTs) or DHTs of the same length, using primarily permutations and sign changes only. The algorithm proposed is more efficient than others previously published.
7B2F9E2B	this research presents a new algorithm for an image compression consist of three phases; the first phase is using "Discrete Wavelet Transformation (DWT)", to produce low-frequency and high-frequencies sub-bands. The high-frequencies sub-bands are ignored (i.e. not used in this research), in the second phase used "Discrete Cosine Transformation (DCT)" applied on each "2x2" block from "LL" sub-band, then each block stored as a one- dimensional array in the new matrix called "Multi-Array- Matrix (MA-Matrix)". The third phase; MA-Matrix separated into "DC-Column" and "MA2-Matrix", and then applied Minimize-Matrix-Size algorithm on the "MA2- Matrix", to be as a one-dimensional array. Our decompression algorithm phase starts from "Sequential Search Algorithm (SS-Algorithm)" to find the estimated values for the "MA2-Matrix". The SS-Algorithm depends on the three pointers, for decompress MA2-Matrix, and then combined it with DC-Column for reconstructs MA-Matrix. Finally the inverse DCT and the inverse DWT are used for reconstructs approximately original image. Our approach compared with JPEG and JPEG2000 by using PSNR. 
674BBF3E	An effective index mapping is introduced by which the odd-length sinusoid-class orthogonal transforms, such as GDFTs,GDHTs,DCTs and DSTs, can be converted to DFTs,real-valued DFTs (RDFTs) or DHTs of the same length,using primarily permutations and sign changes only.The algorithm proposed here is more efficient than others previously published. 
7EDB4A91	Fast recursive algorithms for the computation of the discrete cosine and sine transforms are developed. An N-point discrete cosine transform (DCT) or discrete sine transform (DST) can be computed from two N/2-point DCTs or DSTs. Compared to the existing algorithms the algorithms have less multiplications by two, and add operations are better positioned, giving rise to faster computation and easier VLSI implementation.
80E6A82C	An efficient direct method for the computation of a length-N discrete cosine transform (DCT) given two adjacent length-(N/2) DCT coefficients, is presented. The computational complexity of the proposed method is lower than the traditional approach for lengths N>8. Savings of N memory locations and 2N data transfers are also achieved.
7A61FB18	In this paper we present a new global method to derive invertible integer-to-integer mappings from given linear mappings . If is given by and Hn is an invertible matrix, then one can always find a suitable factor such that the condition is satisfied. An invertible mapping can now simply be defined by , and obviously, this nonlinear integer mapping is close to the linear mapping . We apply this idea in order to derive a new invertible integer DCT-II transform of radix-2 length and new integer wavelet algorithms. It turns out, that the expansion factors can be chosen very small.
76D04F48	The discrete cosine transform (DCT) is widely applied in various fields, including image data compression, because it operates like the Karhunen-Loeve transform for stationary random data. This paper presents a recursive algorithm for DCT with a structure that allows the generation of the next higher order DCT from two identical lower order DCT's. As a result, the method for implementing this recursive DCT requires fewer multipliers and adders than other DCT algorithms.
7FC2B1C0	Recently, many applications for three-dimensional (3-D) image and video compression have been proposed using 3-D discrete cosine transforms (3-D DCTs). Among different types of DCTs, the type-II DCT (DCT-II) is the most used. In order to use the 3-D DCTs in practical applications, fast 3-D algorithms are essential. Therefore, in this paper, the 3-D vector-radix decimation-in-frequency (3-D VR DIF) algorithm that calculates the 3-D DCT-II directly is introduced. The mathematical analysis and the implementation of the developed algorithm are presented, showing that this algorithm possesses a regular structure, can be implemented in-place for efficient use of memory, and is faster than the conventional row-column-frame (RCF) approach. Furthermore, an application of 3-D video compression-based 3-D DCT-II is implemented using the 3-D new algorithm. This has led to a substantial speed improvement for 3-D DCT-II-based compression systems and proved the validity of the developed algorithm.
781655CB	In this paper, 3-D discrete Hartley transform is applied for the compression of two medical modalities, namely, magnetic resonance images and X-ray angiograms and the performance results are compared with those of 3-D discrete cosine and Fourier transforms using the parameters such as PSNR and bit rate. It is shown that the 3-D discrete Hartley transform is better than the other two transforms for magnetic resonance brain images whereas for the X-ray angiograms, the 3-D discrete cosine transform is found to be superior.
7FE3364C	Recently, a fast radix-q algorithm for an efficient computation of the type-IV discrete cosine transform (DCT-IV) has been proposed in , where q is an odd positive integer. In particular, based on the proposed fast algorithm, optimized efficient 3-, 5-, and 9-point scaled DCT-IV (SDCT-IV) modules have been derived in . As a response, an improved efficient optimized 9-point scaled DCT-IV (SDCT-IV) module in terms of the arithmetic complexity is presented. The improved optimized efficient 9-point SDCT-IV module requires 17 multiplications, 53 additions, and three shifts. Consequently, the arithmetic complexity of extended fast mixed-radix DCT-IV algorithm for composite lengths is also significantly improved.
7FD3F0EB	An index permutation-based fast two-dimensional discrete cosine transform (2-D DCT) algorithm is presented. It is shown that the N/spl times/N 2-D DCT, where N=2/sup m/, can be computed using only N 1-D DCTs and some post additions.
7E68A6E2	The discrete cosine transform (DCT) is often computed from a discrete Fourier transform (DFT) of twice or four times the DCT length. DCT algorithms based on identical-length DFT algorithms generally require additional arithmetic operations to shift the phase of the DCT coefficients. It is shown that a DCT of odd length can be computed by an identical-length DFT algorithm, by simply permuting the input and output sequences. Using this relation, odd-length DCT modules for a prime factor DCT are derived from corresponding DFT modules. The multiplicative complexity of the DCT is then derived in terms of DFT complexities.
77C93D55	The modified discrete cosine transform (MDCT) and modified discrete sine transform (MDST) are employed in subband/transform coding schemes as the analysis/synthesis filter banks based on the concept of time domain aliasing cancellation (TDAC). Princen, Bradley and Johnson defined two types of the MDCT, specifically, for an evenly stacked and oddly stacked analysis/synthesis systems. The MDCT is the basic processing component in the international audio coding standards and commercial products for high-quality audio compression. Almost all existing audio coding systems have used the complex-valued or real-valued FFT algorithms, and the DCT/DST of type IV (DCT-IV/DST-IV) for the fast MDCT computation. New fast and efficient algorithm for a unified forward and inverse MDCT/MDST computation in the oddly stacked system is proposed. It is based on the DCT/DST of types II and III (DCT-II/DST-II, DCT-III/DST-III), and the real arithmetic is used only. Corresponding generalized signal flow graph is regular, structurally simple and enables to compute MDCT/MDST and their inverses in general for any N divisible by 4 (N being length of a data sequence). Consequently, the new fast algorithm can be adopted for the MDCT computation in the current audio coding standards such as MPEG family (MPEG-1, MPEG-2, MPEG-2 Advanced Audio Coding and MPEG-4 audio), and in commercial products (proprietary audio coding algorithms) such as Sony MiniDisc/ATRAC/ATRAC2/SDDS digital audio coding systems, the AT&T Perceptual Audio Coder (PAC) or Lucent Technologies PAC/Enhanced PAC/Multichannel PAC, and Dolby Labs AC-3 digital audio compression algorithm. Besides the new fast algorithm has some interesting properties, it provides an efficient implementation of the forward and inverse MDCT computation for layer III in MPEG audio coding, where the length of data blocks. Especially, for the AC-3 algorithm, it is shown how both the proposed new MDCT/MDST algorithm and existing fast algorithms/computational architectures for the discrete sinusoidal transforms computation of real data sequences such as the DCT-IV/DST-IV, generalized discrete Fourier transform of type IV (DFT-IV) and generalized discrete Hartley transform of type IV (DHT-IV) can be used for the fast alternate or simultaneous (on-line) MDCT/MDST computation by simple pre- and post-processing of data sequences.
78363BC0	Integer DCTs have a wide range of applications in lossless coding, especially in image compression. An integer-to-integer DCT of radix-2-length n is a nonlinear, left-invertible mapping, which acts on /spl Zopf//sup n/ and approximates the classical discrete cosine transform (DCT) of length n. All known integer-to-integer DCT-algorithms of length 8 are based on factorizations of the cosine matrix C/sub 8//sup II/ into a product of sparse matrices and work with lifting steps and rounding off. For fast implementation one replaces floating point numbers by appropriate dyadic rationals. Both rounding and approximation leads to truncation errors. In this paper, we consider an integer-to-integer transform for (2/spl times/2) rotation matrices and give estimates of the truncation errors for arbitrary approximating dyadic rationals. Further, using two known integer-to-integer DCT-algorithms, we show examplarily how to estimate the worst-case truncation error of lifting based integer-to-integer algorithms in fixed-point arithmetic, whose factorizations are based on (2/spl times/2) rotation matrices.
7D10C675	In this paper, we first propose an efficient algorithm for computing one-dimensional (1-D) discrete cosine transform (DCT) for a signal block, given its two adjacent subblocks in the DCT domain and then introduce several algorithms for the fast computation of multidimensional (m-D) DCT with size N/sub 1//spl times/N/sub 2//spl times/.../spl times/N/sub m/ given 2/sup m/ subblocks of DCT coefficients with size N/sub 1//2/spl times/N/sub 2//2/spl times/.../spl times/N/sub m//2, where N/sub i/(i=1,2,...,m) are powers of 2. Obviously, the row-column method, which employs the most efficient algorithms along each dimension, reduces the computational complexity considerably, compared with the traditional method, which employs only the one-dimensional (1-D) fast DCT and inverse DCT (IDCT) algorithms. However, when m/spl ges/2, the traditional method, which employs the most efficient multidimensional DCT/IDCT algorithms, has lower computational complexity than the row-column method. Besides, we propose a direct method by dividing the data into 2/sup m/ parts for independent fast computation, in which only two steps of r-dimensional (r=1,2,...,m) IDCT and additional multiplications and additions are required. If all the dimensional sizes are the same, the number of multiplications required for the direct method is only (2/sup m/-1)/m2/sup m-1/ times of that required for the row-column method, and if N/spl ges/2/sup 2m-1/, the computational efficiency of the direct method is surely superior to that of the traditional method, which employs the most efficient multidimensional DCT/IDCT algorithms.
7EBEC735	An efficient method for computing the discrete cosine transform (DCT) is proposed. Based on direct decomposition of the DCT, the recursive properties of the DCT for an even length input sequence is derived, which is a generalization of the radix 2 DCT algorithm. Based on the recursive property, a new DCT algorithm for an even length sequence is obtained. The proposed algorithm is very structural and requires fewer computations when compared with others. The regular structure of the proposed algorithm is suitable for fast parallel algorithm and VLSI implementation.
7F77E0BA	The discrete cosine transform (DCT) and the discrete sine transform (DST) have found wide applications in speech and image processing, as well as telecommunication signal processing for the purpose of data compression, feature extraction, image reconstruction, and filtering. In this paper, we present new recursive algorithms for the DCT and the DST. The proposed method is based on certain recursive properties of the DCT coefficient matrix, and can be generalized to design recursive algorithms for the 2-D DCT and the 2-D DST. These new structured recursive algorithms are able to decompose the DCT and the DST into two balanced lower-order subproblems in comparison to previous research works. Therefore, when converting our algorithms into hardware implementations, we require fewer hardware components than other recursive algorithms. Finally, we propose two parallel algorithms for accelerating the computation.
781849EC	Integer DCTs have important applications in lossless coding. In this paper, an integer DCT of radix-2 length n is understood to be a nonlinear, (left-)invertible mapping which acts on and approximates the classical discrete cosine transform (DCT) of length n. In image compression, the DCT of type II (DCT-II) is of special interest. In this paper we present a new approach to invertible integer DCT-II and integer DCT-IV. Our method is based on a factorization of the cosine matrices of types II and IV into products of sparse, orthogonal matrices. Up to some permutations, each matrix factor is a block-diagonal matrix with blocks being orthogonal matrices of order 2. Hence one has to construct only integer transforms of length 2. We factorize an orthogonal matrix of order 2 into three lifting matrices and work with lifting steps and rounding-off. This allows the construction of new integer DCT algorithms. We give uniform bounds for the worst case difference between the results of exact DCT and the corresponding integer DCT. Finally, we present some numerical experiments for the integer DCT-II of length 8 and for the 2-dimensional integer DCT-II of size 8 8.
7F3438A9	This tutorial paper describes the methods for constructing fast algorithms for the computation of the discrete Fourier transform (DFT) of a real-valued series. The application of these ideas to all the major fast Fourier transform (FFT) algorithms is discussed, and the various algorithms are compared. We present a new implementation of the real-valued split-radix FFT, an algorithm that uses fewer operations than any other real-valued power-of-2-length FFT. We also compare the performance of inherently real-valued transform algorithms such as the fast Hartley transform (FHT) and the fast cosine transform (FCT) to real-valued FFT algorithms for the computation of power spectra and cyclic convolutions. Comparisons of these techniques reveal that the alternative techniques always require more additions than a method based on a real-valued FFT algorithm and result in computer code of equal or greater length and complexity.
7D05A275	As the circuit complexity is increasing in demand for the more computations on a single VLSI chip, low power VLSI design has become important specially for portable devices powered by battery. Digital camera is one of them where realtime image capturing, compression and storage of compressed image data is done. Most of the digital camera implement JPEG baseline algorithm to store highly compressed image in camera memory. In this paper we report and present low cost, low power and computationally efficient circuit design of JPEG for digital camera to get highly compressed image by exploiting removal of subjective redundancy from the image.
7C5BD5F9	A systematic method of sparse matrix factorization is developed for all four versions of the discrete W transform, the discrete cosine transform, and the discrete sine transform, as well as for the discrete Fourier transform. The factorization leads to fast algorithms in which only real arithmetic is involved. A scheme for reducing multiplications and a convenient index system are introduced. This makes new algorithms more efficient than conventional algorithms for the discrete Fourier transform, the discrete cosine transform, and the discrete sine transform.
79411F44	The fast Hartley transform (FHT) is similar to the Cooley-Tukey fast Fourier transform (FFT) but performs much faster because it requires only real arithmetic computations compared to the complex arithmetic computations required by the FFT. Through use of the FHT, discrete cosine transforms (DCT) and discrete Fourier transforms (DFT) can be obtained. The recursive nature of the FHT algorithm derived in this paper enables us to generate the next higher order FHT from two identical lower order FHT's. In practice, this recursive relationship offers flexibility in programming different sizes of transforms, while the orderly structure of its signal flow-graphs indicates an ease of implementation in VLSI.
7576CA59	A new VLSI algorithm and its associated systolic array architecture for a prime length type IV discrete cosine transform is presented. They represent the basis of an efficient design approach for deriving a linear systolic array architecture for type IV DCT. The proposed algorithm uses a regular computational structure called pseudoband correlation structure that is appropriate for a VLSI implementation. The proposed algorithm is then mapped onto a linear systolic array with a small number of I/O channels and low I/O bandwidth. The proposed architecture can be unified with that obtained for type IV DST due to a similar kernel. A highly efficient VLSI chip can be thus obtained with good performance in the architectural topology, computing parallelism, processing speed, hardware complexity and I/O costs similar to those obtained for circular correlation and cyclic convolution computational structures.
7EDD5239	This correspondence presents an odd-factor algorithm for the type-III discrete cosine transform (DCT) for uniform or mixed radix decomposition. By jointly using the old-factor and the existing radix-2 algorithms, a general decomposition method for arbitrarily composite sequence length is developed. A reduction of computational complexity can be achieved compared with that needed by other reported algorithms for M=2/sup m/. The decomposition approach has a simple computational structure and supports a wider range of choices for different sequence lengths.
5937B17A	By combining the polynomial transform and radix-q decomposition, the paper presents a new algorithm for the type-III r-dimensional discrete Cosine transform (rD-DCT-III) with size ql1 ql2  ...  qlr, where q is an odd prime number. The number of multiplications for computing an rD-DCT-III is approximately 1/r times that needed by the row-column method while the number of additions increase slightly. The total number of operations (additions plus multiplications) is also reduced. The proposed algorithm has a simple computational structure because it needs only 1D-DCT-III and the polynomial transform.
75538016	Discrete cosine transforms (DCT) are essential tools in numerical analysis and digital signal processing. Processors in digital signal processing often use fixed point arithmetic. In this paper, we consider the numerical stability of fast DCT algorithms in fixed point arithmetic. The fast DCT algorithms are based on known factorizations of the corresponding cosine matrices into products of sparse, orthogonal matrices of simple structure. These algorithms are completely recursive, are easy to implement and use only permutations, scaling, butterfly operations, and plane rotations/rotation-reflections. In comparison with other fast DCT algorithms, these algorithms have low arithmetic costs. Using von Neumann Goldstine model of fixed point arithmetic, we present a detailed roundoff error analysis for fast DCT algorithms in fixed point arithmetic. Numerical tests demonstrate the performance of our results.
81736770	A new algorithm for the type-II multidimensional discrete cosine transform (MD-DCT) is proposed. Based on the polynomial transform, the rD-DCT with size N/sub 1//spl times/N/sub 2//spl times//spl middot//spl middot//spl middot//spl times/N/sub r/, where N/sub i/ is a power of 2, can be converted into a series of one dimensional (1-D) discrete cosine transforms (DCTs). The algorithm achieves considerable savings on the number of operations compared with the row-column method. For example, the number of multiplications for computing an r-dimensional DCT is only 1/r times that needed by the row-column method, and the number of additions is also reduced. Compared with other known polynomial transform algorithms for MD-DCT and the most recently presented algorithm for MD-DCT, the proposed one uses about the same number of operations. However, advantages such as better computational structure and flexibility in the choice of dimensional sizes can be achieved.
7D843341	A Fast Discrete Cosine Transform algorithm has been developed which provides a factor of six improvement in computational complexity when compared to conventional Discrete Cosine Transform algorithms using the Fast Fourier Transform. The algorithm is derived in the form of matrices and illustrated by a signal-flow graph, which may be readily translated to hardware or software implementations.
7B64D19B	The discrete cosine transform of type IV (DCT-IV) and corresponding discrete sine transform of type IV (DST-IV) have played key role in the efficient implementation of orthogonal lapped transforms and perfect reconstruction cosine-modulated filter banks such as the oddly stacked modified discrete cosine transform (MDCT) or equivalently, the modulated lapped transform (MLT). However, the DCT-IV and DST-IV of double sizes are related to two variants of filter banks defined by Dolby Labs AC-3 digital audio compression algorithm. Since these two variants of filter banks are efficiently computed by recently proposed new fast algorithm for the oddly stacked MDCT (Signal Processing 82 (2002) 433), it is shown that the efficient DCT-IV and DST-IV computation can be realized via the MDCT of double size. The careful analysis of regular structure of the new fast MDCT algorithm allows to extract a new DCT-IV/DST-IV computational structure and to suggest a new sparse matrix factorization of the DCT-IV matrix. Finally, the new DCT-IV/DST-IV computational structure provides an alternative efficient implementation of the forward and inverse MDCT in layer III of MPEG (MP3) audio coding.
7A1904AD	A new recursive algorithm and two types of circuit architectures are presented for the computation of the two-dimensional discrete cosine transform (2D DCT). The new algorithm permits to compute the 2D DCT by a simple procedure of the 1D recursive calculations involving only cosine coefficients. The recursive kernel for the proposed algorithm contains a small number of operations. Also, it requires a smaller number of pre-computed data compared with many of existing algorithms in the same category. The kernel can be easily implemented in a simple circuit block with a short critical delay path. In order to evaluate the performance improvement resulting from the new algorithm, an architecture for the 2D DCT designed by direct mapping from the computation structure of the proposed algorithm has been implemented in an FPGA board. The results show that the reduction of the hardware consumption can easily reach 25 and the clock frequency can increase 17 compared with a system implementing a recently reported 2D DCT recursive algorithm. For a further reduction of the hardware, another architecture has been proposed for the same 2D DCT computation. Using one recursive computation block to perform different functions, this architecture needs only approximately one-half of the hardware that is required in the first architecture, which has been confirmed by an FPGA implementation.
7FA005E7	This letter proposes a fast radix-q algorithm to compute type-IV discrete cosine transform (DCT) of the length qlambda, where q is an odd positive integer. The proposed fast radix-q algorithm has merits in computational complexity, parallelism, and numerical stability over existing algorithms. Furthermore, the fast radix-q algorithm is used to develop the fast mixed-radix type-II/ type-IV DCT algorithm for composite lengths.
801D5F6A	A method is proposed to factor the type-II discrete cosine transform (DCT-II) into lifting steps and additions. After approximating the lifting matrices, we get a new type-II integer discrete cosine transform (IntDCT-II) that is float-point multiplication free. Based on the relationships among the various types of DCTs, we can generally factor any DCTs into lifting steps and additions and then get four types of integer DCTs, which need no float-point multiplications. By combining the polynomial transform and the one-dimensional (1-D) integer cosine transform, a two-dimensional (2-D) integer discrete cosine transform is proposed. The proposed transform needs only integer operations and shifts. Furthermore, it is nonseparable and requires a far fewer number of operations than that used by the corresponding row-column 2-D integer discrete cosine transform.
7E83E2D3	In this paper, a generalized fast computational algorithm for the n-dimensional discrete cosine transform (DCT) of length N=2/sup m/ (m/spl ges/2) is presented. The developed algorithm is proved and its efficiency is evaluated theoretically. The theoretical results show that compared with the conventional method of computing the one-dimensional along n directions, the number of multiplications needed by our algorithm is only 1/n of that required by the conventional method; for the total number of additions, the latter is a bit more when N/spl les/8 and much fewer when N/spl ges/16 than the former. To validate the proposed algorithm, we take the case when n=3 as an example and apply it to motion-picture coding. The results show that our method is superior to MPEG-2 in speed and coding performance. The algorithm is clearly described and it is easy to make a computer program for implementation.
7D419CF0	New algorithms are proposed for the type-III multidimensional discrete cosine transform (MD-DCT-III). The polynomial transform is used to convert the type-III MD-DCT into a series of one-dimensional type-III discrete cosine transforms (1-D-DCT-III). The algorithms achieve considerable savings on the number of operations compared to the row column method. For computing an r-dimensional DCT-III, the number of multiplications required by the proposed algorithm is only 1//spl tau/ times that needed by the row-column method, and the number of additions is also reduced. Compared to other known fast algorithms for two-dimensional- and MD-DCTs, the proposed method uses about the same number of operations. However, advantages such as better computational structure and flexibility on the choice of dimensional sizes can be achieved.
77E8F1CA	Due to technology scaling trends, the accurate and efficient calculations of the temperature distribution corresponding to a specific circuit layout and power density distribution will become indispensable in the design of high-performance very large scale integrated circuits. In this paper, we present three highly efficient thermal simulation algorithms for calculating the on-chip temperature distribution in a multilayered substrate structure. All three algorithms are based on the concept of the Green function and utilize the technique of discrete cosine transform. However, the application areas of the algorithms are different. The first algorithm is suitable for localized analysis in thermal problems, whereas the second algorithm targets full-chip temperature profiling. The third algorithm, which combines the advantages of the first two algorithms, can be used to perform thermal simulations where the accuracy requirement differs from place to place over the same chip. Experimental results show that all three algorithms can achieve relative errors of around 1% compared with that of a commercial computational fluid dynamic software package for thermal analysis, whereas their efficiencies are orders of magnitude higher than that of the direct application of the Green function method.
7D9FC910	Advances in wavelet transforms and quantization methods have produced algorithms capable of surpassing the existing image compression standards like the Joint Photographic Experts Group (JPEG) algorithm. The existing compression methods for JPEG standards are using DCT with arithmetic coding and DWT with Huffman coding. The DCT uses a single kernel where as wavelet offers more number of filters depends on the applications. The wavelet based Set Partitioning In Hierarchical Trees (SPIHT) algorithm gives better compression. For best performance in image compression, wavelet transforms require filters that combine a number of desirable properties, such as orthogonality and symmetry, but they cannot simultaneously possess all of these properties. The relatively new field of multiwavelets offer more design options and can combine all desirable transform features. But there are some limitations in using the SPIHT algorithm for multiwavelet coefficients. This paper presents a new method for encoding the multiwavelet decomposed images by defining coefficients suitable for SPIHT algorithm which gives better compression performance over the existing methods in many cases.
7E0F3E15	The Discrete Tchebichef Transform (DTT) which based on discrete orthogonal Tchebichef polynomials can be an alternative to the Discrete Cosine Transform (DCT) for image processing such as image compression and image recognition as the properties of the DTT are similar to that of the DCT. The DTT not only has higher energy compactness than the DCT in images that have high illumination value variations such as artificial diagrams but also has the advantage of easily computation using a set of recurrence relations. In this paper, the DTT will be introduced with explanation of its similarity to DCT, also a new fast and efficient 4x4 algorithm for computing the DTT coefficients which can be used in image compression will be proposed. This algorithm reduces computational complexity as measured in terms of the number of arithmetic operations while keeping the accuracy of the reconstructed images. 
8112BD3C	Recently,  with  the  advances  in  digital  signal  processing,  compression  of  biomedical  signals  has  received  great attention for telemedicine applications. In this paper, an adaptive transform  coding-based  method  for  compression  of  respiratory and  swallowing  sounds  is  proposed.  Using  special  characteristics  of  respiratory  sounds,  the  recorded  signals  are  divided  into stationary and nonstationary portions, and two different bit allocation methods (BAMs) are designed for each portion. The method was applied to the data of 12 subjects and its performance in terms of overall signal-to-noise ratio (SNR) values was calculated at different bit rates. The performance of different quantizers was also considered  and  the  sensitivity  of  the  quantizers  to  initial  conditions has been alleviated. In addition, the fuzzy clustering method was examined for classifying the signal into different numbers of clusters and investigating the performance of the adaptive BAM with increasing the number of classes. Furthermore, the effects of assigning  different  numbers  of  bits  for  encoding  stationary  and nonstationary  portions  of  the  signal  were  studied.  The  adaptive BAM with variable number of bits was found to improve the SNR values of the fixed BAM by 5 dB. Last, the possibility of removing the  training  part  for  finding  the  parameters  of  adaptive  BAMs for  each individual was  investigated. The results indicate that it is  possible  to  use  a  predefined  set  of  BAMs  for  all  subjects  and remove the training part completely. Moreover, the method is fast enough to be implemented for real-time application.
76FFC627	In this paper introduce new idea for image compression based on the two levels DWT. The low-frequency sub-band is minimized by using DCT with the Minimize-Matrix-Size-Algorithm, which is converting the AC-coefficients into array contains stream of real values, and then store the DC-coefficients are stored in a column called DC-Column. DC-Column is transformed by one-dimensional DCT to be converted into T-Matrix, then T-Matrix compressed by RLE and arithmetic coding. While the high frequency sub-bands are compressed by the technique; Eliminate Zeros and Store Data (EZSD). This technique eliminates each 8 × 8 sub-matrix contains zeros from the high frequencies sub-bands, in another hands store nonzero  data in an array.The results of our compression algorithm compared with JPEG2000 by using four different gray level images. 
80A84DE7	This paper presents a robust image watermarking method in discrete cosine transform (DCT) domain based on chaotic sequences encryption. Exploiting some characteristics of Human Visual System (HVS) and DC(Direct Current) components having much larger perceptual capacity than any AC (Alternating Current)components, watermark is embedded into the DC components of the host image. First, we scramble the watermark image to avoid the block effect. Then we split the host image and the scrambled watermark image into 8×8block respectively, and the scrambled watermark is embedded into the DC components of the host image. The experimental results show that the embedded watermark is invisible and robust against noise and commonly used image processing methods such as Gaussian, JPEG compression, Median filtering etc
792E12D0	A modified discrete Fourier-cosine transform (DFCT) algorithm and its VLSI implementation on a high speed VLSI chip are presented. The proposed DFCT algorithm achieves a considerably higher throughput rate when compared to other implementations by exploiting the inherent parallelism of the new flowgraph, proposed for the DFCT algorithm, to the full. DFCTs of greater length and two dimensional DFCTs can be performed by a set of such chips, at board level. 1.2 DLM CMOS technology was used for the implementation of the chip and the chip die size is 112.54 mm2. The throughput rate for the DFCT is 750 Mbitss.
5BE8D5F7	Digital image and video in their raw form require an enormous amount of storage capacity. Considering the important role played by digital imaging and video in medical and health science, it is necessary to develop a system that produces high degree of compression while preserving critical image/video information. In this paper, we present a hybrid algorithm that performs the discrete cosine transform on the discrete wavelet transform coefficients. Simulation has been carried out on several medical and endoscopic images and videos. The results show that the proposed hybrid algorithm performs much better in term of peak-signal-to-noise-ratio with a higher compression ratio compared to standalone DCT and DWT algorithms. The scheme is intended to be used as the image/video compressor engine in medical imaging and video applications, such as, telemedicine and wireless capsule endoscopy
60C2371C	Small length Discrete Cosine Transforms (DCT's) are used for image data compression. In that case, length 8 or 16 DCT's are needed to be performed at video rate. We propose two new implementation of DCT's which have several interesting features, as far as VLSI implementation is concerned. A first one, using modulo-arithmetic, needs only one multiplication per input point, so that a single multiplier is needed on-chip. A second one, based on a decomposition of the DCT into polynomial products, and evaluation of these polynomial products by distributed arithmetic, results in a very small chip, with a great regularity and testability. Furthermore, the same structure can be used for FFT computation by changing only the ROM-part of the chip. Both new architectures are mainly based on a new formulation of a length-2nDCT as a cyclic convolution, which is explained in the first section of the paper.
7E6FD3E0	An adaptive DCT-based image compression algorithm for radar images is proposed, tested and compared to JPEG and to classical coding algorithms for remote sensing imagery. The Modified Adaptive Discrete Cosine Transform (MADCT) scheme is proposed, which allows one to classify each image block by means of a threshold criterion based on AC and DC activity. The strategy of transmission of the DCT coefficients, the recovering process of blocks incorrectly discarded, and the bit-allocation phase have been properly designed to provide high compression of two classes of images: X-band real-aperture radar images for ship traffic control, and SAR images for browsing applications. The experimental results, in terms of PSNR and compression ratio, prove the superiority of the novel scheme with respect to standard coding techniques.
7A6D7FA4	Digital images in their uncompressed form require an enormous amount of storage capacity. Such uncompressed data needs large transmission bandwidth for the transmission over the network. Discrete Cosine Transform (DCT) is one of the widely used image compression method and the Discrete Wavelet Transform (DWT) provides substantial improvements in the quality of picture because of multi resolution nature. Image compression reduces the storage space of image and also maintains the quality information of the image. In this research study the performance of three most widely used techniques namely DCT, DWT and Hybrid DCT-DWT are discussed for image compression and their performance is evaluated in terms of Peak Signal to Noise Ratio (PSNR), Mean Square Error (MSE) and Compression Ratio (CR). The experimental results obtained from the study shows that the Hybrid DCT- DWT technique for image compression has in general a better performance than individual DCT or DWT. 
816929C1	A novel block matching algorithm for motion estimation in a video frame sequence, well suited for a high performance FPGA implementation is presented in this paper. The algorithm is up to 40% faster when compared to one of the fastest existing algorithms, viz., one-at-a-time step search algorithm without compromising either in the image quality or in the compression effected. The speed advantage is preserved even in the event of a sudden scene change in a video sequence. The proposed algorithm is also capable of dynamically detecting the direction of motion of image blocks. The FPGA implementation of the algorithm is capable of processing color pictures of sizes up to 1024x768 pixels at the real time video rate of 25 frames/second and conforms to MPEG-2 standards.
76022FC0	This paper assesses the arithmetic benefits provided by the Residue Number System (RNS) for building Digital Signal Processing (DSP) systems with Field-Programmable Logic (FPL) technology. The quantifiable benefits of this approach are studied in the context of a new Fast Cosine Transform (FCT) architecture enhanced by using the Quadratic Residue Number System (QRNS). The system reduces the number of adders and multipliers required for the N-point Discrete Cosine Transform (DCT) and provides high throughput. For an FPL-based implementation, the proposed design gets significant improvements over an equivalent 2C structure. By using up to 6-bit moduli, an overall increase in the system performance of about 140% is achieved. If this speed increase is considered along with the penalty in device resources, the presented QRNS-based FCT system provides an improvement in the area-delay figure factor of about 20%. Finally, the conversion overhead was carefully studied and it was found that the quantifiable benefits of the proposed design are not affected when converters are included 
80FFB575	In this paper, we propose a system-level error tolerance scheme for systems where a linear transform is combined with quantization. These are key components in multimedia compression systems, e.g., video and image codecs. Using the concept of acceptable degradation, our scheme classifies hardware faults into acceptable and unacceptable faults. We propose analysis techniques that allow us to estimate the faults' impact on compression performance, and in particular on the quality of decoded images/video. We consider as an example the discrete cosine transform (DCT), which is part of a large number of existing image and video compression systems. We propose methods to establish thresholds of acceptable degradation and corresponding testing algorithms for DCT-based systems. Our results for a JPEG encoder using a typical DCT architecture show that over 50% of single stuck-at interconnection faults in one of its 1D DCT modules lead to imperceptible quality degradation in the decoded images, over the complete range of compression rates at which JPEG can operate.
7F066D3F	Frequency -warped signal processing techniques are attractive to many wideband speech and audio applications since they have a clear connection to the frequency resolution of human hearing. A warped version of the linear predictive coding (LPC) for speech compression is implemented in this paper and an analysis of the application of Set Partitioning In Hierarchical Trees (SPIHT) algorithm to the compression of speech signals is performed. It has been shown that the proposed scheme i.e. Warped LPC with MLT_SPIHT algorithm produces an enhancement in speech quality. The proposed scheme is based on the combination of the Modulated Lapped Transform(MLT) and SPIHT. Comparisons are made with Plain LPC Coder, Voice Excited LPC Coder with the coding of the residual signal with DCT, Voice Excited LPC Coder with the coding of the residual signal with MLT and SPIHT. The performance of the coders described has been assessed by computer simulation in terms of a) Signal -to -noise ratio (SNR) b) Compression ratio c) Informal subjective listening test.
80CB08BD	This paper presents a new adaptive algorithm for speech compression using cosine packet transform. The proposed algorithm uses packet decomposition, which reduces a computational complexity of a system. This paper compare the compression ratio of methods using wavelet transform, cosine transform, wavelet packet transform and proposed adaptive algorithm using cosine packet transform for different speech signal samples. The mean compression ratio is calculated for all the methods and compared. The implemented results show that the proposed compression algorithm gives the better performance for speech signals.
7996F7EA	Unlike classical wired networks and wireless sensor networks, WMSN differs from their predecessor’s scalar network basically in the following points; nature and size of data being transmitted, important memory resources, as well as, power consumed per each node for processing and transmission. The most effective solution to overcome those problems is image compression. As the image contains massive amount of redundancies resulting from high correlation between pixels, many compression algorithms have been developed. The main objective of this survey was to study and analyze relevant research directions and the most recent algorithms of image compression over WMSN. This survey characterizes the benefits and shortcomings of recent efforts of such algorithms. Moreover, it provides an open research issue for each compression method; and its potentials to WMSN. Reducing consumed power thus granting long life time is considered the main performance metric and will be the main target in the investigated solution
77ABB4F5	As data compression plays now an important role in the development of medical PACS, a technique has been developed for medical image sequences storage and transmission in order to obtain very high compression ratio: in dynamic nuclear medicine studies it can achieve a compression ratio as high as 100:1 without significant degradation. The implemented technique combines two methods which multiply their effects. In a first step, a principal component analysis (PCA) of the image series is performed. It extracts a limited number of principal components and their associated images. For data compression it is not necessary to perform an oblique factor analysis to estimate the so-called ‘physiological functions’ and their spatial distributions as in factor analysis of dynamic structures (FADS). In a second step, the principal images are compressed by means of a transform coding procedure: an adaptive block-quantization technique using the 2D discrete cosine transform (DCT) is implemented, followed by a statistical quantization method to encode the DCT coefficients. To reconstruct the principal images, an inverse DCT is applied. Then the original series is computed from the reconstructed images combined with the principal components which have been stored without any modification. The reconstructed series is compared to the original series, as well as the time activity curves generated on different regions of interest (ROI) and the factor estimates obtained using FADS performed on the two series. Method and evaluation are illustrated on an example of first pass radionuclide angiocardiography.