783FB036	The behavior and self-organization of ant colonies has been widely studied to address distributed clustering. However, most models that directly mimic ants produce too many clusters and converge too slowly. A wide range of research has attempted to address this through various means, but a number of sources of inefficiency remain, including: i) ants must physically move from one cluster to another through intermediate locations, ii) patterns in movement among clusters is not considered, and iii) while some approaches have included bulk item movement, they do not provide efficient movement while still maintaining the self-organizing nature of ant-based clustering. To address these issues, this paper presents a new algorithm for ant-based clustering. Here ants maintain a movement zone around each cluster, keeping ants close to data items. These movement zones are used to elect representatives that are responsible for all long distance movement. Representatives can, probabilistically, pass an object it has to any other representative. Since each cluster has approximately one representative at any given time, the search space for placing items over a long distance is reduce to the number of clusters. This provides an infrastructure that allows bulk movement and efficient long distance merging
77B1E9C6	Recently there is an increasing attention in heterogeneous information network analysis, which models networked data as networks including different types of objects and relations. Many data mining tasks have been exploited in heterogeneous networks, among which clustering and ranking are two basic tasks. These two tasks are usually done separately, whereas recent researches show that they can mutually enhance each other. Unfortunately, these works are limited to heterogeneous networks with special structures (e.g. bipartite or star-schema network). However, real data are more complex and irregular, so it is desirable to design a general method to manage objects and relations in heterogeneous networks with arbitrary schema. In this paper, we study the ranking-based clustering problem in a general heterogeneous information network and propose a novel solution HeProjI. HeProjI projects a general heterogeneous network into a sequence of sub-networks and an information transfer mechanism is designed to keep the consistency among sub-networks. For each sub-network, a path-based random walk model is built to estimate the reachable probability of objects which can be used for clustering and ranking analysis. Iteratively analyzing each sub-network leads to effective ranking-based clustering. Extensive experiments on three real datasets illustrate that HeProjI can achieve better clustering and ranking performances compared to other well-established algorithms.
7DA603AE	The framework of multiobjective optimization is used to tackle the unsupervised learning problem, data clustering, following a formulation first proposed in the statistics literature. The conceptual advantages of the multiobjective formulation are discussed and an evolutionary approach to the problem is developed. The resulting algorithm, multiobjective clustering with automatic k-determination, is compared with a number of well-established single-objective clustering algorithms, a modern ensemble technique, and two methods of model selection. The experiments demonstrate that the conceptual advantages of multiobjective clustering translate into practical and scalable performance benefits
7D2F4231	In this paper, the fully automatic clustering system (FACS) is presented. It is a technique for clustering and vector quantization whose objective is the automatic calculation of the codebook of the right dimension, the desired error (or target) being fixed. At each iteration, FACS tries to improve the setting of the existing codewords and, if necessary, some elements are removed from or added to the codebook. In order to save on the number of computations per iteration, greedy techniques are adopted. It has been demonstrated, from a heuristic point of view, that the number of the codewords determined by FACS is very low and that the algorithm quickly converges toward the final solution.
7C91B3BF	A nonparametric clustering technique incorporating the concept of similarity based on the sharing of near neighbors is presented. In addition to being an essentially paraliel approach, the computational elegance of the method is such that the scheme is applicable to a wide class of practical problems involving large sample size and high dimensionality. No attempt is made to show how a priori problem knowledge can be introduced into the procedure.
7E341299	Describes a genetically guided approach to optimizing the hard (J/sub 1/) and fuzzy (J/sub m/) c-means functionals used in cluster analysis. Our experiments show that a genetic algorithm (GA) can ameliorate the difficulty of choosing an initialization for the c-means clustering algorithms. Experiments use six data sets, including the Iris data, magnetic resonance, and color images. The genetic algorithm approach is generally able to find the lowest known J/sub m/ value or a J/sub m/ associated with a partition very similar to that associated with the lowest J/sub m/ value. On data sets with several local extrema, the GA approach always avoids the less desirable solutions. Degenerate partitions are always avoided by the GA approach, which provides an effective method for optimizing clustering models whose objective function can be represented in terms of cluster centers. A series random initializations of fuzzy/hard c-means, where the partition associated with the lowest J/sub m/ value is chosen, can produce an equivalent solution to the genetic guided clustering approach given the same amount of processor time in some domains.
7A47CD8E	We define a method to estimate the number of clusters in a data set E, using the bootstrap technique. This approach involves the generation of several “fake” data sets by sampling patterns with replacement in E (bootstrapping). For each number, K, of clusters, a measure of stability of the K-cluster partitions over the bootstrap samples is used to characterize the significance of the K-cluster partition for the original data set. The value of K which provides the most stable partitions is the estimate of the number of clusters in E. The performance of this new technique is demonstrated on both synthetic and real data, and is applied to the segmentation of range images.
7E118482	Clustering methods need to be robust if they are to be useful in practice. In this paper, we analyze several popular robust clustering methods and show that they have much in common. We also establish a connection between fuzzy set theory and robust statistics, and point out the similarities between robust clustering methods and statistical methods such as the weighted least-squares technique, the M estimator, the minimum volume ellipsoid algorithm, cooperative robust estimation, minimization of probability of randomness, and the epsilon contamination model. By gleaning the common principles upon which the methods proposed in the literature are based, we arrive at a unified view of robust clustering methods. We define several general concepts that are useful in robust clustering, state the robust clustering problem in terms of the defined concepts, and propose generic algorithms and guidelines for clustering noisy data. We also discuss why the generalized Hough transform is a suboptimal solution to the robust clustering problem.
7C0CAEF9	Clustering algorithms tend to generate clusters even when applied to random data. This paper provides a semi-tutorial review of the state-of-the-art in cluster validity, or the verification of results from clustering algorithms. The paper covers ways of measuring clustering tendency, the fit of hierarchical and partitional structures and indices of compactness and isolation for individual clusters. Included are structural criteria for validating clusters and the factors involved in choosing criteria, according to which the literature of cluster validity is classified. An application to speaker identification demonstrates several indices. The development of new clustering techniques and the wide availability of clustering programs necessitates vigorous research in cluster validity.
76FA8332	An algorithm is presented which partitions a given sample from a multimodal fuzzy set into unimodal fuzzy sets. It is proven that if certain assumptions are satisfied, then the algorithm will derive the optimal partition in the sense of maximum separation.
7D143B43	Artificial Bee Colony (ABC) algorithm which is one of the most recently introduced optimization algorithms, simulates the intelligent foraging behavior of a honey bee swarm. Clustering analysis, used in many disciplines and applications, is an important tool and a descriptive task seeking to identify homogeneous groups of objects based on the values of their attributes. In this work, ABC is used for data clustering on benchmark problems and the performance of ABC algorithm is compared with Particle Swarm Optimization (PSO) algorithm and other nine classification techniques from the literature. Thirteen of typical test data sets from the UCI Machine Learning Repository are used to demonstrate the results of the techniques. The simulation results indicate that ABC algorithm can efficiently be used for multivariate data clustering.	
76C1E847	Clustering is the unsupervised classification of patterns (observations, data items, or feature vectors) into groups (clusters). The clustering problem has been addressed in many contexts and by researchers in many disciplines; this reflects its broad appeal and usefulness as one of the steps in exploratory data analysis. However, clustering is a difficult problem combinatorially, and differences in assumptions and contexts in different communities has made the transfer of useful generic concepts and methodologies slow to occur. This paper presents an overview of pattern clustering methods from a statistical pattern recognition perspective, with a goal of providing useful advice and references to fundamental concepts accessible to the broad community of clustering practitioners. We present a taxonomy of clustering techniques, and identify cross-cutting themes and recent advances. We also describe some important applications of clustering algorithms such as image segmentation, object recognition, and information retrieval.
8045ACA4	We propose a notion of deterministic association rules for ordered data. We prove that our proposed rules can be formally justified by a purely logical characterization, namely, a natural notion of empirical Horn approximation for ordered data which involves background Horn conditions; these ensure the consistency of the propositional theory obtained with the ordered context. The main proof resorts to a concept lattice model in the framework of Formal Concept Analysis, but adapted to ordered contexts. We also discuss a general method to mine these rules that can be easily incorporated into any algorithm for mining closed sequences, of which there are already some in the literature.
7AE5B59D	A method for investigating the relationships of points in multi-dimensional space is described. Using an analysis of variance technique, the points are divided into the two most-compact clusters, and the process repeated sequentially so that a `tree' diagram is formed. The application of the method to problems of classification is particularly stressed, and numerical examples are given.
7DA40E23	This paper addresses three major issues associated with conventional partitional clustering, namely, sensitivity to initialization, difficulty in determining the number of clusters, and sensitivity to noise and outliers. The proposed Robust Competitive Agglomeration (RCA) algorithm starts with a large number of clusters to reduce the sensitivity to initialization, and determines the actual number of clusters by a process of competitive agglomeration. Noise immunity is achieved by incorporating concepts from robust statistics into the algorithm. RCA assigns two different sets of weights for each data point: the first set of constrained weights represents degrees of sharing, and is used to create a competitive environment and to generate a fuzzy partition of the data set. The second set corresponds to robust weights, and is used to obtain robust estimates of the cluster prototypes. By choosing an appropriate distance measure in the objective function, RCA can be used to find an unknown number of clusters of various shapes in noisy data sets, as well as to fit an unknown number of parametric models simultaneously. Several examples, such as clustering/mixture decomposition, line/plane fitting, segmentation of range images, and estimation of motion parameters of multiple objects, are shown.
80ECF443	In this paper we describe a new time-constrained clustering algorithm. It is coupled with a time-constrained scheduling algorithm and used for design-space-exploration (DSE) of clustered VLIW processors with heterogeneous clusters and heterogeneous functional units. The algorithm enables us to reduce the complexity of the DSE, because the parameters of the VLIW are derived from the clustered schedule of the considered application which is produced during a single compilation step. Several compilations of the same application with different VLIW-parameter settings are not necessary. Our proposed algorithm is integrated into a DSE-Tool in order to explore the best parameters of a clustered VLIW processor for several basic blocks of signal processing applications. The obtained results are compared to the results of Lapinskii's work and show, that, for most benchmarks, we are able to save ports in the register file of each cluster
76B1BBBB	A Firefly Algorithm (FA) is a recent nature inspired optimization algorithm, that simulates the flash pattern and characteristics of fireflies. Clustering is a popular data analysis technique to identify homogeneous groups of objects based on the values of their attributes. In this paper, the FA is used for clustering on benchmark problems and the performance of the FA is compared with other two nature inspired techniques — Artificial Bee Colony (ABC), Particle Swarm Optimization (PSO), and other nine methods used in the literature. Thirteen typical benchmark data sets from the UCI machine learning repository are used to demonstrate the results of the techniques. From the results obtained, we compare the performance of the FA algorithm and conclude that the FA can be efficiently used for clustering.
80CA7E45	In this paper we introduce a new tree-structured self-organizing neural network called a dynamical growing self-organizing tree (DGSOT). This DGSOT algorithm constructs a hierarchy from top to bottom by division. At each hierarchical level, the DGSOT optimizes the number of clusters, from which the proper hierarchical structure of the underlying data set can be found. We propose a K-level up distribution (KLD) mechanism. This KLD scheme increases the scope for data distribution in the hierarchy, which allows the data mis-clustered in the early stages to be re-evaluated at a later stage increasing the accuracy of the final clustering result. The DGSOT algorithm, combined with the KLD mechanism, overcomes the drawbacks of traditional hierarchical clustering algorithms (e.g., hierarchical agglomerative clustering). The DGSOT algorithm has been tested on two benchmark data sets including gene expression complex data set and we observe that our algorithm extracts patterns with different levels of abstraction. Furthermore, our approach is useful on recognizing features in complex gene expression data. As a dendrogram, these results can be easily displayed for visualization.
7B47D356	This paper concerns a novel method to deal with data clustering, which is called completely positive factorizations combined with QR decomposition. We first introduce the concept of completely positive matrices and then the (0,1) CP factorizations, by which some recent work on the linear clustering and the number of the clusters in this case is initialized. A detailed CP-QR algorithm is presented, and its advantage over NMF method is illustrated by an example
0364F566	In the past decade, Probabilistic Latent Semantic Indexing (PLSI) has become an important modeling technique, widely used in clustering or graph partitioning analysis. However, the original PLSI is designed for multinomial data and may not handle other data types. To overcome this restriction, we generalize PLSI to t-exponential family based on a recently proposed information criterion called t-divergence. The t-divergence enjoys more flexibility than KL-divergence in PLSI such that it can accommodate more types of noise in data. To optimize the generalized learning objective, we propose a Majorization-Minimization algorithm which multiplicatively updates the factorizing matrices. The new method is verified in pairwise clustering tasks. Experimental results on real-world datasets show that PLSI with t-divergence can improve clustering performance in purity for certain datasets.
7D4D4E68	Clustering is an important and popular technique in data mining. It partitions a set of objects in such a manner that objects in the same clusters are more similar to each another than objects in the different cluster according to certain predefined criteria. K-means is simple yet an efficient method used in data clustering. However, K-means has a tendency to converge to local optima and depends on initial value of cluster centers. In the past, many heuristic algorithms have been introduced to overcome this local optima problem. Nevertheless, these algorithms too suffer several short-comings. In this paper, we present an efficient hybrid evolutionary data clustering algorithm referred to as K-MCI, whereby, we combine K-means with modified cohort intelligence. Our proposed algorithm is tested on several standard data sets from UCI Machine Learning Repository and its performance is compared with other well-known algorithms such as K-means, K-means++, cohort intelligence (CI), modified cohort intelligence (MCI), genetic algorithm (GA), simulated annealing (SA), tabu search (TS), ant colony optimization (ACO), honey bee mating optimization (HBMO) and particle swarm optimization (PSO). The simulation results are very promising in the terms of quality of solution and convergence speed of algorithm.
77EF8A66	Estimating the true number of clusters for an unlabeled data set is one of the most important limitations in clustering. To solve this issue, many approaches with different assumptions have been proposed in the literature. X-means clustering is one of the proposed methods, which employs Bayesian Information Criterion (BIC) to approximate the correct number of clusters. In this paper, we propose the use of Minimum Noiseless Description Length (MNDL) as a cluster splitting criterion for X-means clustering. MNDL is able to find the optimum splitting criterion for X-means clustering. Simulation results demonstrate that MNDL splitting criterion has the same computational complexity as BIC but, predicts the true number of clusters more often.
78B6BEE1	When clustering algorithms are applied to image segmentation, the goal is to solve a classification problem. However, these algorithms do not directly optimize classification duality. As a result, they are susceptible to two problems: 1) the criterion they optimize may not be a good estimator of "true" classification quality, and 2) they often admit many (suboptimal) solutions. This paper introduces an algorithm that uses cluster validity to mitigate problems 1 and 2. The validity-guided (re)clustering (VGC) algorithm uses cluster-validity information to guide a fuzzy (re)clustering process toward better solutions. It starts with a partition generated by a soft or fuzzy clustering algorithm. Then it iteratively alters the partition by applying (novel) split-and-merge operations to the clusters. Partition modifications that result in improved partition validity are retained. VGC is tested on both synthetic and real-world data. For magnetic resonance image (MRI) segmentation, evaluations by radiologists show that VGC outperforms the (unsupervised) fuzzy c-means algorithm, and VGC's performance approaches that of the (supervised) k-nearest-neighbors algorithm.
7DBBBE71	Clustering techniques have received attention in many fields of study such as engineering, medicine, biology and data mining. The aim of clustering is to collect data points. The K-means algorithm is one of the most common techniques used for clustering. However, the results of K-means depend on the initial state and converge to local optima. In order to overcome local optima obstacles, a lot of studies have been done in clustering. This paper presents an efficient hybrid evolutionary optimization algorithm based on combining Modify Imperialist Competitive Algorithm (MICA) and K-means (K), which is called K-MICA, for optimum clustering N objects into K clusters. The new Hybrid K-ICA algorithm is tested on several data sets and its performance is compared with those of MICA, ACO, PSO, Simulated Annealing (SA), Genetic Algorithm (GA), Tabu Search (TS), Honey Bee Mating Optimization (HBMO) and K-means. The simulation results show that the proposed evolutionary optimization algorithm is robust and suitable for handling data clustering.
8057BAB5	Data analysis plays an indispensable role for understanding various phenomena. Cluster analysis, primitive exploration with little or no prior knowledge, consists of research developed across a wide variety of communities. The diversity, on one hand, equips us with many tools. On the other hand, the profusion of options causes confusion. We survey clustering algorithms for data sets appearing in statistics, computer science, and machine learning, and illustrate their applications in some benchmark data sets, the traveling salesman problem, and bioinformatics, a new field attracting intensive efforts. Several tightly related topics, proximity measure, and cluster validation, are also discussed.
7253E23A	Data clustering, the process of grouping similar objects in a set of observations is one of the attractive and main tasks in data mining that is used in many areas and applications such as text clustering and information retrieval, data compaction, fraud detection, biology, computer vision, data summarization, marketing and customer analysis, etc. The well-known k-means algorithm, which widely applied to the clustering problem, has the drawbacks of depending on the initial state of centroids and may converge to the local optima rather than global optima. A data clustering algorithm based on the gravitational search algorithm (GSA) is proposed in this research. In this algorithm, some candidate solutions for clustering problem are created randomly and then interact with one another via Newton’s gravity law to search the problem space. The performance of the presented algorithm is compared with three other well-known clustering algorithms, including k-means, genetic algorithm (GA), and particle swarm optimization algorithm (PSO) on four real and standard datasets. Experimental results confirm that the GSA is a robust and viable method for data clustering.
8020B0E2	Selection of “matched” areas for test marketing is an important undertaking if reliable comparisons among markets are to be made. This usually has been done on a rather arbitrary basis, largely because of the large number of market characteristics on which markets can be viewed as similar or different.The authors suggest a numerical procedure—cluster analysis—for matching prospective test markets on the basis of a large variety of characteristics which could affect test marketing results. In this way, markets can be pre-selected so as to reduce undesired variability among test areas.
7F02386E	We explore the idea of evidence accumulation for combining the results of multiple clusterings. Initially, n d-dimensional data is decomposed into a large number of compact clusters; the K-means algorithm performs this decomposition, with several clusterings obtained by N random initializations of the K-means. Taking the co-occurrences of pairs of patterns in the same cluster as votes for their association, the data partitions are mapped into a co-association matrix of patterns. This n/spl times/n matrix represents a new similarity measure between patterns. The final clusters are obtained by applying a MST-based clustering algorithm on this matrix. Results on both synthetic and real data show the ability of the method to identify arbitrary shaped clusters in multidimensional data.
7FED3742	This paper proposes a constrained clustering method that is based on a graph-cut problem formalized by SDP (Semi-Definite Programming). Our SDP approach has the advantage of convenient constraint utilization compared with conventional spectral clustering methods. The algorithm starts from a single cluster of a complete dataset and repeatedly selects the largest cluster, which it then divides into two clusters by swapping rows and columns of a relational label matrix obtained by solving the maximum graph-cut problem. This swapping procedure is effective because we can create clusters without any computationally heavy matrix decomposition process to obtain a cluster label for each data. The results of experiments using a Web document dataset demonstrated that our method outperformed other conventional and the state of the art clustering methods in many cases. Hence we consider our clustering provides a promising basic method to interactive Web clustering.
77E33E25	We introduce a novel clustering algorithm named GAKREM (Genetic Algorithm K-means Logarithmic Regression Expectation Maximization) that combines the best characteristics of the K-means and EM algorithms but avoids their weaknesses such as the need to specify a priori the number of clusters, termination in local optima, and lengthy computations. To achieve these goals, genetic algorithms for estimating parameters and initializing starting points for the EM are used first. Second, the log-likelihood of each configuration of parameters and the number of clusters resulting from the EM is used as the fitness value for each chromosome in the population. The novelty of GAKREM is that in each evolving generation it efficiently approximates the log-likelihood for each chromosome using logarithmic regression instead of running the conventional EM algorithm until its convergence. Another novelty is the use of K-means to initially assign data points to clusters. The algorithm is evaluated by comparing its performance with the conventional EM algorithm, the K-means algorithm, and the likelihood cross-validation technique on several datasets.
7E672365	The clustering problem is cast in the framework of possibility theory. The approach differs from the existing clustering methods in that the resulting partition of the data can be interpreted as a possibilistic partition, and the membership values can be interpreted as degrees of possibility of the points belonging to the classes, i.e., the compatibilities of the points with the class prototypes. An appropriate objective function whose minimum will characterize a good possibilistic partition of the data is constructed, and the membership and prototype update equations are derived from necessary conditions for minimization of the criterion function. The advantages of the resulting family of possibilistic algorithms are illustrated by several examples.
799A946E	This paper presents and investigates Clustered Shading for deferred and forward rendering. In Clustered Shading, view samples with similar properties (e.g. 3D-position and/or normal) are grouped into clusters. This is comparable to tiled shading, where view samples are grouped into tiles based on 2D-position only. We show that Clustered Shading creates a better mapping of light sources to view samples than tiled shading, resulting in a significant reduction of lighting computations during shading. Additionally, Clustered Shading enables using normal information to perform per-cluster back-face culling of lights, again reducing the number of lighting computations. We also show that Clustered Shading not only outperforms tiled shading in many scenes, but also exhibits better worst case behaviour under tricky conditions (e.g. when looking at high-frequency geometry with large discontinuities in depth). Additionally, Clustered Shading enables real-time scenes with two to three orders of magnitudes more lights than previously feasible (up to around one million light sources).
808A14C1	Bayesian model-based clustering programs have gained increased popularity in studies of population structure since the publication of the software structure. These programs are generally acknowledged as performing well, but their running-time may be prohibitive. fastruct is a non-Bayesian implementation of the classical model with no-admixture uncorrelated allele frequencies. This new program relies on the expectation–maximization principle, and produces assignment rivalling other model-based clustering programs. In addition, it can be manyfold faster than Bayesian implementations. The software consists of a command-line engine, which is suitable for batch analysis of data, and a graphical interface, which is convenient for exploring data.
78158877	Clustering finds various applications in the field of medical and telecommunication for unsupervised learning which is much required in expert system and its application. Various algorithms have been developed to clustering for the past fifty years after the introduction of k-means clustering. Recently, optimization algorithms are applied for clustering to find optimal clusters with the help of different objective functions. Accordingly, in this research, clustering is performed using three newly designed objective functions along with four existing objective functions with the help of optimization algorithms like, genetic algorithm, cuckoo search and particle swarm optimization algorithm. Here, three different objective functions are designed including the cumulative summation of fuzzy membership and distance value with normal data space, kernel space as well as multiple kernel space. In addition to the existing seven objective functions, totally, 21 different clustering algorithms are discussed and the performance is validated with 16 different datasets which are synthetic, small and large scale real data. The comparison is made with five different evaluation metrics to validate the effectiveness and efficiency. From the research outcome, the suggestion is presented to select a suitable algorithm among 21 algorithms for a particular data and results proved that the effectiveness of cluster analysis is mainly dependent on objective function and the efficiency of cluster analysis is based on search algorithm.
78A3708F	Digitised colour images quantised at 24 bits per pel represent a considerable storage requirement. For many applications a coarser quantisation is allowable or even necessary. The authors describe three variations on a method to quantise RGB data at approximately 4 bits per pel. The main criterion in the scheme is that of a minimum perceptual distortion in the reproduced data. The MacAdam chromaticity domain is used as a perceptually metric space in which equal Euclidean distances may be assumed to represent equally perceived colour differences. Histogram and cluster analysis methods are used to quantise the RGB data at 4 bits luminance and 0.75 bits chromaticity. The results appear acceptably close to the originals.
7D078885	This paper introduces the problem of combining multiple partitionings of a set of objects into a single consolidated clustering without accessing the features or algorithms that determined these partitionings. We first identify several application scenarios for the resultant 'knowledge reuse' framework that we call cluster ensembles. The cluster ensemble problem is then formalized as a combinatorial optimization problem in terms of shared mutual information. In addition to a direct maximization approach, we propose three effective and efficient techniques for obtaining high-quality combiners (consensus functions). The first combiner induces a similarity measure from the partitionings and then reclusters the objects. The second combiner is based on hypergraph partitioning. The third one collapses groups of clusters into meta-clusters which then compete for each object to determine the combined clustering. Due to the low computational costs of our techniques, it is quite feasible to use a supra-consensus function that evaluates all three approaches against the objective function and picks the best solution for a given situation. We evaluate the effectiveness of cluster ensembles in three qualitatively different application scenarios: (i) where the original clusters were formed based on non-identical sets of features, (ii) where the original clustering algorithms worked on non-identical sets of objects, and (iii) where a common data-set is used and the main purpose of combining multiple clusterings is to improve the quality and robustness of the solution. Promising results are obtained in all three situations for synthetic as well as real data-sets.
7F498871	In this paper, a stochastic connectionist approach is proposed for solving function optimization problems with real-valued parameters. With the assumption of increased processing capability of a node in the connectionist network, we show how a broader class of problems can be solved. As the proposed approach is a stochastic search technique, it avoids getting stuck in local optima. Robustness of the approach is demonstrated on several multi-modal functions with different numbers of variables. Optimization of a well-known partitional clustering criterion, the squared-error criterion (SEC), is formulated as a function optimization problem and is solved using the proposed approach. This approach is used to cluster selected data sets and the results obtained are compared with that of the K-means algorithm and a simulated annealing (SA) approach. The amenability of the connectionist approach to parallelization enables effective use of parallel hardware.
7DDC24D9	Lacunarity (L) is a scale (r)-dependent parameter that was developed for quantifying clustering in fractals and has subsequently been employed to characterize various natural patterns. For multifractals it can be shown analytically that L is related to the correlation dimension, D2, by: dlog(L)/dlog(r) = D2 - 2. We empirically tested this equation using two-dimensional multifractal grayscale patterns with known correlation dimensions. These patterns were analyzed for their lacunarity using the gliding-box algorithm. D2 values computed from the dlog(L)/dlog(r) analysis gave a ~1:1 relationship with the known D2 values. Lacunarity analysis was also employed in discriminating between multifractal grayscale patterns with the same D2 values, but different degrees of scale-dependent clustering. For this purpose, a new lacunarity parameter, <L>, was formulated based on the weighted mean of the log-transformed lacunarity values at different scales. This approach was further used to evaluate scale-dependent clustering in soil thin section grayscale images that had previously been classified as multifractals based on standard method of moments box-counting. Our results indicate that lacunarity analysis may be a more sensitive indicator of multifractal behavior in natural grayscale patterns than the standard approach. Thus, multifractal behavior can be checked without having to compute the whole spectrum of non-integer dimensions, Dq that typically characterize a multifractal. The new <L> parameter should be useful to researchers who want to explore the correlative influence of clustering on flow and transport in grayscale representations of soil aggregates and heterogeneous aquifer 
77CA0781	Data clustering is an important technique in data mining. It is a method of partitioning data into clusters, in which each cluster must have data of great similarity and different clusters must have data of high dissimilarity. A lot of clustering algorithms are found in the literature. In general, there is no single algorithm that is suitable for all types of data, conditions and applications. Each algorithm has its own advantages, limitations and shortcomings. Therefore, introducing novel and effective approaches for data clustering is an open and active research area. This paper presents a novel binary search algorithm for data clustering that not only finds high quality clusters but also converges to the same solution in different runs. In the proposed algorithm a set of initial centroids are chosen from different parts of the test dataset and then optimal locations for the centroids are found by thoroughly exploring around of the initial centroids. The simulation results using six benchmark datasets from the UCI Machine Learning Repository indicate that proposed algorithm can efficiently be used for data clustering.
74F1CFCD	This paper presents a hybrid method of fuzzy clustering using evolutionary search and self-organizing, which has both advantages of evolutionary algorithm and self-organizing. Simulation experiments have shown that the convergence speed of the proposed method is faster than that of pure evolutionary algorithm
7F1C2084	The primary goal of pattern recognition is supervised or unsupervised classification. Among the various frameworks in which pattern recognition has been traditionally formulated, the statistical approach has been most intensively studied and used in practice. More recently, neural network techniques and methods imported from statistical learning theory have been receiving increasing attention. The design of a recognition system requires careful attention to the following issues: definition of pattern classes, sensing environment, pattern representation, feature extraction and selection, cluster analysis, classifier design and learning, selection of training and test samples, and performance evaluation. In spite of almost 50 years of research and development in this field, the general problem of recognizing complex patterns with arbitrary orientation, location, and scale remains unsolved. New and emerging applications, such as data mining, web searching, retrieval of multimedia data, face recognition, and cursive handwriting recognition, require robust and efficient pattern recognition techniques. The objective of this review paper is to summarize and compare some of the well-known methods used in various stages of a pattern recognition system and identify research topics and applications which are at the forefront of this exciting and challenging field.
7F370479	An algorithm for the analysis of multivariate data is presented along with some experimental results. The algorithm is based upon a point mapping of N L-dimensional vectors from the L-space to a lower-dimensional space such that the inherent data "structure" is approximately preserved.
761B88C7	An approach to clustering and decision making is presented where a prior problem knowledge is inserted interactively. The problem knowledge inserted is in the form of subcategory mean vectors and covariance matrices and in the expert's confidence that these means and covariances accurately characterize the category. Then observations of patterns from the category are used to update these a priori supplied means and covariances. The extent to which new observations update the a priori values depends upon the expert's a priori confidence.
752824BD	This work introduces an alternative representation for large dimensional data sets. Instead of using 2D or 3D representations, data is located on the surface of a sphere. Together with this representation, a hierarchical clustering algorithm is defined to analyse and extract the structure of the data. The algorithm builds a hierarchical structure (a dendrogram) in such a way that different cuts of the structure lead to different partitions of the surface of the sphere. This can be seen as a set of concentric spheres, each one being of different granularity. Also, to obtain an initial assignment of the data on the surface of the sphere, a method based on Sammon's mapping has been developed.
7CD7B2EF	This study reports on a method for carrying out fuzzy classification without a priori assumptions on the number of clusters in the data set. Assessment of cluster validity is based on performance measures using hypervolume and density criteria. An algorithm is derived from a combination of the fuzzy K-means algorithm and fuzzy maximum-likelihood estimation. The unsupervised fuzzy partition-optimal number of classes algorithm performs well in situations of large variability of cluster shapes, densities, and number of data points in each cluster. The algorithm was tested on different classes of simulated data, and on a real data set derived from sleep EEG signal
79100F75	In this paper we perform a genome-wide analysis of H. sapiens promoters. To this aim, we developed and combined two mathematical methods that allow us to (i) classify promoters into groups characterized by specific global structural features, and (ii) recover, in full generality, any regular sequence in the different classes of promoters. One of the main findings of this analysis is that H. sapiens promoters can be classified into three main groups. Two of them are distinguished by the prevalence of weak or strong nucleotides and are characterized by short compositionally biased sequences, while the most frequent regular sequences in the third group are strongly correlated with transposons. Taking advantage of the generality of these mathematical procedures, we have compared the promoter database of H. sapiens with those of other species. We have found that the above-mentioned features characterize also the evolutionary content appearing in mammalian promoters, at variance with ancestral species in the phylogenetic tree, that exhibit a definitely lower level of differentiation among promoters.
77B57104	This paper proposes a multi-level approach to data clustering and provides a novel approach to characterisation of clay soils by, effectively, looking at the same clay sample from different angles. It is shown that using this approach can help avoid detection of spurious clusters or skipping vital natural grouping in data. Muscovite, illite and kaolinite were identified by X-ray diffraction (XRD) in <4 µm fraction of soil samples obtained from the periphery of an abandoned manganese oxide mine and semi quantified as major, minor and trace. Based on information inherent in the data attributes, useful rules for grouping the samples were generated and with the aid of multiple data clustering, applied to characterize the clay minerals occurrences in the soils. The paper found that the presence of large quantities of illite and kaolinite heavily influence the formation of clusters. When the most influential variables—LJ and KJ were taken out, the resulting model showed that muscovite traces play a vital role in initial cluster building and the importance matrix of inputs suggested inter-dependence between muscovite, kaolinite and illite traces as well as between them and minor quantities of illite. Dwelling on aspects of clay mineralogy and modelling sciences, the paper marks a significant departure from the conventional approaches to clay characterisation by showing how effectively data mining methods can be adopted in the area. For a successful approach to characterisation of clay minerals in African soils, the paper recommends to set-up data repositories that will provide scientific data sources and forums in a multi-disciplinary environment. This is particularly important as capturing interesting patterns requires expert knowledge describing the emerging natural groupings.
7C4BE256	The problem of clustering multivariate observations is viewed as the replacement of a set of vectors with a set of labels and representative vectors. A general criterion for clustering is derived as a measure of representation error. Some special cases are derived by simplifying the general criterion. A general algorithm for finding the optimum classification with respect to a given criterion is derived. For a particular case, the algorithm reduces to a repeated application of a straightforward decision rule which behaves as a valley-seeking technique. Asymptotic properties of the procedure are developed. Numerical examples are presented for the finite sample case.
75991EF3	A family of graph-theoretical algorithms based on the minimal spanning tree are capable of detecting several kinds of cluster structure in arbitrary point sets; description of the detected clusters is possible in some cases by extensions of the method. Development of these clustering algorithms was based on examples from two-dimensional space because we wanted to copy the human perception of gestalts or point groupings. On the other hand, all the methods considered apply to higher dimensional spaces and even to general metric spaces. Advantages of these methods include determinacy, easy interpretation of the resulting clusters, conformity to gestalt principles of perceptual organization, and invariance of results under monotone transformations of interpoint distance. Brief discussion is made of the application of cluster detection to taxonomy and the selection of good feature spaces for pattern recognition. Detailed analyses of several planar cluster detection problems are illustrated by text and figures. The well-known Fisher iris data, in four-dimensional space, have been analyzed by these methods also. PL/1 programs to implement the minimal spanning tree methods have been fully debugged.
7F0D6257	Because of today's explosive information from Internet, people will contact much new information at any moment. So how to analyze this non-stationary information becomes more and more important. Clustering analysis is a good information analysis method, but many clustering algorithms only fit to stationary situation. Then in this paper, a novel incremental clustering algorithm based on self-organizing-mapping-IGSOM is provided to dispose this non-stationary information. This algorithm first uses self-organizing-mapping algorithm to construct a neuron model from original data. Then it selects some sample data from this neuron model, and combines the samples with new coming data together to train a new neuron model. To solve unbalance between sample data and new coming data, it alters sample data's weights. The experiments demonstrate that this incremental clustering method can dispose non-stationary data well, and has relatively high precision. Because only small samples are selected to replace large-scale original data, clustering time is also short.
677AC518	Nonparametric clustering algorithms, including mode-seeking, valley-seeking, and unimodal set algorithms, are capable of identifying generally shaped clusters of points in metric spaces. Most mode and valley-seeking algorithms, however, are iterative and the clusters obtained are dependent on the starting classification and the assumed number of clusters. In this paper, we present a noniterative, graph-theoretic approach to nonparametric cluster analysis. The resulting algorithm is governed by a single-scalar parameter, requires no starting classification, and is capable of determining the number of clusters. The resulting clusters are unimodal sets.
7A987394	Nature has always been a source of inspiration. Over the last few decades, it has stimulated many successful algorithms and computational tools for dealing with complex and optimization problems. This paper proposes a new heuristic algorithm that is inspired by the black hole phenomenon. Similar to other population-based algorithms, the black hole algorithm (BH) starts with an initial population of candidate solutions to an optimization problem and an objective function that is calculated for them. At each iteration of the black hole algorithm, the best candidate is selected to be the black hole, which then starts pulling other candidates around it, called stars. If a star gets too close to the black hole, it will be swallowed by the black hole and is gone forever. In such a case, a new star (candidate solution) is randomly generated and placed in the search space and starts a new search. To evaluate the performance of the black hole algorithm, it is applied to solve the clustering problem, which is a NP-hard problem. The experimental results show that the proposed black hole algorithm outperforms other traditional heuristic algorithms for several benchmark datasets.
756EB0D4	This paper presents a new stochastic methodology, which is based on the concepts of genetic algorithms (GAs) and greedy randomized adaptive search procedure (GRASP), for optimally clustering N objects into K clusters. The proposed stochastic algorithm (Hybrid GEN–GRASP) for the solution of the clustering problem is a two phase algorithm which combines a genetic algorithm for the solution of the feature selection problem and a GRASP algorithm for the solution of the clustering problem. Due to the nature of stochastic and population-based search, the proposed algorithm can overcome the drawbacks of traditional clustering methods. Its performance is compared with another methodology that uses for the solution of the feature selection problem a very popular metaheuristic method, the Tabu Search algorithm. Results from the application of the methodology to data sets from the UCI Machine Learning Repository are presented.
7DAC82B3	A family of objective functions called fuzzy c-regression models, which can be used too fit switching regression models to certain types of mixed data, is presented. Minimization of particular objective functions in the family yields simultaneous estimates for the parameters of c regression models, together with a fuzzy c-partitioning of the data. A general optimization approach for the family of objective functions is given and corresponding theoretical convergence results are discussed. The approach is illustrated by two numerical examples that show how it can be used to fit mixed data to coupled linear and nonlinear models.
764D562E	Clustering is a popular data analysis and data mining technique. A popular technique for clustering is based on k-means such that the data is partitioned into K clusters. However, the k-means algorithm highly depends on the initial state and converges to local optimum solution. This paper presents a new hybrid evolutionary algorithm to solve nonlinear partitional clustering problem. The proposed hybrid evolutionary algorithm is the combination of FAPSO (fuzzy adaptive particle swarm optimization), ACO (ant colony optimization) and k-means algorithms, called FAPSO-ACO–K, which can find better cluster partition. The performance of the proposed algorithm is evaluated through several benchmark data sets. The simulation results show that the performance of the proposed algorithm is better than other algorithms such as PSO, ACO, simulated annealing (SA), combination of PSO and SA (PSO–SA), combination of ACO and SA (ACO–SA), combination of PSO and ACO (PSO–ACO), genetic algorithm (GA), Tabu search (TS), honey bee mating optimization (HBMO) and k-means for partitional clustering problem.
7B2F6CD1	This paper presents a formalization of the concept of cluster analysis. It begins with an intuitive description of clustering, and discusses the separation of the measurement problem from the clustering problem. It develops the nature of the elements to be clustered, the nature of the possible clusters, and the nature of the clustering results. Particularly significant is the introduction of the attribute of mass of an element. The paper defines a class of functions, called clustering functions, having a certain domain and range and satisfying a certain set of properties, called axioms. It discusses some properties which are inadequate to serve as axioms. Finally, it presents a function which is in the class of clustering functions.
79A186D1	Data clustering helps one discern the structure of and simplify the complexity of massive quantities of data. It is a common technique for statistical data analysis and is used in many fields, including machine learning, data mining, pattern recognition, image analysis, and bioinformatics, in which the distribution of information can be of any size and shape. The well-known K-means algorithm, which has been successfully applied to many practical clustering problems, suffers from several drawbacks due to its choice of initializations. A hybrid technique based on combining the K-means algorithm, Nelder–Mead simplex search, and particle swarm optimization, called K–NM–PSO, is proposed in this research. The K–NM–PSO searches for cluster centers of an arbitrary data set as does the K-means algorithm, but it can effectively and efficiently find the global optima. The new K–NM–PSO algorithm is tested on nine data sets, and its performance is compared with those of PSO, NM–PSO, K–PSO and K-means clustering. Results show that K–NM–PSO is both robust and suitable for handling data clustering
816C2152	Linear discriminant analysis (LDA) is a well-known method for feature extraction and dimension reduction. It has been used widely in many applications involving high-dimensional data, such as image and text classification. An intrinsic limitation of classical LDA is the so-called singularity problems; that is, it fails when all scatter matrices are singular. Many LDA extensions were proposed in the past to overcome the singularity problems. Among these extensions, PCA+LDA, a two-stage method, received relatively more attention. In PCA+LDA, the LDA stage is preceded by an intermediate dimension reduction stage using principal component analysis (PCA). Most previous LDA extensions are computationally expensive, and not scalable, due to the use of singular value decomposition or generalized singular value decomposition. In this paper, we propose a two-stage LDA method, namely LDA/QR, which aims to overcome the singularity problems of classical LDA, while achieving efficiency and scalability simultaneously. The key difference between LDA/QR and PCA+LDA lies in the first stage, where LDA/QR applies QR decomposition to a small matrix involving the class centroids, while PCA+LDA applies PCA to the total scatter matrix involving all training data points. We further justify the proposed algorithm by showing the relationship among LDA/QR and previous LDA methods. Extensive experiments on face images and text documents are presented to show the effectiveness of the proposed algorithm.
7D1222C0	Clustering is a very important tool in data mining and is widely used in on-line services for medical, financial and social environments. The main goal in clustering is to create sets of similar objects in a data set. The data set to be used for clustering can be owned by a single entity, or in some cases, information from different databases is pooled to enrich the data so that the merged database can improve the clustering effort. However, in either case, the content of the database may be privacy sensitive and/or commercially valuable such that the owners may not want to share their data with any other entity, including the service provider. Such privacy concerns lead to trust issues between entities, which clearly damages the functioning of the service and even blocks cooperation between entities with similar data sets. To enable joint efforts with private data, we propose a protocol for distributed clustering that limits information leakage to the untrusted service provider that performs the clustering. To achieve this goal, we rely on cryptographic techniques, in particular homomorphic encryption, and further improve the state of the art of processing encrypted data in terms of efficiency by taking the distributed structure of the system into account and improving the efficiency in terms of computation and communication by data packing. While our construction can be easily adjusted to a centralized or a distributed computing model, we rely on a set of particular users that help the service provider with computations. Experimental results clearly indicate that the work we present is an efficient way of deploying a privacy-preserving clustering algorithm in a distributed manner.
805E15C9	Shell clustering algorithms are ideally suited for computer vision tasks such as boundary detection and surface approximation, particularly when the boundaries have jagged or scattered edges and when the range data is sparse. This is because shell clustering is insensitive to local aberrations, it can be performed directly in image space, and unlike traditional approaches it does assume dense data and does not use additional features such as curvatures and surface normals. The shell clustering algorithms introduced in Part I of this paper assume that the number of clusters is known, however, which is not the case in many boundary detection and surface approximation applications. This problem can be overcome by considering cluster validity. We introduce a validity measure called surface density which is explicitly meant for the type of applications considered in this paper, we show through theoretical derivations that surface density is relatively invariant to size and partiality (incompleteness) of the clusters. We describe unsupervised clustering algorithms that use the surface density measure and other measures to determine the optimum number of shell clusters automatically, and illustrate the application of the proposed algorithms to boundary detection in the case of intensity images and to surface approximation in the case of range images.
7E15A156	Clustering ensembles have emerged as a powerful method for improving both the robustness as well as the stability of unsupervised classification solutions. However, finding a consensus clustering from multiple partitions is a difficult problem that can be approached from graph-based, combinatorial, or statistical perspectives. This study extends previous research on clustering ensembles in several respects. First, we introduce a unified representation for multiple clusterings and formulate the corresponding categorical clustering problem. Second, we propose a probabilistic model of consensus using a finite mixture of multinomial distributions in a space of clusterings. A combined partition is found as a solution to the corresponding maximum-likelihood problem using the EM algorithm. Third, we define a new consensus function that is related to the classical intraclass variance criterion using the generalized mutual information definition. Finally, we demonstrate the efficacy of combining partitions generated by weak clustering algorithms that use data projections and random data splits. A simple explanatory model is offered for the behavior of combinations of such weak clustering components. Combination accuracy is analyzed as a function of several parameters that control the power and resolution of component partitions as well as the number of partitions. We also analyze clustering ensembles with incomplete information and the effect of missing cluster labels on the quality of overall consensus. Experimental results demonstrate the effectiveness of the proposed methods on several real-world data sets
7FE78FD2	A new fuzzy clustering algorithm, designed to detect and characterize ring-shaped clusters and combinations of ring-shaped and compact spherical clusters, has been developed. This FKR algorithm includes automatic search for proper initial conditions in the two cases of concentric and excentric (intersected) combinations of clusters. Validity criteria based on total fuzzy area and fuzzy density are used to estimate the optimal number of substructures in the data set. The FKR algorithm has been tested on a variety of simulated combinations of ring-shaped and compact spherical clusters, and its performance proved to be very good, both in identifying the input shapes and in recovering the input parameters. Application of the FKR algorithm to an MRI image of the heart's left ventricle was used to investigate the possibility of using this algorithm as an aid in image processing.
8045B11A	There are many different reasons why it is desirable to keep a set of modules (called a cluster) together during floorplanning. A cluster might be strongly connected, or functionality and testability of a design could be improved. We address the problem of performance constraints in a non-slicing floorplan represented by a sequence pair, and we use an evolutionary algorithm to generate a hard module placement preserving cluster constraints. The main contribution is to define cluster constraints as sequence pair constraints, and therefore reduce significantly the feasible solution search space. We use Lagrangian Relaxation formulation to generate an optimal soft module floorplan. Experimental results on modified MCNC benchmarks show the efficiency of our approach.
7D5ADE7F	Part I of this paper defines the class of constructive unsupervised on-line learning simplified adaptive resonance theory (SART) clustering networks. Proposed instances of class SART are the symmetric fuzzy ART (S-Fuzzy ART) and the Gaussian ART (GART) network. In Part II of our work, a third network belonging to class SART, termed fully self-organizing SART (FOSART), is presented and discussed. FOSART is a constructive, soft-to-hard competitive, topology-preserving, minimum-distance-to-means clustering algorithm capable of: 1) generating processing units and lateral connections on an example-driven basis and 2) removing processing units and lateral connections on a minibatch basis. FOSART is compared with Fuzzy ART, S-Fuzzy ART, GART and other well-known clustering techniques (e.g., neural gas and self-organizing map) in several unsupervised learning tasks, such as vector quantization, perceptual grouping and 3-D surface reconstruction. These experiments prove that when compared with other unsupervised learning networks, FOSART provides an interesting balance between easy user interaction, performance accuracy, efficiency, robustness, and flexibility.
79513265	A genetic algorithm-based efficient clustering technique that utilizes the principles of K-Means algorithm is described in this paper. The algorithm called KGA-clustering, while exploiting the searching capability of K-Means, avoids its major limitation of getting stuck at locally optimal values. Its superiority over the K-Means algorithm and another genetic algorithm-based clustering method, is extensively demonstrated for several artificial and real life data sets. A real life application of the KGA-clustering in classifying the pixels of a satellite image of a part of the city of Mumbai is provided.
790F7F31	We propose a linear clustering approach for large datasets of molecular geometries produced by high-throughput molecular dynamics simulations (e.g., protein folding and protein-ligand docking simulations). To this scope, we transform each three-dimensional (3D) molecular conformation into a single point in the 3D space reducing the space complexity while still encoding the molecular similarities and geometries. We assign an identifier to each single 3D point mapping a docked ligand, generate a tree from the whole space, and apply a tree-based clustering on the reduced conformation space that identifies most dense hyperspaces. We adapt our method for MapReduce and implement it in Hadoop. The load-balancing, fault-tolerance, and scalability in MapReduce allows screening of very large conformation datasets not approachable with traditional clustering methods. We analyze results for datasets with different concentrations of optimal solutions, and draw conclusions about the limitations and usability of our method. The advantages of this approach make it attractive for complex applications in real-world high-throughput molecular simulations.